{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "tHmE31eLymXz",
        "LGBlpXPj0wgX",
        "Xj-rus2X3byR",
        "-orT2gBY3hl0",
        "QjLTmqSU4G9A"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmrXBgGUz86b",
        "outputId": "2d2034bf-4f04-442a-d66b-aa6376e977e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-03-30 20:11:54.293869: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-30 20:11:57.009259: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-03-30 20:12:01.651543: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-md==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-md==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (67.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.2)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ],
      "source": [
        "!spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhdc3gVhmMOU",
        "outputId": "e0e6e652-368e-4d22-9bb5-a3d5f039b8d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-03-30 20:12:23.657740: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-30 20:12:25.256835: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-03-30 20:12:28.328462: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-lg==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-lg==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (67.6.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.2)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy, nltk, os, re, en_core_web_md\n",
        "# from os import listdir\n",
        "from os.path import join\n",
        "import spacy\n",
        "import numpy as np\n",
        "# from collections import Counter\n",
        "from string import punctuation\n",
        "import pandas as pd\n",
        "# from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import stopwords, words\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "# from sklearn.pipeline import make_pipeline\n",
        "nltk.download(['punkt','stopwords','wordnet','omw-1.4'])\n",
        "# from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "# from wordcloud import WordCloud\n",
        "# from PyPDF2 import PdfReader\n",
        "# import wikipedia as wiki\n",
        "nlp = en_core_web_md.load()\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "QJNGO-lb8XL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1ff251a-0af7-43e1-d67e-80bc8429a345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy, nltk, os, re, en_core_web_md\n",
        "from os.path import join\n",
        "import spacy\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import stopwords, words\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "nltk.download(['punkt','stopwords','wordnet','omw-1.4'])\n",
        "import matplotlib.pyplot as plt\n",
        "nlp = en_core_web_md.load()\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "yF_T4yKqvl9u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c557b3-b7a6-45f1-b190-bfb1cdf7b472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') \n",
        "%cd drive/MyDrive/lstm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSTn4KQvErY2",
        "outputId": "c764bf92-4d68-47be-c0b3-3d751066686a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/lstm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(filename):\n",
        "    df = pd.read_excel(filename, sheet_name='Train data')#,names = ['Statement', 'Data Definition', 'Data Action', 'Measurement', 'Time Constraint', 'Convention'])\n",
        "    return df\n",
        "\n",
        "dafr = load_data('legal_data.xlsx')\n",
        "dafr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kHg3EkCLCYHX",
        "outputId": "2c7bfeed-d2ec-4942-af5a-917570c564b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Statement  \\\n",
              "0    198 The following definitions apply in this Part.   \n",
              "1    Canadian unit means a unit of measurement that...   \n",
              "2    metric unit means a unit of measurement that i...   \n",
              "3    199 (1) For the purposes of subsection 6(1) of...   \n",
              "4    or\\n\\n(b) any expression, word, number, depict...   \n",
              "..                                                 ...   \n",
              "596  The incoming eggs received can present a sourc...   \n",
              "597  When conducting the hazard analysis, identify ...   \n",
              "598  Information on general preventive controls tha...   \n",
              "599  Ensure the water used to wash eggs is a minimu...   \n",
              "600  In addition, the egg wash water:\\n\\ncontains a...   \n",
              "\n",
              "     Data Definition\\nFood attached  Data Action\\nNot Food attached  \\\n",
              "0                               NaN                             NaN   \n",
              "1                               NaN                             NaN   \n",
              "2                               NaN                             NaN   \n",
              "3                               NaN                             NaN   \n",
              "4                               NaN                             NaN   \n",
              "..                              ...                             ...   \n",
              "596                             NaN                             NaN   \n",
              "597                             NaN                             NaN   \n",
              "598                             NaN                             NaN   \n",
              "599                             NaN                             NaN   \n",
              "600                             NaN                             NaN   \n",
              "\n",
              "     Measurement  Time Constraint  Convention  \n",
              "0            NaN              NaN         NaN  \n",
              "1            NaN              NaN         NaN  \n",
              "2            NaN              NaN         NaN  \n",
              "3            NaN              NaN         NaN  \n",
              "4            NaN              NaN         NaN  \n",
              "..           ...              ...         ...  \n",
              "596          NaN              NaN         NaN  \n",
              "597          NaN              NaN         NaN  \n",
              "598          NaN              NaN         NaN  \n",
              "599          1.0              NaN         NaN  \n",
              "600          1.0              NaN         NaN  \n",
              "\n",
              "[601 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50405cb6-f539-4000-bddb-d343aab1626e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Statement</th>\n",
              "      <th>Data Definition\\nFood attached</th>\n",
              "      <th>Data Action\\nNot Food attached</th>\n",
              "      <th>Measurement</th>\n",
              "      <th>Time Constraint</th>\n",
              "      <th>Convention</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>198 The following definitions apply in this Part.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Canadian unit means a unit of measurement that...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metric unit means a unit of measurement that i...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>199 (1) For the purposes of subsection 6(1) of...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>or\\n\\n(b) any expression, word, number, depict...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>The incoming eggs received can present a sourc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>When conducting the hazard analysis, identify ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>Information on general preventive controls tha...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>Ensure the water used to wash eggs is a minimu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>In addition, the egg wash water:\\n\\ncontains a...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>601 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50405cb6-f539-4000-bddb-d343aab1626e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50405cb6-f539-4000-bddb-d343aab1626e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50405cb6-f539-4000-bddb-d343aab1626e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dafr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAi0wyoa-UyY",
        "outputId": "0780bcdf-1c4d-4b8d-e95f-e63c68e6f4e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "601"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NrTZ-BrYElL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dafr.rename(columns = {'Data Definition\\nFood attached':'Data Definition'}, inplace = True)\n",
        "dafr.rename(columns = {'Data Action\\nNot Food attached':'Data Action'}, inplace = True)"
      ],
      "metadata": {
        "id": "2F7j7BkT67tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data = pd.concat([dafr])[['Statement','Measurement']]\n",
        "# data = pd.concat([dafr])[['Statement','Time Constraint']]\n",
        "# data = pd.concat([dafr])[['Statement','Data Definition']]\n",
        "data = pd.concat([dafr])[['Statement','Data Action']]\n",
        "# data = pd.concat([dafr])[['Statement','Convention']]\n",
        "# data = pd.concat([dafr])[['Statement','Software Related']]"
      ],
      "metadata": {
        "id": "ryEPiU36PpKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data['Measurement'] = data['Measurement'].fillna(0)\n",
        "# data['Time Constraint'] = data['Time Constraint'].fillna(0)\n",
        "# data['Data Definition'] = data['Data Definition'].fillna(0)\n",
        "data['Data Action'] = data['Data Action'].fillna(0)\n",
        "# data['Convention'] = data['Convention'].fillna(0)\n",
        "# data['Software Related'] = data['Software Related'].fillna(0)"
      ],
      "metadata": {
        "id": "cpxAt5KbSRez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.dropna()"
      ],
      "metadata": {
        "id": "aKDzfweDRuz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting data into train and test"
      ],
      "metadata": {
        "id": "vIOvrkcGAVqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# label_column = 'Measurement'\n",
        "# label_column = 'Time Constraint'\n",
        "# label_column = 'Data Definition'\n",
        "label_column = 'Data Action'\n",
        "\n",
        "df_train, df_test = train_test_split(data, stratify = data[label_column], train_size = 0.5, random_state = 42)"
      ],
      "metadata": {
        "id": "5tzFKqW1ALce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zvk0IbiKAolk",
        "outputId": "395cd88b-f5da-45d8-c5b7-636e584e8cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "419"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWkuH5YQFo1o",
        "outputId": "159aeadf-4ddc-4ec5-8132-8c1ea976569a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = df_train['Statement']\n",
        "data1 = data1.dropna()\n",
        "\n",
        "# data2 = df_test['Statement']\n",
        "# data2 = data2.dropna()"
      ],
      "metadata": {
        "id": "azXWYXb9Aj5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Keyword Method 1 - Using WikidoMiner"
      ],
      "metadata": {
        "id": "K58Im_65fjLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stemlemma(text):\n",
        "  return ' '.join([stemmer.stem(wordnet_lemmatizer.lemmatize(word)) for word in word_tokenize(text.lower())])"
      ],
      "metadata": {
        "id": "Dyb3mN6qAME8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional"
      ],
      "metadata": {
        "id": "ZZm1nH5VfA1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buildTFIDFvector(docs,use_ngrams=True,ngrams=4):\n",
        "  if use_ngrams:\n",
        "    vectorizer = TfidfVectorizer(ngram_range=(1,ngrams),min_df=0,stop_words=stopwords.words('english'))\n",
        "  else:\n",
        "    vectorizer = TfidfVectorizer(min_df=0,stop_words=stopwords.words('english'))\n",
        "  vectors = vectorizer.fit_transform(docs)\n",
        "  return pd.DataFrame(vectors.todense().tolist(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "def buildTFIDF(domains,files,use_ngrams=True,ngrams=3):\n",
        "  docs={}\n",
        "  for d in domains:\n",
        "    docs[d]=stemlemma(' '.join([files[doc] for doc in domains[d]]))\n",
        "  return buildTFIDFvector(list(docs.values()),use_ngrams=use_ngrams,ngrams=ngrams)\n",
        "\n",
        "def getTFIDFscore(q,id,tfidf):\n",
        "  score=0\n",
        "  for t in q.split():\n",
        "    if t in tfidf[q].columns:\n",
        "      score+=tfidf[q][t][id]\n",
        "  return score  "
      ],
      "metadata": {
        "id": "9r5AIkAj9LCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getAllNPsFromSent(sent,include_nouns=False):\n",
        "    npstr=[]\n",
        "    chunks = list(sent.noun_chunks)\n",
        "    for i in range(len(chunks)):\n",
        "        np=chunks[i]\n",
        "        if len(np)==1:\n",
        "            if np[0].pos_!=\"NOUN\":\n",
        "                continue\n",
        "        if np.text.lower() not in npstr:\n",
        "            npstr.append(np.text.lower())      \n",
        "        if i < len(chunks)-1:\n",
        "            np1=chunks[i+1]\n",
        "            if np1.start-np.end==1:\n",
        "                if sent.doc[np.end].tag_==\"CC\":\n",
        "                    newnp = sent[np.start:np1.end]\n",
        "                    if newnp.text.lower() not in npstr:\n",
        "                        npstr.append(newnp.text.lower())\n",
        "    if include_nouns:\n",
        "        for t in sent:\n",
        "            if \"subj\" in t.dep_ and t.pos_==\"NOUN\": \n",
        "                if t.text.lower() not in npstr:\n",
        "                    npstr.append(t.text.lower())\n",
        "    return npstr  "
      ],
      "metadata": {
        "id": "thyPY4ud_2qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getTopK(di,K=50):\n",
        "  tempdf=pd.DataFrame.from_dict(di,columns=[\"tfidf\"], orient='index')\n",
        "  return list(tempdf.sort_values(by=['tfidf'],ascending=False)[:K].index)\n",
        "\n",
        "def getKeywords(doc,nlp,include_nouns=False,tfidf=[],K=None): # K: free parameter\n",
        "  keywords=[]\n",
        "  for s in doc.split('\\n'):\n",
        "    s=nlp(s)\n",
        "    keywords.extend([n.text for n in list(s.ents)])\n",
        "    keywords.extend(list(getAllNPsFromSent(s,include_nouns)))\n",
        "  \n",
        "  keywords=list(set(keywords))\n",
        "\n",
        "  keywords_wn={}\n",
        "\n",
        "  if len(tfidf) > 0:\n",
        "    tfidf_threshold=np.mean([t for t in tfidf if t>0])\n",
        "\n",
        "  # print(\"Reached line 19\")\n",
        "  for k in keywords:\n",
        "    keyword=' '.join([word for word in word_tokenize(k) if not word.lower() in stopwords.words('english')])\n",
        "    if not wn.synsets(keyword) and keyword.replace(' ','').isalpha() and not keyword.isupper() and not np.array([k.isupper() for k in [ky[:-1] for ky in keyword.split()]]).any():\n",
        "      keyword=keyword.lower()\n",
        "      if len(tfidf)>0:\n",
        "        if stemlemma(keyword) in tfidf.index:# and len(keyword)>2:\n",
        "          if tfidf[stemlemma(keyword)]>tfidf_threshold:\n",
        "            if keyword not in keywords_wn:\n",
        "              keywords_wn[keyword]=tfidf[stemlemma(keyword)]\n",
        "            else:\n",
        "              keywords_wn[keyword]=max(keywords_wn[keyword],tfidf[stemlemma(keyword)])\n",
        "      else:\n",
        "        keywords_wn[keyword]=0\n",
        "\n",
        "  if K and len(tfidf)>0:\n",
        "    return getTopK(keywords_wn,K=K)\n",
        "\n",
        "  else:\n",
        "    return list(keywords_wn.keys())"
      ],
      "metadata": {
        "id": "JBgqmL-p_2ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords_set1={}\n",
        "corpora={}\n",
        "id = 0\n",
        "for doc in data1:\n",
        "  keywords = getKeywords(doc,nlp,include_nouns=True,K=50) # extract keywords\n",
        "  keywords_set1[id]=keywords\n",
        "  id = id + 1\n",
        "\n",
        "\n",
        "# keywords_set2={}\n",
        "# corpora={}\n",
        "# id = 0\n",
        "# for doc in data2:\n",
        "#   keywords = getKeywords(doc,nlp,include_nouns=True,K=50) # extract keywords\n",
        "#   keywords_set2[id]=keywords\n",
        "#   id = id + 1"
      ],
      "metadata": {
        "id": "vZw8fCYsFrDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords_set1[298]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CaekjXYKkgB",
        "outputId": "d85ec84f-93e2-4945-de1b-1c825b0ed271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['eriocheir']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1[298]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CtjwEnR4K-Km",
        "outputId": "294f6e5f-ec33-47c5-9403-f810a3028a8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'187 The requirements of this Division apply in respect of any food that is sent or conveyed from one province to another or imported.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Keyword Method 2 - Using TFIDF to rank the words and choosing the Top K words"
      ],
      "metadata": {
        "id": "pRTKNg9M2Vvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PUNCTUATION = \"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\" \n",
        "TOP_K_KEYWORDS = 8\n",
        "\n",
        "def sort_coo(coo_matrix):\n",
        "    \"\"\"Sort a dict with highest score\"\"\"\n",
        "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
        "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
        "\n",
        "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
        "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
        "    \n",
        "    #use only topn items from vector\n",
        "    sorted_items = sorted_items[:topn]\n",
        "\n",
        "    score_vals = []\n",
        "    feature_vals = []\n",
        "    \n",
        "    # word index and corresponding tf-idf score\n",
        "    for idx, score in sorted_items:\n",
        "        \n",
        "        #keep track of feature name and its corresponding score\n",
        "        score_vals.append(round(score, 3))\n",
        "        feature_vals.append(feature_names[idx])\n",
        "\n",
        "    #create a tuples of feature, score\n",
        "    results= {}\n",
        "    for idx in range(len(feature_vals)):\n",
        "        results[feature_vals[idx]]=score_vals[idx]\n",
        "    \n",
        "    return results\n",
        "\n",
        "def get_keywords(vectorizer, feature_names, doc):\n",
        "    \"\"\"Return top k keywords from a doc using TF-IDF method\"\"\"\n",
        "\n",
        "    #generate tf-idf for the given document\n",
        "    tf_idf_vector = vectorizer.transform([doc])\n",
        "    # print(\"tf_idf output:\", tf_idf_vector)\n",
        "    #sort the tf-idf vectors by descending order of scores\n",
        "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
        "    # print(\"Sorted output:\", sorted_items)\n",
        "\n",
        "    #extract only TOP_K_KEYWORDS\n",
        "    keywords=extract_topn_from_vector(feature_names,sorted_items,TOP_K_KEYWORDS)\n",
        "    # print(\"Results dict\",keywords)\n",
        "    keys = keywords.keys()\n",
        "    return [*keys]"
      ],
      "metadata": {
        "id": "NwPx0TyFukqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "ry7kUUB0za2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpora = df_train['Statement'].to_list()\n",
        "len(corpora)/2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piKt3SIdbYcp",
        "outputId": "8bc935a8-c97d-4828-83c4-7a0464a806eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149.5"
            ]
          },
          "metadata": {},
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stopwords=get_stopwords_list(STOPWORD_PATH)\n",
        "import nltk\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "# Initializing TF-IDF Vectorizer with stopwords\n",
        "vectorizer = TfidfVectorizer(stop_words=stopwords, smooth_idf=True, use_idf=True)\n",
        "\n",
        "corpora = df_train['Statement'].to_list()\n",
        "# Creating vocab with our corpora\n",
        "# Excluding first 10 docs for testing purpose\n",
        "vectorizer.fit_transform(corpora[239:]) # vectorizing the first half of the corpora\n",
        "\n",
        "# Storing vocab\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "\n",
        "result = []\n",
        "keywords_set1= []\n",
        "#Fetching keywords for the 2nd half of the corpora\n",
        "\n",
        "for doc in corpora[:239]:\n",
        "    keys = get_keywords(vectorizer, feature_names, doc)\n",
        "    li = doc.lower().split()\n",
        "    key_list = []\n",
        "    for i in li:\n",
        "      if i in keys:\n",
        "        key_list.append(i)\n",
        "    # print(key_list)\n",
        "    keywords_set1.append(key_list)\n",
        "\n",
        "#Repeating the procedure for the 2nd half of the corpora\n",
        "vectorizer = TfidfVectorizer(stop_words=stopwords, smooth_idf=True, use_idf=True)\n",
        "vectorizer.fit_transform(corpora[:239])\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "keywords_set2= []\n",
        "for doc in corpora[239:]:\n",
        "    keys = get_keywords(vectorizer, feature_names, doc)\n",
        "    li = doc.lower().split()\n",
        "    key_list = []\n",
        "    for i in li:\n",
        "      if i in keys:\n",
        "        key_list.append(i)\n",
        "    # print(key_list)\n",
        "    keywords_set2.append(key_list)\n",
        "\n",
        "# test_corpora = df_test['Statement']\n",
        "# keywords_set2= []\n",
        "# for doc in test_corpora:\n",
        "#     keys = get_keywords(vectorizer, feature_names, doc)\n",
        "#     li = doc.lower().split()\n",
        "#     key_list = []\n",
        "#     for i in li:\n",
        "#       if i in keys:\n",
        "#         key_list.append(i)\n",
        "#     # print(key_list)\n",
        "#     keywords_set2.append(key_list)"
      ],
      "metadata": {
        "id": "9mZdgWX5t2RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords_set1 = keywords_set1 + keywords_set2"
      ],
      "metadata": {
        "id": "HCjZujO2yBBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Keyword Method 3 - Using Spacy's methods to get the hotwords"
      ],
      "metadata": {
        "id": "gjh_X97r2Zvh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WSgqWi-9krPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import en_core_web_lg\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "metadata": {
        "id": "PQs1v62j2b5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hotwords(text):\n",
        "    result = []\n",
        "    pos_tag = ['PROPN', 'ADJ', 'NOUN'] # 1\n",
        "    doc = nlp(text.lower()) # 2\n",
        "    for token in doc:\n",
        "        # 3\n",
        "        if(token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
        "            continue\n",
        "        # 4\n",
        "        if(token.pos_ in pos_tag):\n",
        "            result.append(token.text)\n",
        "                \n",
        "    return result # 5"
      ],
      "metadata": {
        "id": "PujGDpuI2b9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords_set1={}\n",
        "corpora={}\n",
        "id = 0\n",
        "for doc in data1:\n",
        "  keywords = get_hotwords(doc)\n",
        "  keywords_set1[id]=keywords\n",
        "  id = id + 1\n",
        "\n",
        "\n",
        "# keywords_set2={}\n",
        "# corpora={}\n",
        "# id = 0\n",
        "# for doc in data2:\n",
        "#   keywords = get_hotwords(doc)\n",
        "#   keywords_set2[id]=keywords\n",
        "#   id = id + 1"
      ],
      "metadata": {
        "id": "vAoZxUKEks85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1[386]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wazMM29BnJCq",
        "outputId": "99277c30-bb6d-4ce7-e92e-ea4585ef9ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(2) The conditions in paragraphs (1)(a) and (b) do not apply in respect of the manufacturing, preparing, storing, packaging or labelling of the adductor muscles of scallops or the meat of geoducks.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(keywords_set1)"
      ],
      "metadata": {
        "id": "LG1Enom4m9Ld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c08d074c-6bd4-4491-bf29-9246ae635d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "299"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(keywords_set2)"
      ],
      "metadata": {
        "id": "CJUxYqE51-EG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assigning Train data and test data"
      ],
      "metadata": {
        "id": "QViwYV9_x_2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tr_df = df_train\n",
        "tr_df = tr_df.reset_index(drop=True)\n",
        "tr_df = tr_df.dropna()\n",
        "\n",
        "te_df = df_test\n",
        "te_df = te_df.reset_index(drop=True)\n",
        "te_df = te_df.dropna()"
      ],
      "metadata": {
        "id": "SsXMh1QNWPsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tr_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azmQob9OyLtI",
        "outputId": "d4ea6474-7c28-45ea-e313-988298f113a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "299"
            ]
          },
          "metadata": {},
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(te_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVEc05Wv_K2u",
        "outputId": "cdb6a6a1-1da9-4973-d063-7e35e069ef57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keywords_set2[0]"
      ],
      "metadata": {
        "id": "pfTZl113PiGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting list of keywords into a line"
      ],
      "metadata": {
        "id": "lJ5v3IfUAf5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(tr_df['Statement'])):\n",
        "  line = ''\n",
        "  for j in keywords_set1[i]:\n",
        "    if line == '':\n",
        "      line = j\n",
        "    else:\n",
        "      line = line +' '+ j\n",
        "  tr_df['Statement'][i] = line\n",
        "\n",
        "# for i in range(len(te_df['Statement'])):\n",
        "#   line = ''\n",
        "#   for j in keywords_set2[i]:\n",
        "#     if line == '':\n",
        "#       line = j\n",
        "#     else:\n",
        "#       line = line +' '+ j\n",
        "#   te_df['Statement'][i] = line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_OauL7Ha4NJ",
        "outputId": "42f314fc-6899-48a2-db41-746ca3586d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-303-fe97dc94535c>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tr_df['Statement'][i] = line\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove records for which no Keywords were extracted "
      ],
      "metadata": {
        "id": "m8yhN6effpjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tr_df = tr_df[tr_df['Statement'] !='']\n",
        "\n",
        "te_df = te_df[te_df['Statement'] !='']"
      ],
      "metadata": {
        "id": "xgGXA0RZ8j_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tr_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl7A3FZonbck",
        "outputId": "ce6a8b10-1483-4494-952b-57223579bba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "299"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(te_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reUfcP3-QDKa",
        "outputId": "202035eb-e713-4f75-b4b3-fdf5438ca7a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_df['Statement'][0]"
      ],
      "metadata": {
        "id": "LIiRpTJnJXoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get train Class Distribution"
      ],
      "metadata": {
        "id": "tSIfDSLnfzQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = tr_df.sample(frac=1, axis=0, random_state = None)\n",
        "num_labels = df[label_column].nunique()\n",
        "\n",
        "print(df.shape)\n",
        "print(df[label_column].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlFYV23MGigf",
        "outputId": "48acd00e-f76a-401f-e2d5-970d9494c5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(299, 2)\n",
            "0.0    287\n",
            "1.0     12\n",
            "Name: Data Action, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oversample/ Undersample "
      ],
      "metadata": {
        "id": "O6XN67RHf2xb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# label_column = 'Measurement'\n",
        "# label_column = 'Time Constraint'\n",
        "# label_column = 'Data Definition'\n",
        "label_column = 'Data Action'\n",
        "# label_column = 'Convention'\n",
        "# label_column = 'Software Related'\n",
        "seed = 904727489\n",
        "def undersample(df_trn, major_label, minor_label):\n",
        "  sample_size = sum(df_trn[label_column] == minor_label)\n",
        "  majority_indices = df_trn[df_trn[label_column] == major_label].index\n",
        "  random_indices = np.random.choice(majority_indices, sample_size, replace=False)\n",
        "  sample = df_trn.loc[random_indices]\n",
        "  sample = sample.append(df_trn[df_trn[label_column] == minor_label])\n",
        "  df_trn = sample\n",
        "  df_trn = df_trn.sample(frac=1, axis=0, random_state = seed)\n",
        "  print(df_trn[label_column].value_counts())\n",
        "  return df_trn\n",
        "\n",
        "def oversample(df_trn, major_label, minor_label):\n",
        "  minor_size = sum(df_trn[label_column] == minor_label)\n",
        "  major_size = sum(df_trn[label_column] == major_label)\n",
        "  multiplier = major_size//minor_size\n",
        "  sample = df_trn\n",
        "  minority_indices = df_trn[df_trn[label_column] == minor_label].index\n",
        "  diff = major_size - (multiplier * minor_size)     \n",
        "  random_indices = np.random.choice(minority_indices, diff, replace=False)\n",
        "  sample = pd.concat([df_trn.loc[random_indices], sample], ignore_index=True)\n",
        "  for i in range(multiplier - 1):\n",
        "    sample = pd.concat([sample, df_trn[df_trn[label_column] == minor_label]], ignore_index=True)\n",
        "  df_trn = sample\n",
        "  df_trn = df_trn.sample(frac=1, axis=0, random_state = seed)\n",
        "  print(df_trn[label_column].value_counts())\n",
        "  return df_trn"
      ],
      "metadata": {
        "id": "PQB4rDHnnLJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ov = oversample(tr_df, 0.0, 1.0 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgKLjDb-nOpF",
        "outputId": "dd83829d-e473-4b7a-b4d3-b02b5f9e8391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0    287\n",
            "0.0    287\n",
            "Name: Data Action, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ov = oversample(ov, 1.0, 0.0 )"
      ],
      "metadata": {
        "id": "okhf0FDOIVCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ov = tdf # FOr Data Definition alone no need of Sampling"
      ],
      "metadata": {
        "id": "jGpwcslcHPWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ov = ov.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "WMBtX7rTCaSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = ov['Statement']\n",
        "# y_train = ov['Measurement']\n",
        "# y_train = ov['Time Constraint']\n",
        "# y_train = ov['Data Definition']\n",
        "y_train = ov['Data Action']\n",
        "# y_train = ov['Convention']\n",
        "# y_train = ov['Software Related']\n",
        "\n",
        "x_test = te_df['Statement']\n",
        "# y_test = te_df['Measurement']\n",
        "# y_test = te_df['Time Constraint']\n",
        "# y_test = te_df['Data Definition']\n",
        "y_test = te_df['Data Action']\n",
        "# y_test = te_df['Convention']\n",
        "# y_test = te_df['Software Related']"
      ],
      "metadata": {
        "id": "U7gp5Ux-mT-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test[0])"
      ],
      "metadata": {
        "id": "UldawE8qmpAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02827af4-75bc-485b-b5f7-8ca663385e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "633"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "te_df['Statement'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "y-sL1fQjK2ry",
        "outputId": "2c60a829-043f-4f2a-df39-440fffd87c81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(3) Despite subsection (2), the licence holder must keep a meat product that is a specified risk material, contains a specified risk material or is derived from a specified risk material in a separate area of the inedible products area and must handle and destroy it in accordance with Part I.1 of the Health of Animals Regulations.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizing using TFIDF"
      ],
      "metadata": {
        "id": "Zz4CED_E_cqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(max_features=400, smooth_idf=True, use_idf=True)\n",
        "\n",
        "cvectorizer = CountVectorizer()\n",
        "\n",
        "\n",
        "# vectorizer.fit_transform(corpora)\n",
        "# tfidf.fit_transform(x_train)\n",
        "cvectorizer.fit_transform(x_train)\n",
        "\n",
        "# X_train = tfidf.fit_transform(x_train).toarray()\n",
        "X_train = cvectorizer.fit_transform(x_train).toarray()\n",
        "\n",
        "\n",
        "# X_test = tfidf.transform(x_test).toarray()\n",
        "X_test = cvectorizer.transform(x_test).toarray()"
      ],
      "metadata": {
        "id": "dDK2ufuEK3CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test)"
      ],
      "metadata": {
        "id": "Dti6RQCgcHby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96513d42-12d7-4e54-8656-62a12b6daa47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eliminating test sentences that don't have any keywords in common with the train data"
      ],
      "metadata": {
        "id": "Wce_YfdyckKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = 0\n",
        "new_test = []\n",
        "for j in range(len(X_test)):\n",
        "  for i in range(len(X_test[j])):\n",
        "    if X_test[j][i] != 0:\n",
        "      # print(i)\n",
        "      c = c + 1\n",
        "  if c != 0:\n",
        "    new_test.append(X_test[j])\n",
        "\n",
        "X_test = new_test"
      ],
      "metadata": {
        "id": "r7GHiKLhY3nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_test[0]"
      ],
      "metadata": {
        "id": "V0FjsXEpZwJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzkDGRCW8VFX",
        "outputId": "42c91b4f-4a9d-4ade-b17e-4db749244f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "623"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le"
      ],
      "metadata": {
        "id": "l3fWx4pMpAYU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "fa569634-cb5b-4ec2-933c-409983436825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'225 The label of a prepackaged food must be applied or attached in such a manner that the label is still applied or attached at the time it is sold.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sen = \"Ash finally won the Pokemon league with Pikachu\"\n",
        "c=0\n",
        "l = cvectorizer.transform([sen]).toarray()\n",
        "ind = 0\n",
        "for i in l[0]:\n",
        "    ind = ind + 1\n",
        "    if i != 0:\n",
        "      print(cvectorizer.get_feature_names_out()[ind])\n",
        "      c = c + 1\n",
        "    # else:\n",
        "    #   print(\"ZEROES\")"
      ],
      "metadata": {
        "id": "QSAww6dPolDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l"
      ],
      "metadata": {
        "id": "UE7TiLySR-1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['Gotta catch em all gotta catch em all', 'The first Gym Leader is Brock', 'Ash lost in the quarter finals of Indigo league']\n",
        "cv = CountVectorizer()\n",
        "cv.fit_transform(sentences)\n",
        "train_sen = cv.transform(sentences).toarray()\n",
        "\n",
        "sen = \"Ash chose Pikachu to fight against Brock\"\n",
        "l = cv.transform([sen]).toarray()"
      ],
      "metadata": {
        "id": "CICp9gvrcXGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(18):\n",
        "  print(cv.get_feature_names_out()[i])"
      ],
      "metadata": {
        "id": "Chk3WDuhcDDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sen[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlC81Upx596S",
        "outputId": "a302ab3a-3063-473b-d829-a5c27646f9a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Evaluating using Multinomial NB Classifier"
      ],
      "metadata": {
        "id": "mnteRJst_flx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "classification_report = classification_report(y_test, y_pred)\n",
        "print(classification_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQI5Mg68QWA8",
        "outputId": "3773856c-ce96-421f-cc4b-5f64b3bca71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.92      0.95       288\n",
            "         1.0       0.27      0.75      0.40        12\n",
            "\n",
            "    accuracy                           0.91       300\n",
            "   macro avg       0.63      0.83      0.68       300\n",
            "weighted avg       0.96      0.91      0.93       300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Measurement"
      ],
      "metadata": {
        "id": "tHmE31eLymXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All requirements"
      ],
      "metadata": {
        "id": "fZYi2Eo6DHYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(TfidfVectorizer(), MultinomialNB()) # svm.SVC(kernel='linear'))\n",
        "\n",
        "# scores = cross_validate(clf, data_x, data_y, scoring=['accuracy'], cv=5, return_train_score=False)\n",
        "scores = cross_validate(clf, x_train, y_train, scoring=['f1_weighted', 'precision' ,'recall'], cv=10)\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdsOgP7zkX81",
        "outputId": "50fc476a-aafd-43fc-da74-5df08f236dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.01585722, 0.01125169, 0.01205945, 0.01140118, 0.01134229,\n",
            "       0.01091671, 0.01111054, 0.01142097, 0.01088881, 0.01131153]), 'score_time': array([0.00528383, 0.00502157, 0.00498366, 0.00511479, 0.00497532,\n",
            "       0.00498295, 0.00494623, 0.00511336, 0.0049777 , 0.00539994]), 'test_f1_weighted': array([0.86185003, 0.87235023, 0.87235023, 0.85017904, 0.90736121,\n",
            "       0.82452107, 0.84877417, 0.80428725, 0.84997963, 0.83670383]), 'test_precision': array([0.82978723, 0.80769231, 0.80769231, 0.8125    , 0.84313725,\n",
            "       0.76363636, 0.79245283, 0.78723404, 0.81632653, 0.77777778]), 'test_recall': array([0.90697674, 0.97674419, 0.97674419, 0.90697674, 1.        ,\n",
            "       0.95454545, 0.95454545, 0.84090909, 0.90909091, 0.95454545])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB Classifier - SW Related Requirements"
      ],
      "metadata": {
        "id": "uk3oscBnDN13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(TfidfVectorizer(), MultinomialNB()) # svm.SVC(kernel='linear'))\n",
        "\n",
        "# scores = cross_validate(clf, data_x, data_y, scoring=['accuracy'], cv=5, return_train_score=False)\n",
        "scores = cross_validate(clf, x_train, y_train, scoring=['f1_weighted', 'precision' ,'recall'], cv=10)\n",
        "print(scores) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yetzgcFzC7p4",
        "outputId": "627b790a-5054-4a5f-8441-c45450e601b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.01274514, 0.00637507, 0.00638056, 0.00609422, 0.00680614,\n",
            "       0.00654674, 0.00620914, 0.00618029, 0.00621247, 0.00641942]), 'score_time': array([0.00429583, 0.00421453, 0.00417042, 0.00432563, 0.0042007 ,\n",
            "       0.00445437, 0.0041678 , 0.00420666, 0.00443912, 0.00433707]), 'test_f1_weighted': array([0.96543485, 0.93087028, 0.82717423, 0.79261084, 0.79011936,\n",
            "       0.89630454, 0.78803245, 0.78803245, 0.78803245, 0.93103448]), 'test_precision': array([1.        , 0.875     , 0.84615385, 0.75      , 0.72222222,\n",
            "       0.875     , 0.73684211, 0.73684211, 0.73684211, 0.93333333]), 'test_recall': array([0.92857143, 1.        , 0.78571429, 0.85714286, 0.92857143,\n",
            "       0.93333333, 0.93333333, 0.93333333, 0.93333333, 0.93333333])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM classifier - SW Related Requirements"
      ],
      "metadata": {
        "id": "5nvXG8_0DtSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(TfidfVectorizer(), SVC(kernel='linear'))\n",
        "\n",
        "# scores = cross_validate(clf, data_x, data_y, scoring=['accuracy'], cv=5, return_train_score=False)\n",
        "scores = cross_validate(clf, x_train, y_train, scoring=['f1_weighted', 'precision' ,'recall'], cv=10)\n",
        "print(scores) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MOw7CfoC53f",
        "outputId": "94cb823a-9acd-4380-8e75-15351b89ef90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.02498794, 0.02009344, 0.018507  , 0.02617359, 0.02270603,\n",
            "       0.02205062, 0.01829505, 0.01780844, 0.01872349, 0.01745749]), 'score_time': array([0.00822401, 0.00882602, 0.00885415, 0.01023483, 0.00844479,\n",
            "       0.01036048, 0.0085361 , 0.00784278, 0.00836849, 0.00836182]), 'test_f1_weighted': array([0.89504702, 0.93087028, 0.86107427, 0.82758621, 0.75804392,\n",
            "       0.86206897, 0.89504702, 0.78803245, 0.82717423, 0.89630454]), 'test_precision': array([1.        , 0.875     , 0.91666667, 0.8       , 0.76923077,\n",
            "       0.86666667, 0.83333333, 0.73684211, 0.8125    , 0.875     ]), 'test_recall': array([0.78571429, 1.        , 0.78571429, 0.85714286, 0.71428571,\n",
            "       0.86666667, 1.        , 0.93333333, 0.86666667, 0.93333333])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Time Constraint"
      ],
      "metadata": {
        "id": "LGBlpXPj0wgX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All Requirements"
      ],
      "metadata": {
        "id": "30gpL8uLLSr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(TfidfVectorizer(), MultinomialNB()) # svm.SVC(kernel='linear'))\n",
        "\n",
        "# scores = cross_validate(clf, data_x, data_y, scoring=['accuracy'], cv=5, return_train_score=False)\n",
        "scores = cross_validate(clf, x_train, y_train, scoring=['f1_weighted', 'precision' ,'recall'], cv=10)\n",
        "print(scores) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5qUVakf0xkW",
        "outputId": "f53c3a13-66e4-48ff-dba2-0d3e20868f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.03298378, 0.01283407, 0.01323009, 0.01287174, 0.01451612,\n",
            "       0.01308393, 0.0127213 , 0.01454878, 0.01284194, 0.01400685]), 'score_time': array([0.00556183, 0.00567102, 0.00512433, 0.0052309 , 0.00651622,\n",
            "       0.00525308, 0.0049603 , 0.00491738, 0.00500298, 0.00518203]), 'test_f1_weighted': array([0.92965531, 0.93978322, 0.87824675, 0.94987469, 0.92965531,\n",
            "       0.9194847 , 0.92898881, 0.90841868, 0.91859334, 0.92888627]), 'test_precision': array([0.87719298, 0.89285714, 0.80645161, 0.90909091, 0.87719298,\n",
            "       0.86206897, 0.875     , 0.84482759, 0.86206897, 0.87719298]), 'test_recall': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB Classifier- SW related requirements"
      ],
      "metadata": {
        "id": "8nrik1FZED90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(TfidfVectorizer(), MultinomialNB()) # svm.SVC(kernel='linear'))\n",
        "\n",
        "# scores = cross_validate(clf, data_x, data_y, scoring=['accuracy'], cv=5, return_train_score=False)\n",
        "scores = cross_validate(clf, x_train, y_train, scoring=['f1_weighted', 'precision' ,'recall'], cv=10)\n",
        "print(scores) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugdh_n7kEDIc",
        "outputId": "c0e3d68b-413f-4163-a3e4-2c7e62f0ec56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.01387763, 0.00745583, 0.0080893 , 0.00820112, 0.00779247,\n",
            "       0.00777817, 0.0072875 , 0.00743103, 0.01130271, 0.00745749]), 'score_time': array([0.00469947, 0.00505543, 0.00447893, 0.00446868, 0.00526261,\n",
            "       0.00428391, 0.00424957, 0.00486422, 0.01276159, 0.00439382]), 'test_f1_weighted': array([0.95227273, 0.97617697, 0.95227273, 0.92820513, 0.97617697,\n",
            "       0.97617697, 0.95104446, 0.97558067, 0.90173883, 0.95116144]), 'test_precision': array([0.91304348, 0.95454545, 0.91304348, 0.875     , 0.95454545,\n",
            "       0.95454545, 0.91304348, 0.95454545, 0.83333333, 0.90909091]), 'test_recall': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM classifier - SW Related Requirements"
      ],
      "metadata": {
        "id": "pxXWI6GpELsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(TfidfVectorizer(), SVC(kernel='linear'))\n",
        "\n",
        "# scores = cross_validate(clf, data_x, data_y, scoring=['accuracy'], cv=5, return_train_score=False)\n",
        "scores = cross_validate(clf, x_train, y_train, scoring=['f1_weighted', 'precision' ,'recall'], cv=10)\n",
        "print(scores) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWGpNeU9EDQ6",
        "outputId": "c549b86a-bb5f-426e-f5d6-1abb62db82c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.01535416, 0.01124787, 0.01188064, 0.01135683, 0.01169634,\n",
            "       0.01102185, 0.01130986, 0.01198077, 0.01128101, 0.01424718]), 'score_time': array([0.00550175, 0.0051384 , 0.00503588, 0.00901794, 0.00529718,\n",
            "       0.00519538, 0.00523973, 0.00558639, 0.00494719, 0.00562549]), 'test_f1_weighted': array([0.97617697, 1.        , 0.97617697, 1.        , 0.97617697,\n",
            "       0.95227273, 1.        , 0.97558067, 0.92656748, 1.        ]), 'test_precision': array([0.95454545, 1.        , 0.95454545, 1.        , 0.95454545,\n",
            "       0.91304348, 1.        , 0.95454545, 0.86956522, 1.        ]), 'test_recall': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Definition"
      ],
      "metadata": {
        "id": "Xj-rus2X3byR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All Requirements"
      ],
      "metadata": {
        "id": "uOGoCGW3LWw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(TfidfVectorizer(), MultinomialNB()) # svm.SVC(kernel='linear'))\n",
        "\n",
        "# scores = cross_validate(clf, data_x, data_y, scoring=['accuracy'], cv=5, return_train_score=False)\n",
        "scores = cross_validate(clf, x_train, y_train, scoring=['f1_weighted', 'precision' ,'recall'], cv=10)\n",
        "print(scores) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0uHvltD3cAH",
        "outputId": "e115dc6a-1f3f-49d9-a126-eceeb5e37ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.01901507, 0.01147604, 0.01103902, 0.01136446, 0.0108521 ,\n",
            "       0.01177931, 0.01091766, 0.01100349, 0.01245427, 0.01081014]), 'score_time': array([0.00503922, 0.00492668, 0.0050981 , 0.00489783, 0.00593734,\n",
            "       0.00499487, 0.00497842, 0.00488353, 0.00519633, 0.00491285]), 'test_f1_weighted': array([0.88605792, 0.8742929 , 0.89974937, 0.72793522, 0.77142857,\n",
            "       0.7968254 , 0.88663203, 0.84915148, 0.925     , 0.84761905]), 'test_precision': array([0.81632653, 0.82608696, 0.86363636, 0.67272727, 0.72      ,\n",
            "       0.74      , 0.82978723, 0.80434783, 0.925     , 0.78      ]), 'test_recall': array([1.   , 0.95 , 0.95 , 0.925, 0.9  , 0.925, 0.975, 0.925, 0.925,\n",
            "       0.975])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB classifier - SW related Requirements"
      ],
      "metadata": {
        "id": "3hPVRzSaIqrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(TfidfVectorizer(), MultinomialNB()) # svm.SVC(kernel='linear'))\n",
        "\n",
        "# scores = cross_validate(clf, data_x, data_y, scoring=['accuracy'], cv=5, return_train_score=False)\n",
        "scores = cross_validate(clf, x_train, y_train, scoring=['f1_weighted', 'precision' ,'recall'], cv=10)\n",
        "print(scores) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHU6JIh_IoJ4",
        "outputId": "2e0b05c0-0387-461e-ca45-7d3e073f31d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.01529908, 0.01145625, 0.01072431, 0.00992656, 0.0127635 ,\n",
            "       0.01034474, 0.0110538 , 0.01171303, 0.01020288, 0.00886178]), 'score_time': array([0.00945902, 0.01048493, 0.00820827, 0.00690389, 0.0077033 ,\n",
            "       0.00714231, 0.00955343, 0.00760555, 0.00911188, 0.00694609]), 'test_f1_weighted': array([0.4989648 , 0.26666667, 0.54166667, 0.58095238, 0.70535714,\n",
            "       0.47276688, 0.76842105, 0.72727273, 0.77225673, 0.75070028]), 'test_precision': array([0.5       , 0.30769231, 0.55555556, 0.57894737, 0.64705882,\n",
            "       0.5       , 0.875     , 0.72727273, 0.8       , 1.        ]), 'test_recall': array([0.54545455, 0.36363636, 0.45454545, 1.        , 1.        ,\n",
            "       0.72727273, 0.63636364, 0.72727273, 0.72727273, 0.54545455])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM classifier - SW related requirements"
      ],
      "metadata": {
        "id": "dprnaoSHIrvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(TfidfVectorizer(), SVC(kernel='linear'))\n",
        "\n",
        "# scores = cross_validate(clf, data_x, data_y, scoring=['accuracy'], cv=5, return_train_score=False)\n",
        "scores = cross_validate(clf, x_train, y_train, scoring=['f1_weighted', 'precision' ,'recall'], cv=10)\n",
        "print(scores) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm4ZUcfWItXk",
        "outputId": "c00e010c-0484-4015-9a6f-00602c140250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.01386642, 0.01038623, 0.01152945, 0.01018095, 0.010391  ,\n",
            "       0.00992942, 0.00980854, 0.00975513, 0.00963664, 0.00976682]), 'score_time': array([0.00560045, 0.00503802, 0.00483441, 0.00483823, 0.00493145,\n",
            "       0.00497127, 0.0048902 , 0.00484991, 0.00503087, 0.00475025]), 'test_f1_weighted': array([0.45      , 0.4989648 , 0.49052632, 0.58095238, 0.70535714,\n",
            "       0.41071429, 0.77225673, 0.67578947, 0.67578947, 0.75070028]), 'test_precision': array([0.46153846, 0.5       , 0.5       , 0.57894737, 0.64705882,\n",
            "       0.47058824, 0.8       , 0.75      , 0.75      , 1.        ]), 'test_recall': array([0.54545455, 0.45454545, 0.36363636, 1.        , 1.        ,\n",
            "       0.72727273, 0.72727273, 0.54545455, 0.54545455, 0.54545455])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After Oversampling on both classes "
      ],
      "metadata": {
        "id": "by-QR2hbIjKs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB classifier - SW Related"
      ],
      "metadata": {
        "id": "YEcPOzDeHYj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(TfidfVectorizer(), MultinomialNB()) # svm.SVC(kernel='linear'))\n",
        "\n",
        "# scores = cross_validate(clf, data_x, data_y, scoring=['accuracy'], cv=5, return_train_score=False)\n",
        "scores = cross_validate(clf, x_train, y_train, scoring=['f1_weighted', 'precision' ,'recall'], cv=10)\n",
        "print(scores) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fidYRx8HYuG",
        "outputId": "72302626-8da6-4b15-9861-5a987053dca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.01800203, 0.00872016, 0.00804877, 0.00765634, 0.00842643,\n",
            "       0.008425  , 0.00858688, 0.00960565, 0.00788164, 0.00773692]), 'score_time': array([0.00491714, 0.0047493 , 0.00448227, 0.00462317, 0.00490046,\n",
            "       0.00471282, 0.00628424, 0.00468254, 0.00441718, 0.0044167 ]), 'test_f1_weighted': array([0.88630491, 0.77225673, 0.86335404, 0.8625    , 0.84082687,\n",
            "       0.90890269, 0.86363636, 0.93178295, 0.78932745, 0.79069767]), 'test_precision': array([0.86956522, 0.75      , 0.9       , 0.94444444, 0.82608696,\n",
            "       0.875     , 0.86363636, 0.91304348, 0.76      , 0.77272727]), 'test_recall': array([0.90909091, 0.81818182, 0.81818182, 0.77272727, 0.86363636,\n",
            "       0.95454545, 0.86363636, 0.95454545, 0.86363636, 0.80952381])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM classifier  - SW Related"
      ],
      "metadata": {
        "id": "hfSG0lFYHY7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(TfidfVectorizer(), SVC(kernel='linear'))\n",
        "\n",
        "# scores = cross_validate(clf, data_x, data_y, scoring=['accuracy'], cv=5, return_train_score=False)\n",
        "scores = cross_validate(clf, x_train, y_train, scoring=['f1_weighted', 'precision' ,'recall'], cv=10)\n",
        "print(scores) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roZwB4PbHZC4",
        "outputId": "f2bd1712-f51a-4953-a1a5-83518ebf63b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.0382185 , 0.02666497, 0.02651405, 0.02728724, 0.02744365,\n",
            "       0.02730799, 0.02668715, 0.02865553, 0.02593517, 0.02670622]), 'score_time': array([0.00903583, 0.0100565 , 0.01171947, 0.01016903, 0.00917363,\n",
            "       0.0093348 , 0.01080656, 0.00915313, 0.01110077, 0.00881553]), 'test_f1_weighted': array([0.90909091, 0.8858329 , 0.8625    , 0.83882784, 0.88630491,\n",
            "       0.88630491, 0.90909091, 0.93178295, 0.81334681, 0.74335413]), 'test_precision': array([0.90909091, 0.84      , 0.94444444, 0.94117647, 0.86956522,\n",
            "       0.86956522, 0.90909091, 0.91304348, 0.79166667, 0.70833333]), 'test_recall': array([0.90909091, 0.95454545, 0.77272727, 0.72727273, 0.90909091,\n",
            "       0.90909091, 0.90909091, 0.95454545, 0.86363636, 0.80952381])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Action"
      ],
      "metadata": {
        "id": "-orT2gBY3hl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All Requirements"
      ],
      "metadata": {
        "id": "R1mgHLAnLe87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(TfidfVectorizer(), MultinomialNB()) # svm.SVC(kernel='linear'))\n",
        "\n",
        "# scores = cross_validate(clf, data_x, data_y, scoring=['accuracy'], cv=5, return_train_score=False)\n",
        "scores = cross_validate(clf, x_train, y_train, scoring=['f1_weighted', 'precision' ,'recall'], cv=10)\n",
        "print(scores) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkKiNw_i3hvy",
        "outputId": "8510f91a-8f6f-4b23-8e18-a5c333cdb13b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.02472878, 0.0127039 , 0.01214981, 0.01222706, 0.01309323,\n",
            "       0.01463008, 0.01225138, 0.0302341 , 0.01725769, 0.0126667 ]), 'score_time': array([0.00922942, 0.00501919, 0.00536633, 0.00507951, 0.01011014,\n",
            "       0.00501537, 0.00542593, 0.01392102, 0.00509691, 0.00510025]), 'test_f1_weighted': array([0.91781971, 0.91781971, 0.90738213, 0.82114868, 0.89688552,\n",
            "       0.88632289, 0.88632289, 0.91781971, 0.89688552, 0.90738213]), 'test_precision': array([0.85964912, 0.85964912, 0.84482759, 0.74242424, 0.83050847,\n",
            "       0.81666667, 0.81666667, 0.85964912, 0.83050847, 0.84482759]), 'test_recall': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB classifier - SW Related"
      ],
      "metadata": {
        "id": "Jz9BPAyVKWQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(TfidfVectorizer(), MultinomialNB()) # svm.SVC(kernel='linear'))\n",
        "\n",
        "# scores = cross_validate(clf, data_x, data_y, scoring=['accuracy'], cv=5, return_train_score=False)\n",
        "scores = cross_validate(clf, x_train, y_train, scoring=['f1_weighted', 'precision' ,'recall'], cv=10)\n",
        "print(scores) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E2u3PpbKYFE",
        "outputId": "3dfa0755-4bcf-402b-d47f-482e8d04b2af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.02742696, 0.02068758, 0.01323771, 0.01296306, 0.01565671,\n",
            "       0.01529002, 0.02945971, 0.01277614, 0.0149374 , 0.01302958]), 'score_time': array([0.01512551, 0.00774908, 0.01286459, 0.01093554, 0.00978255,\n",
            "       0.00840616, 0.00952983, 0.00766659, 0.00933719, 0.0074892 ]), 'test_f1_weighted': array([0.97498437, 0.97498437, 0.87301587, 0.92457574, 0.92457574,\n",
            "       0.92457574, 1.        , 0.8989899 , 1.        , 0.97432517]), 'test_precision': array([0.95238095, 0.95238095, 0.8       , 0.86956522, 0.86956522,\n",
            "       0.86956522, 1.        , 0.83333333, 1.        , 0.95238095]), 'test_recall': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM classifier - SW Related"
      ],
      "metadata": {
        "id": "HNz8AyAkKZMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(TfidfVectorizer(), SVC(kernel='linear'))\n",
        "\n",
        "# scores = cross_validate(clf, data_x, data_y, scoring=['accuracy'], cv=5, return_train_score=False)\n",
        "scores = cross_validate(clf, x_train, y_train, scoring=['f1_weighted', 'precision' ,'recall'], cv=10)\n",
        "print(scores) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3_tQ5WcKaYz",
        "outputId": "586f73c6-9c38-4197-b0ec-663ffac9e7b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.01977134, 0.020823  , 0.01964808, 0.03770065, 0.0187757 ,\n",
            "       0.01894879, 0.02614117, 0.03451753, 0.01813149, 0.01856828]), 'score_time': array([0.00939775, 0.00978541, 0.00991416, 0.00983334, 0.00908208,\n",
            "       0.01068926, 0.01530719, 0.00862432, 0.00859737, 0.00738025]), 'test_f1_weighted': array([1.        , 1.        , 0.92457574, 0.97498437, 1.        ,\n",
            "       0.97498437, 1.        , 0.97498437, 0.97435897, 1.        ]), 'test_precision': array([1.        , 1.        , 0.86956522, 0.95238095, 1.        ,\n",
            "       0.95238095, 1.        , 0.95238095, 0.95      , 1.        ]), 'test_recall': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convention"
      ],
      "metadata": {
        "id": "QjLTmqSU4G9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All requirements\n"
      ],
      "metadata": {
        "id": "alhu30QcLkKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(TfidfVectorizer(), MultinomialNB()) # svm.SVC(kernel='linear'))\n",
        "\n",
        "# scores = cross_validate(clf, data_x, data_y, scoring=['accuracy'], cv=5, return_train_score=False)\n",
        "scores = cross_validate(clf, x_train, y_train, scoring=['f1_weighted', 'precision' ,'recall'], cv=10)\n",
        "print(scores) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zacai9tr4HFA",
        "outputId": "bbdb1dcf-62af-4b13-d275-46478e3dac32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.02019405, 0.01156139, 0.01158094, 0.01188731, 0.01155686,\n",
            "       0.01201034, 0.01197195, 0.01206708, 0.01615453, 0.01201701]), 'score_time': array([0.00513315, 0.00483274, 0.00539303, 0.00492597, 0.00518584,\n",
            "       0.00531602, 0.00475192, 0.01734781, 0.00534773, 0.00491619]), 'test_f1_weighted': array([0.88800398, 0.91040319, 0.88800398, 0.87764182, 0.87703391,\n",
            "       0.89988877, 0.89939138, 0.91071429, 0.84185736, 0.87574615]), 'test_precision': array([0.83018868, 0.8490566 , 0.83018868, 0.85416667, 0.82692308,\n",
            "       0.875     , 0.84615385, 0.8627451 , 0.80392157, 0.82352941]), 'test_recall': array([0.97777778, 1.        , 0.97777778, 0.91111111, 0.95555556,\n",
            "       0.93333333, 0.97777778, 0.97777778, 0.91111111, 0.95454545])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB Classifier - SW Related"
      ],
      "metadata": {
        "id": "iHcFETsPLBII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(TfidfVectorizer(), MultinomialNB()) # svm.SVC(kernel='linear'))\n",
        "\n",
        "# scores = cross_validate(clf, data_x, data_y, scoring=['accuracy'], cv=5, return_train_score=False)\n",
        "scores = cross_validate(clf, x_train, y_train, scoring=['f1_weighted', 'precision' ,'recall'], cv=10)\n",
        "print(scores) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea433NZQLCQm",
        "outputId": "6f2c1a07-0f44-4372-9992-f90ba0b13823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.01424479, 0.00822806, 0.00749469, 0.0077765 , 0.00783563,\n",
            "       0.00699306, 0.00755167, 0.00769854, 0.00684118, 0.00754333]), 'score_time': array([0.00489569, 0.00492764, 0.00445199, 0.0055387 , 0.00596499,\n",
            "       0.0048573 , 0.00486541, 0.00469017, 0.0048418 , 0.00561762]), 'test_f1_weighted': array([0.875     , 0.81176471, 0.90541872, 0.90541872, 0.9372549 ,\n",
            "       0.90615836, 0.81176471, 0.9372549 , 0.86934128, 0.87069892]), 'test_precision': array([0.875     , 0.77777778, 0.84210526, 0.84210526, 0.88888889,\n",
            "       0.88235294, 0.77777778, 0.88888889, 0.78947368, 0.92857143]), 'test_recall': array([0.875 , 0.875 , 1.    , 1.    , 1.    , 0.9375, 0.875 , 1.    ,\n",
            "       1.    , 0.8125])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM Classifier - SW Related"
      ],
      "metadata": {
        "id": "h71xT5WgLHQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(TfidfVectorizer(), SVC(kernel='linear'))\n",
        "\n",
        "# scores = cross_validate(clf, data_x, data_y, scoring=['accuracy'], cv=5, return_train_score=False)\n",
        "scores = cross_validate(clf, x_train, y_train, scoring=['f1_weighted', 'precision' ,'recall'], cv=10)\n",
        "print(scores) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGpj200MLGob",
        "outputId": "368fe1a6-ef75-4a07-d998-b0051232bd6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fit_time': array([0.01495552, 0.01225591, 0.0121181 , 0.01242709, 0.01251817,\n",
            "       0.01282024, 0.01257658, 0.0124495 , 0.0121932 , 0.01224017]), 'score_time': array([0.0050528 , 0.00505853, 0.00496864, 0.00501561, 0.00525951,\n",
            "       0.00498891, 0.00511169, 0.00496984, 0.00504541, 0.00485849]), 'test_f1_weighted': array([0.84359726, 0.84359726, 0.9372549 , 0.90615836, 1.        ,\n",
            "       0.87301587, 0.9372549 , 0.96871945, 0.96774194, 0.90261907]), 'test_precision': array([0.86666667, 0.86666667, 0.88888889, 0.88235294, 1.        ,\n",
            "       0.8       , 1.        , 0.94117647, 0.9375    , 1.        ]), 'test_recall': array([0.8125, 0.8125, 1.    , 0.9375, 1.    , 1.    , 0.875 , 1.    ,\n",
            "       1.    , 0.8125])}\n"
          ]
        }
      ]
    }
  ]
}