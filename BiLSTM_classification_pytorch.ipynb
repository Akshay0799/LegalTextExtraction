{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHK7PYIbtrgr"
      },
      "source": [
        "## IMPORTS "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6waH525HuQ40",
        "outputId": "45fc514b-b591-4f49-8bc8-208ab32b102f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmn-vJzityPq",
        "outputId": "baf460a0-74eb-464c-bf41-1912f89346ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/lstm\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgn2iuwqxVwx",
        "outputId": "e7d52e1d-cf01-40ed-fc82-af70b0ed2264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoints  embedding\tlegal_data.xlsx  SFCR-Akshay11.xlsx\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9j5EVDmz7B9F"
      },
      "outputs": [],
      "source": [
        "!unzip glove.840B.300d.txt.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yz5JX3jiunwZ"
      },
      "outputs": [],
      "source": [
        "!unzip drugs_train.zip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qjes83Xt_v1",
        "outputId": "2145d008-da5f-422b-81e0-130ad760a903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting aenum\n",
            "  Downloading aenum-3.1.11-py3-none-any.whl (131 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aenum\n",
            "Successfully installed aenum-3.1.11\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.1.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.4.46)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (23.0)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.9.3-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.6/210.6 KB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.9.1\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (6.0.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (5.10.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.9.3 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install aenum\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5pAV9TJtrg0",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "from aenum import Enum, extend_enum\n",
        "#import spacy\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "tqdm.pandas(desc='Progress')\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from nltk import word_tokenize\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "# from torch.autograd import Variable\n",
        "import os \n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "# cross validation and metrics\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# from multiprocessing import  Pool\n",
        "# from functools import partial\n",
        "# from sklearn.decomposition import PCA\n",
        "import torch as t\n",
        "import matplotlib.pyplot as plt\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "from aenum import Enum, extend_enum\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from tqdm.auto import tqdm\n",
        "tqdm.pandas(desc='Progress')\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from nltk import word_tokenize\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import os \n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "# cross validation and metrics\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch as t\n",
        "import matplotlib.pyplot as plt\n",
        "import optuna"
      ],
      "metadata": {
        "id": "6OTcOUHsyHQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NuWcUc_trg5"
      },
      "source": [
        "### Basic Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_otRngsatrg6",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "embed_size = 300 # how big is each word vector\n",
        "max_features = 12000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 750 # max number of words in a question to use\n",
        "batch_size = 16 # how many samples to process at once\n",
        "n_epochs = 5 # how many times to iterate over all samples\n",
        "n_splits = 5 # Number of K-fold Splits\n",
        "SEED = 10\n",
        "debug = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOzjvlWw39_d"
      },
      "source": [
        "### Optional Preprocessing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUfGv3-gtrhD",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "def clean_text(x):\n",
        "    pattern = r'[^a-zA-z0-9\\s]'\n",
        "    text = re.sub(pattern, '', x)\n",
        "    return x\n",
        "\n",
        "def clean_numbers(x):\n",
        "    if bool(re.search(r'\\d', x)):\n",
        "        x = re.sub('[0-9]{5,}', '#####', x)\n",
        "        x = re.sub('[0-9]{4}', '####', x)\n",
        "        x = re.sub('[0-9]{3}', '###', x)\n",
        "        x = re.sub('[0-9]{2}', '##', x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YSr7rNZ9trhD",
        "outputId": "098aacd8-4d89-44d2-dff4-9fa4fbca6df9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'this is a text with contraction'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "def _get_contractions(contraction_dict):\n",
        "    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
        "    return contraction_dict, contraction_re\n",
        "contractions, contractions_re = _get_contractions(contraction_dict)\n",
        "def replace_contractions(text):\n",
        "    def replace(match):\n",
        "        return contractions[match.group(0)]\n",
        "    return contractions_re.sub(replace, text)\n",
        "# Usage\n",
        "replace_contractions(\"this's a text with contraction\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MlG38uL1dZS"
      },
      "source": [
        "### Load Requirements Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XM5L99ep22kN"
      },
      "outputs": [],
      "source": [
        "class Config(dict):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "    \n",
        "    def set(self, key, val):\n",
        "        self[key] = val\n",
        "        setattr(self, key, val)\n",
        "\n",
        "class Fold(Enum):\n",
        "  No = 1\n",
        "  TenFold = 2\n",
        "  ProjFold = 3\n",
        "\n",
        "class Sampling(Enum):\n",
        "  NoSampling = 1\n",
        "  UnderSampling = 2\n",
        "  OverSampling = 3\n",
        "\n",
        "config = Config(\n",
        "    num_labels = 2, # will be set automatically afterwards\n",
        "    \n",
        "    epochs=16, # 10, 16, 32, 50\n",
        "    bs=16, # default: 16\n",
        "    \n",
        "    loss_func=nn.CrossEntropyLoss(),\n",
        "    seed=904727489, #default: 904727489, 42 (as in Dalpiaz) or None\n",
        "    \n",
        "    fold = Fold.No, # Fold.No, Fold.TenFold, Fold.ProjFold\n",
        "    sampling = Sampling.NoSampling, #Sampling.UnderSampling, Sampling.NoSampling, Sampling.OverSampling\n",
        ")\n",
        "\n",
        "# clazz = 'Measurement' # class to train classification on\n",
        "# clazz = 'Time Constraint'\n",
        "# clazz = 'Data Definition'\n",
        "clazz = 'Data Action'\n",
        "# clazz  = 'Convention'\n",
        "# clazz = 'Software Related'\n",
        "\n",
        "config_data = Config(\n",
        "    root_folder = '.', # where is the root folder? Keep it that way if you want to load from Google Drive\n",
        "    data_folder = '/', # where is the folder containing the datasets; relative to root\n",
        "    train_data = ['SFCR-Akshay.xlsx'], # dataset file to use\n",
        "    label_column = clazz,\n",
        "    # log_folder_name = '/log/',\n",
        "    # log_file = clazz + '_' + Fold(config.fold).name + '_' + Sampling(config.sampling).name + '_classifierPredictions_' +  '.txt', # log-file name (make sure log folder exists)\n",
        "    # result_file = clazz + '_' + Fold(config.fold).name + '_' + Sampling(config.sampling).name + '_classifierResults_' + '.txt', # result-file name (make sure log folder exists)\n",
        "    # model_path = '/models/', # where is the folder for the model(s); relative to the root\n",
        "    # model_name = 'NoRBERT.pkl', # what is the model name? \n",
        "    # gdrive_root_folder = '/content/drive/My Drive/Code/Task1_to_3_original_Promise_NFR_dataset/', # Set this to the Google Drive path. Starts with '/content/drive/' and then usually 'My Drive/*' for the files in your Drive\n",
        "\n",
        "    \n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data from the disk"
      ],
      "metadata": {
        "id": "TZQE81MtZNYX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yl7irlTrBcpV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "5e17d617-0a8d-4acd-e329-e64b16a6db0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Statement  \\\n",
              "0    198 The following definitions apply in this Part.   \n",
              "1    Canadian unit means a unit of measurement that...   \n",
              "2    metric unit means a unit of measurement that i...   \n",
              "3    199 (1) For the purposes of subsection 6(1) of...   \n",
              "4    or\\n\\n(b) any expression, word, number, depict...   \n",
              "..                                                 ...   \n",
              "596  The incoming eggs received can present a sourc...   \n",
              "597  When conducting the hazard analysis, identify ...   \n",
              "598  Information on general preventive controls tha...   \n",
              "599  Ensure the water used to wash eggs is a minimu...   \n",
              "600  In addition, the egg wash water:\\n\\ncontains a...   \n",
              "\n",
              "     Data Definition\\nFood attached  Data Action\\nNot Food attached  \\\n",
              "0                               NaN                             NaN   \n",
              "1                               NaN                             NaN   \n",
              "2                               NaN                             NaN   \n",
              "3                               NaN                             NaN   \n",
              "4                               NaN                             NaN   \n",
              "..                              ...                             ...   \n",
              "596                             NaN                             NaN   \n",
              "597                             NaN                             NaN   \n",
              "598                             NaN                             NaN   \n",
              "599                             NaN                             NaN   \n",
              "600                             NaN                             NaN   \n",
              "\n",
              "     Measurement  Time Constraint  Convention  \n",
              "0            NaN              NaN         NaN  \n",
              "1            NaN              NaN         NaN  \n",
              "2            NaN              NaN         NaN  \n",
              "3            NaN              NaN         NaN  \n",
              "4            NaN              NaN         NaN  \n",
              "..           ...              ...         ...  \n",
              "596          NaN              NaN         NaN  \n",
              "597          NaN              NaN         NaN  \n",
              "598          NaN              NaN         NaN  \n",
              "599          1.0              NaN         NaN  \n",
              "600          1.0              NaN         NaN  \n",
              "\n",
              "[601 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bcb6a1bb-b5d8-4e31-be3f-d5bce2868a06\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Statement</th>\n",
              "      <th>Data Definition\\nFood attached</th>\n",
              "      <th>Data Action\\nNot Food attached</th>\n",
              "      <th>Measurement</th>\n",
              "      <th>Time Constraint</th>\n",
              "      <th>Convention</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>198 The following definitions apply in this Part.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Canadian unit means a unit of measurement that...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metric unit means a unit of measurement that i...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>199 (1) For the purposes of subsection 6(1) of...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>or\\n\\n(b) any expression, word, number, depict...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>The incoming eggs received can present a sourc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>When conducting the hazard analysis, identify ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>Information on general preventive controls tha...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>Ensure the water used to wash eggs is a minimu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>In addition, the egg wash water:\\n\\ncontains a...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>601 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcb6a1bb-b5d8-4e31-be3f-d5bce2868a06')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bcb6a1bb-b5d8-4e31-be3f-d5bce2868a06 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bcb6a1bb-b5d8-4e31-be3f-d5bce2868a06');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        " def load_data(filename):\n",
        "    df = pd.read_excel(filename, sheet_name='Train data')#,names = ['Statement', 'Data Definition', 'Data Action', 'Measurement', 'Time Constraint', 'Convention'])\n",
        "    return df\n",
        "\n",
        "dafr = load_data('legal_data.xlsx')\n",
        "dafr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2b9QsFlrtmC",
        "outputId": "d0000006-516d-4c82-9de7-4e3ac8ebe65b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "601"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "len(dafr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2F7j7BkT67tT"
      },
      "outputs": [],
      "source": [
        "dafr.rename(columns = {'Data Definition\\nFood attached':'Data Definition'}, inplace = True)\n",
        "dafr.rename(columns = {'Data Action\\nNot Food attached':'Data Action'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHv2QwLRPhYP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a3a4c105-0579-41a4-ef53-3e2cdfbd531a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Statement  \\\n",
              "0  198 The following definitions apply in this Part.   \n",
              "1  Canadian unit means a unit of measurement that...   \n",
              "2  metric unit means a unit of measurement that i...   \n",
              "3  199 (1) For the purposes of subsection 6(1) of...   \n",
              "4  or\\n\\n(b) any expression, word, number, depict...   \n",
              "\n",
              "   Data Definition\\nFood attached  Data Action\\nNot Food attached  \\\n",
              "0                             NaN                             NaN   \n",
              "1                             NaN                             NaN   \n",
              "2                             NaN                             NaN   \n",
              "3                             NaN                             NaN   \n",
              "4                             NaN                             NaN   \n",
              "\n",
              "   Measurement  Time Constraint  Convention  \n",
              "0          NaN              NaN         NaN  \n",
              "1          NaN              NaN         NaN  \n",
              "2          NaN              NaN         NaN  \n",
              "3          NaN              NaN         NaN  \n",
              "4          NaN              NaN         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6c8346c-099d-4b8f-91ec-8594434cc5b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Statement</th>\n",
              "      <th>Data Definition\\nFood attached</th>\n",
              "      <th>Data Action\\nNot Food attached</th>\n",
              "      <th>Measurement</th>\n",
              "      <th>Time Constraint</th>\n",
              "      <th>Convention</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>198 The following definitions apply in this Part.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Canadian unit means a unit of measurement that...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metric unit means a unit of measurement that i...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>199 (1) For the purposes of subsection 6(1) of...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>or\\n\\n(b) any expression, word, number, depict...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6c8346c-099d-4b8f-91ec-8594434cc5b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6c8346c-099d-4b8f-91ec-8594434cc5b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6c8346c-099d-4b8f-91ec-8594434cc5b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "dafr.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryEPiU36PpKO"
      },
      "outputs": [],
      "source": [
        "# data = pd.concat([dafr])[['Statement','Measurement']]\n",
        "# data = pd.concat([dafr])[['Statement','Time Constraint']]\n",
        "# data = pd.concat([dafr])[['Statement','Data Definition']]\n",
        "data = pd.concat([dafr])[['Statement','Data Action']]\n",
        "# data = pd.concat([dafr])[['Statement','Convention']]\n",
        "# data = pd.concat([dafr])[['Statement','Software Related']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpxAt5KbSRez"
      },
      "outputs": [],
      "source": [
        "# data['Measurement'] = data['Measurement'].fillna(0)\n",
        "# data['Time Constraint'] = data['Time Constraint'].fillna(0)\n",
        "# data['Data Definition'] = data['Data Definition'].fillna(0)\n",
        "data['Data Action'] = data['Data Action'].fillna(0)\n",
        "# data['Convention'] = data['Convention'].fillna(0)\n",
        "# data['Software Related'] = data['Software Related'].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGz-n_fMPVT6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "84f7ae3c-276f-49b6-c36e-7f6d8776ea9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Statement  Data Action\n",
              "0  198 The following definitions apply in this Part.          0.0\n",
              "1  Canadian unit means a unit of measurement that...          0.0\n",
              "2  metric unit means a unit of measurement that i...          0.0\n",
              "3  199 (1) For the purposes of subsection 6(1) of...          0.0\n",
              "4  or\\n\\n(b) any expression, word, number, depict...          0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b1c9c69-2a2f-40c0-a2c0-cad5d4ca8e4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Statement</th>\n",
              "      <th>Data Action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>198 The following definitions apply in this Part.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Canadian unit means a unit of measurement that...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>metric unit means a unit of measurement that i...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>199 (1) For the purposes of subsection 6(1) of...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>or\\n\\n(b) any expression, word, number, depict...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b1c9c69-2a2f-40c0-a2c0-cad5d4ca8e4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b1c9c69-2a2f-40c0-a2c0-cad5d4ca8e4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b1c9c69-2a2f-40c0-a2c0-cad5d4ca8e4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKDzfweDRuz4"
      },
      "outputs": [],
      "source": [
        "data = data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXlLo04KpOcb",
        "outputId": "40c03448-6e7e-472e-d4a5-88630bda3e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "599"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating test set"
      ],
      "metadata": {
        "id": "nOK8Xga_tTGR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnfxSt7qfwns"
      },
      "outputs": [],
      "source": [
        "def split_dataframe(df, train_size = 0.8, random_state = 42):\n",
        "    # split data into training and validation set\n",
        "    df_trn, df_valid = train_test_split(df, stratify = df[config_data.label_column], train_size = train_size, random_state = random_state)\n",
        "    # apply sample strategy\n",
        "    sizeOne = sum(df_trn[config_data.label_column] == 1)\n",
        "    sizeZero = sum(df_trn[config_data.label_column] == 0)\n",
        "    major_label = 0\n",
        "    minor_label = 1\n",
        "    if sizeOne > sizeZero:\n",
        "      major_label = 1\n",
        "      minor_label = 0\n",
        "    if config.sampling == Sampling.UnderSampling:\n",
        "      df_trn = undersample(df_trn, major_label, minor_label)\n",
        "    elif config.sampling == Sampling.OverSampling:\n",
        "      df_trn = oversample(df_trn, major_label, minor_label)\n",
        "    return df_trn, df_valid\n",
        "\n",
        "data, sep_test = split_dataframe(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqQorvqhg56g",
        "outputId": "9a5da8ee-15fe-4378-ef2e-6455a0b17215"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "len(sep_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wdR_e1ivLAD",
        "outputId": "e54fdce8-2958-43a5-9a51-788f2c6d1284"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "419"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional - Don't have to do preprocessing"
      ],
      "metadata": {
        "id": "tPALOS5WwLnx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VB7pvoFQh8o"
      },
      "outputs": [],
      "source": [
        "# lower the text\n",
        "data[\"Statement\"] = data[\"Statement\"].apply(lambda x: x.lower())\n",
        "\n",
        "# Clean the text\n",
        "data[\"Statement\"] = data[\"Statement\"].apply(lambda x: clean_text(x))\n",
        "\n",
        "# # Clean numbers\n",
        "# data[\"Statement\"] = data[\"Statement\"].apply(lambda x: clean_numbers(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XD95E86yYj2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMDtvtGpaDni"
      },
      "source": [
        "### Get the Number of instances in each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJWR-GBm1tYY",
        "outputId": "0c309d84-7e6b-4132-fd54-acb51d381882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(479, 2)\n",
            "0.0    460\n",
            "1.0     19\n",
            "Name: Data Action, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# df = load_all_data(config_data.train_data)\n",
        "# input_col = 'RequirementText'\n",
        "# shuffle the dataset a bit and get the amount of classes\n",
        "df = data\n",
        "df = df.sample(frac=1, axis=0, random_state = config.seed)\n",
        "config.num_labels = df[config_data.label_column].nunique()\n",
        "\n",
        "print(df.shape)\n",
        "print(df[config_data.label_column].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGblJuPu1zB-",
        "outputId": "52366f90-679f-4714-c101-096d56ee20a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'not_Data Action', 1: 'Data Action'}\n"
          ]
        }
      ],
      "source": [
        "def create_label_indices(df):\n",
        "    #prepare label\n",
        "    labels = ['not_' + config_data.label_column, config_data.label_column]\n",
        "  \n",
        "    #create dict\n",
        "    labelDict = dict()\n",
        "    for i in range (0, len(labels)):\n",
        "        labelDict[i] = labels[i]\n",
        "    return labelDict\n",
        "\n",
        "label_indices = create_label_indices(df)\n",
        "print(label_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkhL2ZjyZ6_m"
      },
      "source": [
        "### Oversampling/UnderSampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjH13Q2L1zH5"
      },
      "outputs": [],
      "source": [
        "def undersample(df_trn, major_label, minor_label):\n",
        "  sample_size = sum(df_trn[config_data.label_column] == minor_label)\n",
        "  majority_indices = df_trn[df_trn[config_data.label_column] == major_label].index\n",
        "  random_indices = np.random.choice(majority_indices, sample_size, replace=False)\n",
        "  sample = df_trn.loc[random_indices]\n",
        "  sample = sample.append(df_trn[df_trn[config_data.label_column] == minor_label])\n",
        "  df_trn = sample\n",
        "  df_trn = df_trn.sample(frac=1, axis=0, random_state = config.seed)\n",
        "  print(df_trn[config_data.label_column].value_counts())\n",
        "  return df_trn\n",
        "\n",
        "def oversample(df_trn, major_label, minor_label):\n",
        "  minor_size = sum(df_trn[config_data.label_column] == minor_label)\n",
        "  major_size = sum(df_trn[config_data.label_column] == major_label)\n",
        "  multiplier = major_size//minor_size\n",
        "  sample = df_trn\n",
        "  minority_indices = df_trn[df_trn[config_data.label_column] == minor_label].index\n",
        "  diff = major_size - (multiplier * minor_size)     \n",
        "  random_indices = np.random.choice(minority_indices, diff, replace=False)\n",
        "  sample = pd.concat([df_trn.loc[random_indices], sample], ignore_index=True)\n",
        "  for i in range(multiplier - 1):\n",
        "    sample = pd.concat([sample, df_trn[df_trn[config_data.label_column] == minor_label]], ignore_index=True)\n",
        "  df_trn = sample\n",
        "  df_trn = df_trn.sample(frac=1, axis=0, random_state = config.seed)\n",
        "  print(df_trn[config_data.label_column].value_counts())\n",
        "  return df_trn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-AnFIcPwXrY",
        "outputId": "914e2ffa-05e5-46ee-d775-7e6a91f2d635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0    460\n",
            "1.0    460\n",
            "Name: Data Action, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "ov = oversample(df, 0.0, 1.0 )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Data Action']"
      ],
      "metadata": {
        "id": "XHve0AX8TRpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Validation set"
      ],
      "metadata": {
        "id": "mmEQSPBwtXYT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVtu7taX7Knv"
      },
      "outputs": [],
      "source": [
        "def split_dataframe(df, train_size = 0.8, random_state = 42):\n",
        "    # split data into training and validation set\n",
        "    df_trn, df_valid = train_test_split(df, stratify = df[config_data.label_column], train_size = train_size, random_state = random_state)\n",
        "    # apply sample strategy\n",
        "    sizeOne = sum(df_trn[config_data.label_column] == 1)\n",
        "    sizeZero = sum(df_trn[config_data.label_column] == 0)\n",
        "    major_label = 0\n",
        "    minor_label = 1\n",
        "    if sizeOne > sizeZero:\n",
        "      major_label = 1\n",
        "      minor_label = 0\n",
        "    if config.sampling == Sampling.UnderSampling:\n",
        "      df_trn = undersample(df_trn, major_label, minor_label)\n",
        "    elif config.sampling == Sampling.OverSampling:\n",
        "      df_trn = oversample(df_trn, major_label, minor_label)\n",
        "    return df_trn, df_valid\n",
        "\n",
        "train, test = split_dataframe(ov)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_train = ov.reset_index(drop=True) # Contains full training data, to be used after hyper parameter tuning\n",
        "\n",
        "train = train.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)\n",
        "sep_test = sep_test.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "9viXSvL1XO3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-smDNWMD2Sqe"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVJrnb3qrwc9",
        "outputId": "2b126ea5-7159-4f81-f283-cdab0d5b6547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of training data after oversampling: 686\n",
            "Length of validation data after oversampling: 172\n"
          ]
        }
      ],
      "source": [
        "print(\"Length of training data after oversampling:\",len(train))\n",
        "print(\"Length of validation data after oversampling:\",len(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ_7Gh9DRGsg"
      },
      "outputs": [],
      "source": [
        "# ov=df\n",
        "ov = ov.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToqWtEv3jw3z"
      },
      "outputs": [],
      "source": [
        "# x_data = ov['Statement']\n",
        "# y_data = ov['Measurement']\n",
        "# y_data = ov['Time Constraint']\n",
        "# y_data = ov['Data Definition']\n",
        "# y_data = ov['Data Action']\n",
        "# y_data = ov['Convention']\n",
        "# y_data = ov['Software Related']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assigning training , test and validation datasets to variables"
      ],
      "metadata": {
        "id": "eLSv5x7MA5YY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4v-HBM9R2Pie"
      },
      "outputs": [],
      "source": [
        "full_train_X = full_train['Statement'] # Full train to be used only after hyper parameter tuning\n",
        "# full_train_Y = full_train['Measurement']\n",
        "# full_train_Y = full_train['Time Constraint']\n",
        "# full_train_Y = full_train['Data Definition']\n",
        "full_train_Y = full_train['Data Action']\n",
        "# full_train_Y = full_train['Convention']\n",
        "\n",
        "train_X = train['Statement']\n",
        "# train_Y = train['Measurement']\n",
        "# train_Y = train['Data Definition']\n",
        "train_Y = train['Data Action']\n",
        "# train_Y = train['Convention']\n",
        "# train_Y = train['Time Constraint']\n",
        "\n",
        "val_X = test['Statement']\n",
        "# val_Y = test['Measurement']\n",
        "# val_Y = test['Data Definition']\n",
        "val_Y = test['Data Action']\n",
        "# val_Y = test['Convention']\n",
        "# val_Y = test['Time Constraint']\n",
        "\n",
        "test_X = sep_test['Statement']\n",
        "# test_Y = sep_test['Measurement']\n",
        "# test_Y = sep_test['Data Definition']\n",
        "test_Y = sep_test['Data Action']\n",
        "# test_Y = sep_test['Convention']\n",
        "# test_Y = sep_test['Time Constraint']\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L4XPd6DHskkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqkKi34m3qsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4a0dde2-dc4b-445b-b937-4f006406bf0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    (b) any person who only sells fresh fruits or ...\n",
              "1    and\\n\\n(b) the statement referred to in sectio...\n",
              "2    (b) fish that is in a hermetically sealed pack...\n",
              "3    and\\n\\n(d) in the case of skim milk powder tha...\n",
              "4    138 (1) Within 24 hours before the slaughter o...\n",
              "Name: Statement, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "train_X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing the initial training, validation ,test data for hyper parameter tuning"
      ],
      "metadata": {
        "id": "kEdXX_j-BJQ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOf-fvF511GT"
      },
      "outputs": [],
      "source": [
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(train_X))\n",
        "train_X = tokenizer.texts_to_sequences(train_X)\n",
        "val_X = tokenizer.texts_to_sequences(val_X)\n",
        "test_X = tokenizer.texts_to_sequences(test_X)\n",
        "\n",
        "## Pad the sentences \n",
        "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
        "test_X = pad_sequences(test_X, maxlen=maxlen)\n",
        "val_X = pad_sequences(val_X, maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FBxK9b6ONNvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing the full training data"
      ],
      "metadata": {
        "id": "W8wqG2ZyBHEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(full_train_X))\n",
        "full_train_X = tokenizer.texts_to_sequences(full_train_X)\n",
        "\n",
        "test_X = tokenizer.texts_to_sequences(test_X)\n",
        "\n",
        "## Pad the sentences \n",
        "full_train_X = pad_sequences(full_train_X, maxlen=maxlen)\n",
        "test_X = pad_sequences(test_X, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "I9eiySaTZVuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding labels for initial train, val and test data for hyper parameter tuning"
      ],
      "metadata": {
        "id": "IR1WrhiiBWM9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2MXjZli11GT"
      },
      "outputs": [],
      "source": [
        "\n",
        "le = LabelEncoder()\n",
        "train_Y = le.fit_transform(train_Y.values)\n",
        "test_Y = le.transform(test_Y.values)\n",
        "val_Y = le.transform(val_Y.values)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding the labels for full training data"
      ],
      "metadata": {
        "id": "oF6pK_h-BTcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(full_train_X))\n",
        "full_train_X = tokenizer.texts_to_sequences(full_train_X)\n",
        "\n",
        "test_X = tokenizer.texts_to_sequences(test_X)\n",
        "\n",
        "## Pad the sentences \n",
        "full_train_X = pad_sequences(full_train_X, maxlen=maxlen)\n",
        "test_X = pad_sequences(test_X, maxlen=maxlen)\n",
        "\n",
        "le = LabelEncoder()\n",
        "full_train_Y = le.fit_transform(full_train_Y.values)\n",
        "test_Y = le.transform(test_Y.values)\n"
      ],
      "metadata": {
        "id": "UZQ9qqhCZy5l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "f2ac868d-488e-4d3b-96a1-38a92ddc2218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-401fee065153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Tokenize the sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_train_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfull_train_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_train_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/preprocessing/text.py\u001b[0m in \u001b[0;36mfit_on_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m           seq = text_to_word_sequence(\n\u001b[0m\u001b[1;32m    280\u001b[0m               text, filters=self.filters, lower=self.lower, split=self.split)\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/preprocessing/text.py\u001b[0m in \u001b[0;36mtext_to_word_sequence\u001b[0;34m(input_text, filters, lower, split)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mtranslate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds6Gd0Zq11GT",
        "outputId": "634188d7-c238-44b5-d41f-2a6e0d5f3662"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "le.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STkPsVVkDmtj",
        "outputId": "68a04bab-cb82-484a-cdb8-37a7fbd17161"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_Y[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dZrbR9uD3FK",
        "outputId": "78d037b8-a947-4651-93b4-4e2c527a3e6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1.0\n",
              "1    0.0\n",
              "2    0.0\n",
              "3    0.0\n",
              "4    0.0\n",
              "Name: Measurement, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "sep_test['Measurement'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPaJDgvCtrhG"
      },
      "source": [
        "### Load Glove Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQCDb9HttrhG"
      },
      "outputs": [],
      "source": [
        "## FUNCTIONS TAKEN FROM https://www.kaggle.com/gmhost/gru-capsule\n",
        "\n",
        "def load_glove(word_index):\n",
        "    EMBEDDING_FILE = 'embedding/glove.840B.300d.txt'\n",
        "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')[:300]\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
        "    \n",
        "    all_embs = np.stack(embeddings_index.values())\n",
        "    emb_mean,emb_std = -0.005838499,0.48782197\n",
        "    embed_size = all_embs.shape[1]\n",
        "\n",
        "    nb_words = min(max_features, len(word_index)+1)\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features: continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None: \n",
        "            embedding_matrix[i] = embedding_vector\n",
        "        else:\n",
        "            embedding_vector = embeddings_index.get(word.capitalize())\n",
        "            if embedding_vector is not None: \n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load glove embeddings for the corresponding tokenizer"
      ],
      "metadata": {
        "id": "7ucAIQ_fBe4K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fA7xGtttrhH",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36c09d69-7b2e-434a-dc16-93516da62429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "# missing entries in the embedding are set using np.random.normal so we have to seed here too\n",
        "\n",
        "if debug:\n",
        "    embedding_matrix = np.random.randn(12000,300)\n",
        "else:\n",
        "    embedding_matrix = load_glove(tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dFVtXPKIrvOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig5X8bNytrhH",
        "outputId": "28ae4989-064b-4fac-a04c-734593d6a2fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1585, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "np.shape(embedding_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhfIhhgftrhH"
      },
      "source": [
        "## Pytorch Model - TextCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvVpoCV2trhH"
      },
      "outputs": [],
      "source": [
        "class CNN_Text(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(CNN_Text, self).__init__()\n",
        "        filter_sizes = [1,2,3,5]\n",
        "        num_filters = 36\n",
        "        n_classes = len(le.classes_)\n",
        "        self.embedding = nn.Embedding(max_features, embed_size)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        self.convs1 = nn.ModuleList([nn.Conv2d(1, num_filters, (K, embed_size)) for K in filter_sizes])\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc1 = nn.Linear(len(filter_sizes)*num_filters, n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)  \n",
        "        x = x.unsqueeze(1)  \n",
        "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1] \n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  \n",
        "        x = torch.cat(x, 1)\n",
        "        x = self.dropout(x)  \n",
        "        logit = self.fc1(x) \n",
        "        return logit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpngGWcitrhI"
      },
      "source": [
        "## Train TextCNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXXN8C6LtrhI",
        "outputId": "6fefe563-a7bc-4339-891b-a615a5ebd56c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:48: UserWarning:\n",
            "\n",
            "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6 \t loss=491.8629 \t val_loss=248.0509  \t val_acc=0.8373  \t time=34.86s\n",
            "Epoch 2/6 \t loss=231.9668 \t val_loss=208.5181  \t val_acc=0.8582  \t time=33.89s\n",
            "Epoch 3/6 \t loss=202.0433 \t val_loss=193.2557  \t val_acc=0.8662  \t time=33.83s\n",
            "Epoch 4/6 \t loss=182.8388 \t val_loss=183.2768  \t val_acc=0.8732  \t time=34.06s\n",
            "Epoch 5/6 \t loss=168.6442 \t val_loss=177.2318  \t val_acc=0.8772  \t time=33.86s\n",
            "Epoch 6/6 \t loss=156.3984 \t val_loss=169.1364  \t val_acc=0.8803  \t time=33.89s\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 6\n",
        "model = CNN_Text()\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
        "model.cuda()\n",
        "\n",
        "# Load train and test in CUDA Memory\n",
        "x_train = torch.tensor(train_X, dtype=torch.long).cuda()\n",
        "y_train = torch.tensor(train_y, dtype=torch.long).cuda()\n",
        "x_cv = torch.tensor(test_X, dtype=torch.long).cuda()\n",
        "y_cv = torch.tensor(test_y, dtype=torch.long).cuda()\n",
        "\n",
        "# Create Torch datasets\n",
        "train = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "valid = torch.utils.data.TensorDataset(x_cv, y_cv)\n",
        "\n",
        "# Create Data Loaders\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    start_time = time.time()\n",
        "    # Set model to train configuration\n",
        "    model.train()\n",
        "    avg_loss = 0.  \n",
        "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
        "        # Predict/Forward Pass\n",
        "        y_pred = model(x_batch)\n",
        "        # Compute loss\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        avg_loss += loss.item() / len(train_loader)\n",
        "    \n",
        "    # Set model to validation configuration -Doesn't get trained here\n",
        "    model.eval()        \n",
        "    avg_val_loss = 0.\n",
        "    val_preds = np.zeros((len(x_cv),len(le.classes_)))\n",
        "    \n",
        "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "        y_pred = model(x_batch).detach()\n",
        "        avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
        "        # keep/store predictions\n",
        "        val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
        "    \n",
        "    # Check Accuracy\n",
        "    val_accuracy = sum(val_preds.argmax(axis=1)==test_y)/len(test_y)\n",
        "    train_loss.append(avg_loss)\n",
        "    valid_loss.append(avg_val_loss)\n",
        "    elapsed_time = time.time() - start_time \n",
        "    print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f}  \\t val_acc={:.4f}  \\t time={:.2f}s'.format(\n",
        "                epoch + 1, n_epochs, avg_loss, avg_val_loss, val_accuracy, elapsed_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-08_2_eFtrhI",
        "outputId": "624b5cab-f9d1-42ec-fa52-4a69ca36864f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:360: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type CNN_Text. It won't be checked for correctness upon loading.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "torch.save(model,'textcnn_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFeirxvntrhI"
      },
      "outputs": [],
      "source": [
        "def plot_graph(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Train/Validation Loss\")\n",
        "    plt.plot(list(np.arange(epochs) + 1) , train_loss, label='train')\n",
        "    plt.plot(list(np.arange(epochs) + 1), valid_loss, label='validation')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('loss', fontsize=12)\n",
        "    plt.legend(loc='best')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5cr1iQBtrhJ",
        "outputId": "28f5b440-118f-4860-f81b-26edb7edc3d5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAALMCAYAAADaYRW1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xl8XHd97//3Z7Rai7XMcRzvsnVMFieO7XiLZoBsN4UESGgDuBC2R0hogFugvSXAr/cH3Au/0lsKuYGSNmFpaENCfoawNeECJQEkx3bsLM7iBEle5V2SJcuWZW3f+8ccGcV2bC0zc2Z5PR8PPTxz5pwz71Hyx9vHn/kec84JAAAAQHJFwg4AAAAA5CKKNgAAAJACFG0AAAAgBSjaAAAAQApQtAEAAIAUoGgDAAAAKUDRBgAAAFKAog0ASWZmBWZ21MzmhvDe15rZjlHPXzGz149l3wm817fM7LMTPR4Ach1FG0DeC0rxyM+wmR0f9fw94z2fc27IOVfhnNs1jgxvMLPfmVmzmb3vDK//tZmtn0CWC5xzvx/vcWd4/w+Z2ROnnPtDzrn/b7LnPsN7fdHM/jXZ5wWAdCsMOwAAhM05VzHyOLjC+yHn3K9fa38zK3TODSY5xvWSHpVUJOl9kr53yuvvlfQvSX5PAEAKcUUbAM4huML6AzN70Mx6JN1iZleY2Xoz6zKzfWZ2t5kVBfsXmpkzs7rg+b8Hrz9mZj1m9qSZzT/lbUaK9vckXWlms0e9/6WSLpT0g+D5h8xsa3CuVjP70Fmyt5nZlcHjMjP7NzM7bGYvSrr8lH3/1sy2Bed90czeNur9vyHp9cFV/vZRn+vzo47/CzNrMbMOM/uxmc045ffx4eD1w2Z29/j+K5x8j0Vm9tvg9/68md0w6rW3jPq9tJnZJ4Pt55nZo8ExnWb2u4m8NwCMF0UbAMbm7ZK+L6lKicI7KOnjkjxJMUlvkvThsxz/bkn/XVKtpF2S/ufIC0GprnbObXHO7ZT0e0m3jDr2fZJ+7pzrDJ4fkHSDpKmSbpP0dTNbPIbP8D8kzZG0QIli//5TXv9D8FmqJH1J0vfNbLpz7nlJH5P0+2Akxjv1xGZ2XXD+myXNkrRX0gOn7Ha9EuV+qRJ/Wbl2DJlHv0expJ9L+g9J0yR9UtIPzMwPdvmupFudc5WSFkv6bbD9byRtC445X4n/DgCQchRtABibRufcz5xzw8654865p5xzG5xzg865bZLulfTGsxy/1jm3yTk3oEQBXTLqtRskPTbq+f1KlGuZWUSJkn7/yItBjm0u4TeS/lPSGb/weIp3Svqic+5wUOi/MfpF59zDzrl9wWf8vqQdkpaP4byS9B5J33LOPeuc65P0aUlvHH1lXtLfOee6nXM7JD2hV/8OxiImqVjSPzjnBoLxnsckrQleH5B0sZlVOuc6nXNPj9o+U9Jc51y/c+63p50ZAFKAog0AY7N79BMzu9DM/sPM9pvZESWu5p52pXeU/aMe90qqGPV8ZGxkxFpJc81suaRrlZjbPlnEgxGJDcEYRJek687x3iNmnPI5dp7ymT5gZs8FIxZdSoyrjOW8UqLInjyfc+6IpMNKXN0ecbbfwVjfY5dzzo3atnPUe7xd0tsk7TKzJ8xsVbD9y8F+/xmM2vzNON8XACaEog0AY+NOef4vkl6Q5Dvnpkr6fyXZeE9qZiVKXKk9+eVL59xRST9S4qr2eyV9f+TLl2Y2RYki/neSpjvnqiX9cozvvV+J0ZERJ5cfNLMFku6RdIekaHDel0ed99TPf6q9kuaNOl+lpBpJe8aQa6z2SppjZqM/69yR9wj+heFtks5TYsTkoWD7EefcJ51zdZJuknSnmZ3tXx8AICko2gAwMZWSuiUdM7OLdPb57LN5o6SnnXPHTtl+v6Q/V+Iq7f2jtpcoMT5xSNKQmb1F0jVjfK+HJX3WzKotscb3x0a9VqFEmT4kyYIvWF446vUDkmaPfOHzDB6UdKuZLQ7+8vB3Ssx0t40x26kKzKx01E+JpHVKzMb/tZkVmdnVSvxrwMNmNsXM3m1mU4PxnB5JQ0p8mLeaWX1Q0LuD7UMTzAUAY0bRBoCJ+WslvkzYo8TV7R9M8Dynjo2MeFyJ8YrtzrlnRjY657qU+BLgI5I6lfjy4c/H+F6fk7RPidnrxzRqCUHn3BZJd0vaGOxzoaQNo479laRmSQfMbPQIyMjxv1BifOaR4Pi5SsxtT9Qtko6P+nnFOXdC0lsl3SipPcj7bufcH4Jj3i9pZzDKc6sS/xogSRdI+o2ko5KaJP1v51zjJLIBwJjYq0fdAADpZGZ/kPSWUWURAJAjuKINACExs1JJ36ZkA0Bu4oo2AAAAkAJc0QYAAABSoDDsAMnieZ6rq6sLOwYAAABy3ObNm9udc9POtV/OFO26ujpt2rQp7BgAAADIcWa289x7MToCAAAApARFGwAAAEgBijYAAACQAjkzow0AAJDPBgYG1NbWpr6+vrCj5IzS0lLNnj1bRUVFEzqeog0AAJAD2traVFlZqbq6OplZ2HGynnNOHR0damtr0/z58yd0DkZHAAAAckBfX5+i0SglO0nMTNFodFL/QkDRBgAAyBGU7OSa7O+Tog0AAACkAEUbAAAASdHV1aVvfvOb4z7u+uuvV1dXVwoShYuiDQAAgKR4raI9NDR01uMeffRRVVdXpypWaNJWtM1sh5k9b2bPmtmmYFutmf3KzJqDP2uC7WZmd5tZi5ltMbNl6coJAACAifn0pz+t1tZWLVmyRCtWrNBVV12ld7/73br00kslSTfddJMuv/xyLVq0SPfee+/J4+rq6tTe3q4dO3booosu0m233aZFixbpuuuu0/Hjx8P6OJOW7uX9rnLOtY96/mlJ/+mc+7KZfTp4fqekN0taGPysknRP8CcAAADO4Qs/e1Ev7T2S1HNePHOqPvfWRWfd58tf/rJeeOEFPfvss3riiSd0ww036IUXXji5PN53vvMd1dbW6vjx41qxYoX+7M/+TNFo9FXnaG5u1oMPPqj77rtP73znO/XDH/5Qt9xyS1I/S7qEPTpyo6T7g8f3S7pp1PbvuYT1kqrNbEYYAQEAADAxK1eufNUa1Hfffbcuu+wyrV69Wrt371Zzc/Npx8yfP19LliyRJF1++eXasWNHuuImXTqvaDtJvzQzJ+lfnHP3SprunNsnSc65fWZ2XrDvLEm7Rx3bFmzbl8a8AAAAWelcV57Tpby8/OTjJ554Qr/+9a/15JNPqqysTFdeeeUZ16guKSk5+bigoIDRkTGKOef2BmX6V2b28ln2PdOihe60ncxul3S7JM2dOzc5KQEAADAhlZWV6unpOeNr3d3dqqmpUVlZmV5++WWtX78+zenSL21F2zm3N/jzoJk9ImmlpANmNiO4mj1D0sFg9zZJc0YdPlvS3jOc815J90rS8uXLTyviAAAASJ9oNKpYLKZLLrlEU6ZM0fTp00++9qY3vUn//M//rMWLF+uCCy7Q6tWrQ0yaHuZc6vupmZVLijjneoLHv5L0PyRdI6lj1Jcha51znzKzGyR9TNL1SnwJ8m7n3Mqzvcfy5cvdpk2bUvtBAAAAMtTWrVt10UUXhR0j55zp92pmm51zy891bLquaE+X9EhwG8tCSd93zv3CzJ6S9LCZ3Sppl6R3BPs/qkTJbpHUK+mDacoJAAAAJEVairZzbpuky86wvUOJq9qnbneSPpqGaAAAAEBKhL28HwAAAJCTKNoAAABAClC0AQAAgBSgaAMAAAApQNEGAABAKCoqKiRJe/fu1c0333zGfa688kqdawnnu+66S729vSefX3/99erq6kpe0AmiaAMAACBUM2fO1Nq1ayd8/KlF+9FHH1V1dXUyok0KRRsAAABJceedd+qb3/zmyeef//zn9YUvfEHXXHONli1bpksvvVQ/+clPTjtux44duuSSSyRJx48f15o1a7R48WK9613v0vHjx0/ud8cdd2j58uVatGiRPve5z0mS7r77bu3du1dXXXWVrrrqKklSXV2d2tvbJUlf/epXdckll+iSSy7RXXfddfL9LrroIt12221atGiRrrvuule9T7Kk7RbsAAAASJPHPi3tfz655zz/UunNXz7rLmvWrNEnPvEJfeQjH5EkPfzww/rFL36hT37yk5o6dara29u1evVqve1tb1NwI8PT3HPPPSorK9OWLVu0ZcsWLVu27ORrX/rSl1RbW6uhoSFdc8012rJli/7yL/9SX/3qV/X444/L87xXnWvz5s367ne/qw0bNsg5p1WrVumNb3yjampq1NzcrAcffFD33Xef3vnOd+qHP/yhbrnllkn+kl6NK9qTsL+7T59a+5ye3R3+DBAAAEDYli5dqoMHD2rv3r167rnnVFNToxkzZuizn/2sFi9erGuvvVZ79uzRgQMHXvMcv/vd704W3sWLF2vx4sUnX3v44Ye1bNkyLV26VC+++KJeeumls+ZpbGzU29/+dpWXl6uiokJ/+qd/qt///veSpPnz52vJkiWSpMsvv1w7duyY5Kc/HVe0J6GspEBrN7fp/KmlWjIn/DkgAAAASee88pxKN998s9auXav9+/drzZo1euCBB3To0CFt3rxZRUVFqqurU19f31nPcaar3du3b9dXvvIVPfXUU6qpqdEHPvCBc54ncbPxMyspKTn5uKCgICWjI1zRnoSppUVaPLtajS3tYUcBAADICGvWrNFDDz2ktWvX6uabb1Z3d7fOO+88FRUV6fHHH9fOnTvPevwb3vAGPfDAA5KkF154QVu2bJEkHTlyROXl5aqqqtKBAwf02GOPnTymsrJSPT09ZzzXj3/8Y/X29urYsWN65JFH9PrXvz6Jn/bsuKI9SXHf0z2/bVVP34AqS4vCjgMAABCqRYsWqaenR7NmzdKMGTP0nve8R29961u1fPlyLVmyRBdeeOFZj7/jjjv0wQ9+UIsXL9aSJUu0cuVKSdJll12mpUuXatGiRVqwYIFisdjJY26//Xa9+c1v1owZM/T444+f3L5s2TJ94AMfOHmOD33oQ1q6dGlKxkTOxM52ST2bLF++3J1rjcVUeLK1Q39+33p9633Lde3F09P+/gAAAJK0detWXXTRRWHHyDln+r2a2Wbn3PJzHcvoyCQtm1et0qII4yMAAAB4FYr2JJUUFmjl/KiaKNoAAAAYhaKdBHE/quaDR3XgyNm/+QoAAJBKuTISnCkm+/ukaCdBQ31icXSuagMAgLCUlpaqo6ODsp0kzjl1dHSotLR0wudg1ZEkuHjGVNWUFamppUN/umx22HEAAEAemj17ttra2nTo0KGwo+SM0tJSzZ498W5H0U6CSMTU4HtqammXc+41bykKAACQKkVFRZo/f37YMTAKoyNJEvc97T/Sp9ZDx8KOAgAAgAxA0U6SuM+cNgAAAP6Iop0kc2rLNLe2jPW0AQAAIIminVQx39P61g4NDg2HHQUAAAAho2gnUcyPqufEoLbs6Q47CgAAAEJG0U6ikfW01zE+AgAAkPco2klUW16sRTOnMqcNAAAAinayxX1PT+/sUm//YNhRAAAAECKKdpLFfE/9Q8N6asfhsKMAAAAgRBTtJFtRV6viggjraQMAAOQ5inaSTSku0LJ51WpspmgDAADkM4p2CsR9Ty/tO6LOY/1hRwEAAEBIKNopEAtux76ulavaAAAA+YqinQKXzqpSZWkhc9oAAAB5jKKdAoUFEV2xIMp62gAAAHmMop0i8YWednce166O3rCjAAAAIAQU7RQZuR07V7UBAADyE0U7Reqnlev8qaVq4guRAAAAeYminSJmppjvaV1Lu4aHXdhxAAAAkGYU7RSKL4zqcO+AXtp3JOwoAAAASDOKdgrFgjltlvkDAADIPxTtFDpvaqleN72CL0QCAADkIYp2ijXUe3pqR6dODA6FHQUAAABpRNFOsbjvqW9gWE/v7Ao7CgAAANKIop1iqxbUqiBizGkDAADkGYp2ilWWFmnJnGrmtAEAAPIMRTsNYr6nLW1d6j4+EHYUAAAApAlFOw3ivqdhJ63f1hF2FAAAAKQJRTsNlsyp1pSiAua0AQAA8ghFOw2KCyNataCWOW0AAIA8QtFOk7jvaduhY9rXfTzsKAAAAEgDinaaxPyR27Ezpw0AAJAPKNppcsH0SnkVxcxpAwAA5AmKdppEIqaGek+NLe1yzoUdBwAAAClG0U6jmB/VoZ4Taj54NOwoAAAASDGKdhqNzGk3NjM+AgAAkOso2mk0u6ZMddEyrWulaAMAAOQ6inaaxXxP67d1amBoOOwoAAAASCGKdprFfU9HTwxqS1tX2FEAAACQQhTtNLuiPiozqbGZ9bQBAAByGUU7zarLinXprCrW0wYAAMhxFO0QNNR7enrXYR07MRh2FAAAAKQIRTsEcd/T4LDTxh2dYUcBAABAilC0Q7C8rkbFhRE1sZ42AABAzqJoh6C0qEAr6mrUyJw2AABAzqJohyTme3p5f48O9ZwIOwoAAABSgKIdknhwO3buEgkAAJCbKNohWTSzSlNLC1nmDwAAIEdRtENSEDE11HtqaumQcy7sOAAAAEgyinaIYgs97ek6rp0dvWFHAQAAQJJRtEM0MqfN6iMAAAC5h6IdorpomWZVT2FOGwAAIAdRtENkZor5Ua1r7dDQMHPaAAAAuYSiHbKY76n7+IBe3NsddhQAAAAkEUU7ZA31zGkDAADkIop2yKZVlujC8yu1rqUj7CgAAABIIop2Boj5njbu6FTfwFDYUQAAAJAkFO0MEPc99Q8Oa/POw2FHAQAAQJJQtDPAyvm1KowYc9oAAAA5hKKdAcpLCrV0bjXraQMAAOQQinaGiPment/Tra7e/rCjAAAAIAnSWrTNrMDMnjGznwfP/9XMtpvZs8HPkmC7mdndZtZiZlvMbFk6c4Yh7ntyTlq/jdVHAAAAckG6r2h/XNLWU7b9jXNuSfDzbLDtzZIWBj+3S7onjRlDcdmcapUXFzCnDQAAkCPSVrTNbLakGyR9awy73yjpey5hvaRqM5uR0oAhKyqIaPWCqJpYTxsAACAnpPOK9l2SPiVp+JTtXwrGQ75mZiXBtlmSdo/apy3Y9ipmdruZbTKzTYcOHUpJ6HSK+Z62tx9T2+HesKMAAABgktJStM3sLZIOOuc2n/LSZyRdKGmFpFpJd44ccobTuNM2OHevc265c275tGnTkhk5FDE/cTt27hIJAACQ/dJ1RTsm6W1mtkPSQ5KuNrN/d87tC8ZDTkj6rqSVwf5tkuaMOn62pL1pyhqa102vkFdRwpw2AABADkhL0XbOfcY5N9s5VydpjaTfOOduGZm7NjOTdJOkF4JDfirpfcHqI6sldTvn9qUja5jMTHE/qnWt7XLutAv4AAAAyCJhr6P9gJk9L+l5SZ6kLwbbH5W0TVKLpPskfSSceOkX8z21H+3XKwd6wo4CAACASShM9xs6556Q9ETw+OrX2MdJ+mj6UmWOkTntxuZ2XXj+1JDTAAAAYKLCvqKNU8ysnqIF08q5HTsAAECWo2hnoFi9pw3bO9U/eOpKiAAAAMgWFO0MFPM99fYP6dndXWFHAQAAwARRtDPQFQuiipgYHwEAAMhiFO0MVFVWpEtnV1O0AQAAshhFO0PF/aie2d2lnr6BsKMAAABgAijaGSrmexoadtq4vTPsKAAAAJgAinaGWja3RqVFEW7HDgAAkKUo2hmqtKhAK+pqmdMGAADIUhTtDBbzPf3hwFEd7OkLOwoAAADGiaKdweLB7djXtXSEnAQAAADjRdHOYBfPmKrqsiLmtAEAALIQRTuDRSKmWL2nppZ2OefCjgMAAIBxoGhnuJjvaV93n7a1Hws7CgAAAMaBop3hYn5UErdjBwAAyDYU7Qw3t7ZMs2umqLGZog0AAJBNKNoZzswU9z09ua1DQ8PMaQMAAGQLinYWiPmeevoG9fye7rCjAAAAYIwo2lmgoZ45bQAAgGxD0c4C0YoSXTxjKnPaAAAAWYSinSViflSbdx7W8f6hsKMAAABgDCjaWSLme+ofGtZTOzrDjgIAAIAxoGhniZXza1VUYGpqZXwEAAAgG1C0s0RZcaGWza3hC5EAAABZgqKdReK+pxf3HlHnsf6wowAAAOAcKNpZJLbQk3PSk60dYUcBAADAOVC0s8jiWVWqLClUI+MjAAAAGY+inUUKCyJatSDKnDYAAEAWoGhnmbgf1a7OXu3u7A07CgAAAM6Cop1l4gs9SdyOHQAAINNRtLNM/bQKTZ9awpw2AABAhqNoZxkzU8z3tK61Q8PDLuw4AAAAeA0U7SwUq/fUeaxfW/cfCTsKAAAAXgNFOwvFfOa0AQAAMh1FOwudX1Uq/7wKNbVw4xoAAIBMRdHOUnHf08btnToxOBR2FAAAAJwBRTtLxXxPxweG9MyurrCjAAAA4Awo2llq1YJaFUSMOW0AAIAMRdHOUlNLi7R4dhXraQMAAGQoinYWi/uentvdpSN9A2FHAQAAwCko2lks5nsadtL6VlYfAQAAyDQU7Sy2dG61phQVaB1FGwAAIONQtLNYSWGBVs6vZU4bAAAgA1G0s1zc99Ry8Kj2d/eFHQUAAACjULSzHLdjBwAAyEwU7Sx34fmVqi0vpmgDAABkGIp2lotETA31UTW2tMs5F3YcAAAABCjaOSDuezrYc0Kth46GHQUAAAABinYOGJnTbmxmfAQAACBTULRzwJzaMs2LlqmxhfW0AQAAMgVFO0fEfE/rt3VocGg47CgAAAAQRTtnxOo9HT0xqOfausOOAgAAAFG0c8YV9VGZsZ42AABApqBo54ja8mItmjmVog0AAJAhKNo5JOZ7enrXYfX2D4YdBQAAIO9RtHNI3Pc0MOS0cXtn2FEAAADyHkU7h6yoq1VxYYTxEQAAgAxA0c4hpUUFunxuDetpAwAAZACKdo6JL/S0dd8RtR89EXYUAACAvEbRzjEjt2N/spWr2gAAAGGiaOeYS2dVqbK0kDltAACAkFG0c0xBxNRQH9Xvm9vlnAs7DgAAQN6iaOeguO9pT9dx7ersDTsKAABA3qJo56CGYE67kfERAACA0FC0c9ACr1wzqkqZ0wYAAAgRRTsHmZlivqd1rR0aHmZOGwAAIAwU7RwV9z119Q7opX1Hwo4CAACQlyjaOarBj0piThsAACAsFO0cdV5lqS6YXsmcNgAAQEgo2jmswY9q4/ZO9Q0MhR0FAAAg71C0c1jc93RicFhP7zwcdhQAAIC8Q9HOYasWRFUQMea0AQAAQkDRzmEVJYVaOqdaTa0dYUcBAADIOxTtHBfzPT3f1qXu3oGwowAAAOQVinaOiy/0NOykJ7dxVRsAACCdKNo57rLZ1SorLmCZPwAAgDSjaOe44sKIVs2vpWgDAACkGUU7D8R8T9vaj2lv1/GwowAAAOQNinYeiC/0JImr2gAAAGmU1qJtZgVm9oyZ/Tx4Pt/MNphZs5n9wMyKg+0lwfOW4PW6dObMNRdMr5RXUUzRBgAASKN0X9H+uKSto57/vaSvOecWSjos6dZg+62SDjvnfElfC/bDBJmZYr6nxpYOOefCjgMAAJAX0la0zWy2pBskfSt4bpKulrQ22OV+STcFj28Mnit4/Zpgf0xQzPfUfvSE/nDgaNhRAAAA8kI6r2jfJelTkoaD51FJXc65weB5m6RZweNZknZLUvB6d7A/JijmJ+a0uR07AABAeqSlaJvZWyQddM5tHr35DLu6Mbw2+ry3m9kmM9t06NChJCTNXbOqp2i+V86cNgAAQJqk64p2TNLbzGyHpIeUGBm5S1K1mRUG+8yWtDd43CZpjiQFr1dJ6jz1pM65e51zy51zy6dNm5baT5ADYn5UG7Z1aGBo+Nw7AwAAYFLSUrSdc59xzs12ztVJWiPpN86590h6XNLNwW7vl/ST4PFPg+cKXv+N41t8kxb3PR3rH9Jzu7vCjgIAAJDzwl5H+05Jf2VmLUrMYH872P5tSdFg+19J+nRI+XLKFQs8mTGnDQAAkA6F594luZxzT0h6Ini8TdLKM+zTJ+kdaQ2WB6rKirR4VpWaWtr1iWtfF3YcAACAnBb2FW2kWYPv6ZldXTp6YvDcOwMAAGDCKNp5Ju57Ghx22ri9I+woAAAAOY2inWcun1ejksKIGpsp2gAAAKlE0c4zpUUFWlFXq3WtfCESAAAglSjaeSjme3p5f48O9vSFHQUAACBnUbTzUDy4HfuTrYyPAAAApApFOw9dPHOqqqYUqbGZ8REAAIBUoWjnoYKIqaE+qqaWdnHDTQAAgNSgaOepmO9pb3eftrcfCzsKAABATqJo56mROe0m5rQBAABSgqKdp+ZFyzSreoqamNMGAABICYp2njIzxX1P61rbNTTMnDYAAECyUbTzWIMf1ZG+Qb2wpzvsKAAAADmHop3HGuoTc9qNLYyPAAAAJBtFO49NqyzRhedXqomiDQAAkHQU7TwX9z1t2nlYfQNDYUcBAADIKRTtPBdb6Kl/cFibdhwOOwoAAEBOoWjnuZV1tSoqMOa0AQAAkoyinefKSwq1dE4Nc9oAAABJRtGGYr6nF/Z26/Cx/rCjAAAA5AyKNhRfGJVz0pPbuB07AABAslC0ocWzq1VRUsj4CAAAQBJRtKGigohWL6ilaAMAACQRRRuSEnPaOzp6tbuzN+woAAAAOYGiDUmJoi1J61q5qg0AAJAMFG1IkhaeV6FplSVqbOELkQAAAMlA0YYkycwU9z2ta2nX8LALOw4AAEDWo2jjpJjvqeNYv17e3xN2FAAAgKxH0cZJMT8qiTltAACAZKBo46QZVVNUP61cjSzzBwAAMGkUbbxK3Pe0YVun+geHw44CAACQ1SjaeJUG39PxgSE9s+tw2FEAAACyGkUbr7J6QVQRE3eJBAAAmCSKNl6lakqRFs+uZk4bAABgkijaOE3c9/RcW7d6+gbCjgIAAJC1KNo4Tcz3NDTstGFbZ9hRAAAAshZFG6dZNq9apUURxkcAAAAmgaKN05QUFmhFXS1fiAQAAJgEijbOKO57aj54VAeO9IUdBQAAICtRtHFGMd+TxDJ/AAAAE0XRxhldPGOqasqK1NTSEXYUAACArETRxhlFIqYG31NTS7ucc2HHAQAAyDoUbbwx7cZQAAAgAElEQVSmuO9p/5E+tR46FnYUAACArEPRxmuK1TOnDQAAMFEUbbymudEyzamdwnraAAAAE0DRxlnFfU/rWzs0ODQcdhQAAICsQtHGWcV8Tz0nBvX8nu6wowAAAGQVijbOqoE5bQAAgAmhaOOsasuLtWjmVOa0AQAAxomijXOK+Z6e3tml3v7BsKMAAABkDYo2zinme+ofGtZTOw6HHQUAACBrULRxTivqalRcEGFOGwAAYBwo2jinsuJCLZtXTdEGAAAYB4o2xiTue3px7xF1HusPOwoAAEBWoGhjTGJ+Ypm/da1c1QYAABgLijbG5NJZVaosKWR8BAAAYIwo2hiTwoKIVtdHWU8bAABgjCjaGLO472l353Ht6ugNOwoAAEDGo2hjzEbmtLmqDQAAcG4UbYxZ/bRynT+1VE18IRIAAOCcKNoYMzNTzPe0rqVdw8Mu7DgAAAAZjaKNcYn5UR3uHdBL+46EHQUAACCjUbQxLiNz2izzBwAAcHYUbYzL9KmlWnheBV+IBAAAOAeKNsYt5nt6akenTgwOhR0FAAAgY1G0MW5x31PfwLCe3tkVdhQAAICMRdHGuK1aUKuCiDGnDQAAcBYUbYxbZWmRlsypZk4bAADgLCjamJBYfVRb2rrUfXwg7CgAAAAZiaKNCYn5noadtH5bR9hRAAAAMhJFGxOydG6NphQVMKcNAADwGijamJDiwohWLailaAMAALwGijYmLO57aj10TPu6j4cdBQAAIONQtDFhf7wdO3PaAAAAp6JoY8IumF6paHkx4yMAAABnQNHGhEUipgbfU2NLu5xzYccBAADIKBRtTErcj+pQzwk1HzwadhQAAICMQtHGpPxxTpvxEQAAgNEo2piU2TVlqouWUbQBAABOQdHGpMV8T+u3dWpgaDjsKAAAABkjLUXbzErNbKOZPWdmL5rZF4Lt/2pm283s2eBnSbDdzOxuM2sxsy1mtiwdOTExMd/T0ROD2tLWFXYUAACAjFGYpvc5Ielq59xRMyuS1GhmjwWv/Y1zbu0p+79Z0sLgZ5Wke4I/kYGuWBCVmdTY3KHL59WGHQcAACAjpOWKtksYWZaiKPg523pwN0r6XnDceknVZjYj1TkxMTXlxbpkZhVz2gAAAKOkbUbbzArM7FlJByX9yjm3IXjpS8F4yNfMrCTYNkvS7lGHtwXbTj3n7Wa2ycw2HTp0KKX5cXYx39PTuw7r2InBsKMAAABkhLQVbefckHNuiaTZklaa2SWSPiPpQkkrJNVKujPY3c50ijOc817n3HLn3PJp06alKDnGIu57Ghx22rijM+woAAAAGSHtq44457okPSHpTc65fcF4yAlJ35W0MtitTdKcUYfNlrQ3rUExLsvralRcGFFTM+MjAAAAUvpWHZlmZtXB4ymSrpX08sjctZmZpJskvRAc8lNJ7wtWH1ktqds5ty8dWTExpUUFWj6vRo3MaQMAAEhK3xXtGZIeN7Mtkp5SYkb755IeMLPnJT0vyZP0xWD/RyVtk9Qi6T5JH0lTTkxCzPf08v4eHeo5EXYUAACA0KVleT/n3BZJS8+w/erX2N9J+miqcyG54r6nf/g/r2hda7tuXHLad1cBAADyCneGRNJcMqtKU0sLWeYPAABAFG0kUUHE1FDvqamlQ4l/lAAAAMhfFG0kVWyhpz1dx7WzozfsKAAAAKGiaCOpYvVRSWL1EQAAkPco2kiq+V65ZlaVMqcNAADyHkUbSWVmivme1rV2aGiYOW0AAJC/KNpIuvhCT93HB/Ti3u6wowAAAISGoo2ka6j3JElNLR0hJwEAAAgPRRtJN62yRBeeX8mcNgAAyGsUbaREQ72njTs61TcwFHYUAACAUFC0kRLxhVH1Dw5r887DYUcBAAAIBUUbKbFyflSFEWM9bQAAkLco2kiJipJCLZ1bzZw2AADIWxRtpEzM9/T8nm519w6EHQUAACDtKNpImbjvyTnpyW1c1QYAAPmHoo2UuWxOtcqLC5jTBgAAeYmijZQpKoho1YIoN64BAAB5iaKNlIr5nra3H1Pb4d6wowAAAKQVRRspFfcTt2Nfx1VtAACQZyjaSKnXTa+QV1HCnDYAAMg7FG2klJkp7ke1rrVdzrmw4wAAAKQNRRspF/M9tR/t1ysHesKOAgAAkDYUbaRcLJjTbmxmfAQAAOQPijZSbmb1FC3wyrkdOwAAyCsUbaRFzPe0YXun+geHw44CAACQFhRtpEXM99TbP6Rnd3eFHQUAACAtKNpIiysWRBUxMT4CAADyBkUbaVFVVqRLZ1dTtAEAQN6gaCNtYvVRPbO7Sz19A2FHAQAASDmKNtIm7nsaGnbauL0z7CgAAAApR9FG2iybV6OSwgi3YwcAAHmBoo20KS0q0Mr5tcxpAwCAvDDmom1mV5nZ/ODxDDO738y+Y2bnpy4eck3M9/SHA0d1sKcv7CgAAAApNZ4r2t+UNBQ8/kdJRZKcpHuTHQq5Kx7cjn1dS0fISQAAAFKrcBz7znLO7TKzQkl/ImmepH5Je1OSDDnp4hlTVV1WpMaWdt20dFbYcQAAAFJmPEX7iJlNl3SJpJecc0fNrFiJK9vAmEQipob6qJpa2uWck5mFHQkAACAlxjM68nVJT0l6QNI/Bdtikl5OdijktpjvaV93n7a1Hws7CgAAQMqM+Yq2c+7vzewRSUPOudZg8x5JH0pJMuSskTntppZ21U+rCDkNAABAaoxreT/n3B9GSraZXSXpfOfc8ylJhpw1t7ZMs2umsMwfAADIaeNZ3u+3ZhYLHt8p6SFJD5rZZ1MVDrnJzBT3Pa1r7dDQsAs7DgAAQEqM54r2JZLWB49vk3SlpNWS/iLJmZAHGnxPPX2Den5Pd9hRAAAAUmI8RTsiyZlZvSRzzm11zu2WVJOaaMhlDfVRSWJ8BAAA5KzxFO1GSd+Q9BVJj0hSULppShg3r6JEF82YqsZm/vcBAAC5aTxF+wOSuiRtkfT5YNuFkv53ciMhX8T9qDbvPKzj/UPn3hkAACDLjLloO+c6nHOfdc59zjl3NNj2H865u1IXD7ks5nvqHxrWUzs6w44CAACQdONZdaTIzL5gZtvMrC/48wvB3SGBcVs5v1ZFBaamVsZHAABA7hnPLdj/l6SVSqwyslPSPEn/XdJUSZ9MfjTkurLiQi2dW8MXIgEAQE4az4z2OyS9zTn3S+fcK865X0p6u6R3piYa8kHc9/Ti3iPqPNYfdhQAAICkGk/RtnFuB84p5ntyTnqytSPsKAAAAEk1nqL9/0v6mZn9iZldZGZvkvTjYDswIZfNrlJFSaEaGR8BAAA5Zjwz2p+S9LeS/knSTEl7lLgN+/9MQS7kicKCiFYviDKnDQAAcs5Zi7aZXX3KpieCH5Pkgm1xSb9JdjDkj7gf1a+3HtDuzl7NqS0LOw4AAEBSnOuK9rdfY/tIyR4p3AuSlgh5J77Qk5S4HfualXNDTgMAAJAcZy3azrn56QqC/FU/rULnVZaokaINAAByyHi+DAmkhJkp7nta19qh4WF37gMAAACyAEUbGSHme+o81q+t+4+EHQUAACApKNrICDH/j3PaAAAAuYCijYxwflWp/PMq1NTCjWsAAEBuoGgjY8R9Txu3d+rE4FDYUQAAACaNoo2M0VAf1fGBIT2zqyvsKAAAAJNG0UbGWF0fVcSY0wYAALmBoo2MMbW0SJfNqVYjRRsAAOQAijYyStz39NzuLh3pGwg7CgAAwKRQtJFRYr6nYSdt2NYZdhQAAIBJoWgjoyydW60pRQXMaQMAgKxH0UZGKSks0Ir5tcxpAwCArEfRRsaJ+1G1HDyq/d19YUcBAACYMIo2Mg63YwcAALmAoo2Mc9H5U1VbXkzRBgAAWY2ijYwTiZga6qNqam2Xcy7sOAAAABNC0UZGivueDhw5odZDR8OOAgAAMCEUbWSkkTntxmbGRwAAQHaiaCMjzakt09zaMjW2dIQdBQAAYEIo2shYMd/T+m0dGhwaDjsKAADAuFG0kbHivqejJwb1XFt32FEAAADGjaKNjHVFfVRmrKcNAACyE0UbGau2vFiLZk6laAMAgKxE0UZGi9V7enrXYfX2D4YdBQAAYFwo2shoMd/TwJDTxu2dYUcBAAAYl7QUbTMrNbONZvacmb1oZl8Its83sw1m1mxmPzCz4mB7SfC8JXi9Lh05kXlW1NWquCDC+AgAAMg66bqifULS1c65yyQtkfQmM1st6e8lfc05t1DSYUm3BvvfKumwc86X9LVgP+ShKcUFunxeDetpAwCArJOWou0SRu6lXRT8OElXS1obbL9f0k3B4xuD5wpev8bMLB1ZkXniCz1t3XdE7UdPhB0FAABgzNI2o21mBWb2rKSDkn4lqVVSl3Nu5FtubZJmBY9nSdotScHr3ZKiZzjn7Wa2ycw2HTp0KNUfASEZuR37k61c1QYAANkjbUXbOTfknFsiabaklZIuOtNuwZ9nunrtTtvg3L3OueXOueXTpk1LXlhklEtnVamytJA5bQAAkFXSvuqIc65L0hOSVkuqNrPC4KXZkvYGj9skzZGk4PUqSSw7kacKIqYrFkT1++Z2OXfa37cAAAAyUrpWHZlmZtXB4ymSrpW0VdLjkm4Odnu/pJ8Ej38aPFfw+m8cDSuvxRd62tN1XLs6e8OOAgAAMCaF594lKWZIut/MCpQo9w87535uZi9JesjMvijpGUnfDvb/tqR/M7MWJa5kr0lTTmSokTntxpZ2zYuWh5wGAADg3NJStJ1zWyQtPcP2bUrMa5+6vU/SO9IQDVligVeuGVWlampp13tWzQs7DgAAwDlxZ0hkBTNTzPe0rrVDw8NMEQEAgMxH0UbWiPueunoH9NK+I2FHAQAAOCeKNrJGQ31iKfVGlvkDAABZgKKNrHHe1FK9bnoF62kDAICsQNFGVon5njZu71TfwFDYUQAAAM6Koo2sEvc9nRgc1tM7D4cdBQAA4Kwo2sgqqxZEVRAxNbUyPgIAADIbRRtZpaKkUEvnVKuxpSPsKAAAAGdF0UbWafA9Pd/Wpe7egbCjAAAAvCaKNrJO3Pc07KQnt3FVGwAAZC6KNrLOkjnVKisuYJk/AACQ0SjayDrFhRGtml9L0QYAABmNoo2sFPM9bWs/pr1dx8OOAgAAcEYUbWSl+EJPkriqDQAAMhZFG1npgumV8iqKKdoAACBjUbSRlcxMDfWeGls65JwLOw4AAMBpKNrIWnHfU/vRE/rDgaNhRwEAADgNRRtZKxbMaTcyPgIAADIQRRtZa1b1FM33ypnTBgAAGYmijawW86PasK1DA0PDYUcBAAB4FYo2slqs3tOx/iE9t7sr7CgAAACvQtFGVruiPioz5rQBAEDmoWgjq1WXFevSWVXMaQMAgIxD0UbWi/mentnVpaMnBsOOAgAAcBJFG1kv7nsaHHbauL0j7CgAAAAnUbSR9S6fV6OSwoiaWijaAAAgc1C0kfVKiwq0vK6GOW0AAJBRKNrICTHf08v7e3Swpy/sKAAAAJIo2sgRcT9xO/YnWxkfAQAAmYGijZywaGaVqqYUqbGZ8REAAJAZKNrICQURU0N9VE0t7XLOhR0HAACAoo3cEfM97e3u046O3rCjAAAAULSRO2LBnDa3YwcAAJmAoo2cURct06zqKWpiThsAAGQAijZyhpkp5ke1rrVdQ8PMaQMAgHBRtJFTYr6nI32DemFPd9hRAABAnqNoI6c01DOnDQAAMgNFGzllWmWJLjy/ktuxAwCA0FG0kXPivqdNOw+rb2Ao7CgAACCPUbSRc2K+p/7BYW3acTjsKAAAII9RtJFzVs6vVWHEmNMGAAChomgj55SXFGrZ3BrmtAEAQKgo2shJMd/TC3u7dfhYf9hRAABAnqJoIyfFF0blnPTkto6wowAAgDxF0UZOWjy7WhUlhYyPAACA0FC0kZOKCiJaNb+Wog0AAEJD0UbOivmednT0andnb9hRAABAHqJoI2fFFyZux76ulavaAAAg/SjayFkLz6vQtMoSNbbwhUgAAJB+FG3kLDNT3Pe0rqVdw8Mu7DgAACDPULSR02K+p45j/XrlQE/YUQAAQJ6haCOnxfyoJLH6CAAASDuKNnLajKopWjCtXI0UbQAAkGYUbeS8uO9pw7ZO9Q8Ohx0FAADkEYo2cl7M93R8YEjP7DocdhQAAJBHKNrIeasXRBUx5rQBAEB6UbSR86qmFGnx7Go1tbKeNgAASB+KNvJCzI/q2d1d6ukbCDsKAADIExRt5IWY72lo2GnDts6wowAAgDxB0UZeWDa3RqVFEZb5AwAAaUPRRl4oLSrQirpavhAJAADShqKNvBH3PTUfPKoDR/rCjgIAAPIARRt5I+Z7kljmDwAApAdFG3nj4hlTVVNWpKYWlvkDAACpR9FG3ohETA31nppa2uWcCzsOAADIcRRt5JWY72n/kT61HjoWdhQAAJDjKNrIK3HmtAEAQJpQtJFX5kbLNKd2CutpAwCAlKNoI+/EfU/rWzs0ODQcdhQAAJDDKNrIOw31nnpODOr5Pd1hRwEAADmMoo2801AflcScNgAASC2KNvJOtKJEF8+Yypw2AABIKYo28lJ8oaend3apt38w7CgAACBHUbSRl2K+p/6hYT2143DYUQAAQI6iaCMvrairUXFBhDltAACQMhRt5KWy4kItm1dN0QYAAClD0UbeitV7enHvEXUe6w87CgAAyEEUbeSt2MLE7djXtXJVGwAAJB9FG3lr8awqVZYUMj4CAABSIi1F28zmmNnjZrbVzF40s48H2z9vZnvM7Nng5/pRx3zGzFrM7BUz+5N05ER+KSyIaHV9lPW0AQBAShSm6X0GJf21c+5pM6uUtNnMfhW89jXn3FdG72xmF0taI2mRpJmSfm1mr3PODaUpL/JE3Pf0q5cOaFdHr+ZGy8KOAwAAckharmg75/Y5554OHvdI2ipp1lkOuVHSQ865E8657ZJaJK1MfVLkm5ifmNNuYk4bAAAkWdpntM2sTtJSSRuCTR8zsy1m9h0zqwm2zZK0e9RhbTp7MQcmpH5auaZPLWF8BAAAJF1ai7aZVUj6oaRPOOeOSLpHUr2kJZL2SfrHkV3PcLg7w/luN7NNZrbp0KFDKUqNXGZmivme1rW0a3j4tP/FAAAAJixtRdvMipQo2Q84534kSc65A865IefcsKT79MfxkDZJc0YdPlvS3lPP6Zy71zm33Dm3fNq0aan9AMhZcd/T4d4BvbTvSNhRAABADknXqiMm6duStjrnvjpq+4xRu71d0gvB459KWmNmJWY2X9JCSRvTkXVcBvulh98n7WgKOwkm4eScNuMjAAAgidJ1RTsm6b2Srj5lKb//ZWbPm9kWSVdJ+qQkOedelPSwpJck/ULSRzNyxZHDO6S2zdK/Xp8o3Id3hp0IEzB9aqkWnlfBnDYAAEiqtCzv55xr1Jnnrh89yzFfkvSllIVKhmmvkz72lLTu61LTXdIrv5AaPibF/0oqqQg7HcYh5nt66KldOjE4pJLCgrDjAACAHMCdISeruEy68k7pY5uki2+Ufv+P0tcvl579vjQ8HHY6jFHM99Q3MKynd3aFHQUAAOQIinayVM2S/uw+6dZfJx7/+A7pW9dIuzac+1iEbtWCWhVEjDltAACQNBTtZJuzIlG2336v1LNP+s510tpbpe62sJPhLKaWFumy2VXMaQMAgKShaKdCJCJd9i7pv26W3vAp6eWfS19fLj3+d1J/b9jp8BrivqctbV3qPj4QdhQAAJADKNqpVFwuXf3/JL4wecGbpd9+WfrGcmnLw5Lj5iiZJuZ7GnbS+m0dYUcBAAA5gKKdDtVzpXd8V/rgL6TyadKPbpO+/V8SSwMiYyydW6MpRQXMaQMAgKSgaKfTvCuk2x6XbvwnqWuX9K2rpR99WDpy2k0vEYLiwohWzq+laAMAgKSgaKdbJCItvSUxvx3/pPTijxLLAf72H6SB42Gny3tx31ProWPa181/CwAAMDkU7bCUVErXfl766EbJv0Z6/IvSN1ZKL/yI+e0Q/fF27MxpAwCAyaFoh612vvSuf5fe/3OptEpa+0Hpu9dLe58NO1leuvD8SkXLixkfAQAAk0bRzhTzXy99+LfSW+6S2v8g3Xul9JOPSj0Hwk6WVyIRU4PvqbGlXY5/WQAAAJNA0c4kkQJp+Qelv3xaaviY9NwPEvPbjV+TBk+EnS5vxP2oDvWcUPPBo2FHAQAAWYyinYlKq6Trvih9dEPiSvevPy/900pp68+Y306DhvqROW3GRwAAwMRRtDNZtF768wel9z4iFU6RfnCLdP9bpf0vhJ0sp82pLdO8aBlFGwAATApFOxvUXy39RaN0/VekAy9K//J66Wcfl45RBFMl5ntav61TA0PDYUcBAABZiqKdLQoKpZW3Jea3V35YeubfpbuXSuu+Lg32h50u58R9T0dPDGpLW1fYUQAAQJaiaGebKTXSm78s3fGkNGeV9Mu/lb65WnrlMea3k+iKBVGZSY3NrKcNAAAmhqKdraa9TrplrfSetYnVSh5cI/3b26WDW8NOlhNqyot1ycwq5rQBAMCEUbSz3cL/It2xTnrTl6W9T0v3xKT/+G9Sb2fYybJegx/VM7sP69iJwbCjAACALETRzgUFRdLqO6T/+kxiHe5N307Mb6//Z2loIOx0WSvuexoYctq4g7+0AACA8aNo55LyqHTDP0p/0STNXCL94s7EFe7mX4edLCutqKtVcWFETc2MjwAAgPGjaOei6RdL7/2x9OcPSf+3vfsOjvM67z3+PehEW/QOEGCnxC4WiZBI2ZZtubfIkbuozDiZOC7j5Lonsp3m3CRO7JvEN44tSrLlKls3LrEsy7ZIsYmkKLGJnQCJShSi990994/3xWIBgiRIYfHuAr/PzA6wuy+wz3JnxB+PnvOc4Ag8/i54/D5oO+N1ZTElJTGe9fOz2aU+bREREbkJCtqzlTGw9A3wp887p0xe3OdMJ3nqszDQ4XV1MaN6UR4nm3to7RnyuhQRERGJMQras11CEmz+KHz0EKx9P+z7Bnx9HRz4FgS0ye967lzkHMe+55xWtUVEROTGKGjPFen58JavwZ88B4W3wi//3Dlh8vyzXlcW1VaU+shMSWDPWc3TFhERkRujoD3XFK2ED/0c3v0dGO6Dx94G338vtJ/zurKoFB9nuGNhLrvOtmF1IJCIiIjcAAXtucgYuOWt8JH98JqHoGYH/PsmePovYbDb6+qizt1LC2joHOBd39jDzw83MhIIel2SiIiIxAAzW1bp1q9fbw8ePOh1GbGppxl++9fw0uOQlgev/kunnzsu3uvKokIgaHlsby2P7KnlQns/xb4UPnDHfN6zoYLstCSvyxMREZEZZox5wVq7/rrXKWhLSOOL8KvPQN0+p8Xk3n+Aymqvq4oagaDl9ydb2L6nht1n20lJjOMda0vZVl3FksIMr8sTERGRGaKgLTfHWjj+U/jNQ9BVB7e8DV77Zciu9LqyqHKyuZtHdtfy5IsNDPmD3Lkoj23VlbxqaQFxccbr8kRERCSCFLTllRkZgD3/B3b9CwQDcMdH4K5PQrJWbsNd7hvm+/sv8p29F2juHqQyN5UPba7kvvXlpCcneF2eiIiIRICCtkyPrgb47ZfgyA8hvdDZPLn6PRCnfbThRgJBfnWsme27a3jxYicZyQnct76cBzZXUpGb6nV5IiIiMo0UtGV61R2Apz4DDQehZC3c+xWouN3rqqLSS3WdbN9dwy+PNBGwlnuWF7KtupI7FuRijNpKREREYp2Ctky/YBCO/hie+SL0NMKKd8E9X4Kscq8ri0rNXYN8d98Fvrf/Ipf7hllWlMG26kretqaUlERNdBEREYlVCtoSOcN9sOtfYc/XAQPVH4Pqj0NSmteVRaXBkQA/e6mRh3fXcLK5h+zURN67qYIP3F5JkS/F6/JERETkBiloS+R1XnSmkxz/KWSUwGu/BCvvcw7EkStYa9l7vp3tu2t55sQl4o3hjSuL2VZdydqKbK/LExERkSlS0JaZc2Gv07/d9BKUbXDmb5fd5nVVUe1iez+P7q3lRwfq6Bnys7Yii23VVbxhRRGJ8dpoKiIiEs0UtGVmBYNw+PvOhJLeS7DqfrjnIcgs8bqyqNY75OeJg3U8sqeW2vZ+ijLdUyc3VpCjUydFRESikoK2eGOoB577Kuz9d+cI9zs/CZv/DBLneV1ZVAsGLc+ebuHhXbXsOttGcoJz6uQD1ZUsK8r0ujwREREJo6At3uqohaf/Ek78DHwVTv/2re9Q//YUnL7Uw/bdtTz5Yj2DI0E2L8xlW3UVr15WQLxOnRQREfGcgrZEh5rn4KnPwqWjUHEH3Pv3zhxuua6OvmF+cKCOx/bW0tQ1SEVOKg9sruS+9WVkpCR6XZ6IiMicpaAt0SMYgBe/A7/9a+hvhzXvg9f8FWQUel1ZTBgJBPn18Wa2767lhQsdpCcn8Ae3lfHA5koq8zRSUUREZKYpaEv0GeyCnf8I+/4vJCTDXX8Ot/8pJGqW9FQdHj118mgT/qDlNcsK2FZdxeaFOnVSRERkpihoS/RqPwdPfwFO/Q9kzYfX/Q0sf4v6t29AS7dz6uTjz1+kvW+YpYUZPFBdyTvW6tRJERGRSFPQluh37vdO/3brCai8y+nfLlrpdVUxZXAkwM8ON7J9dy0nmrrJSk3kvRsr+MAd8yn2adKLiIhIJChoS2wI+OGF7fD7v4PBTlj3QXjVFyA93+vKYoq1ludrLrN9dw2/efkSxhjesKKIB++sYp1OnRQREZlWCtoSWwY6YMf/hv3fhMRU2Pop2PjHkKBDW25U3eV+Ht1Tyw8P1tEz6Gd1eRYPVlfyhhXFJCXo1EkREZFXSkFbYlPraXj683DmachZCK//W1hyr/q3b0LfkJ+fHKrnkd21nG/royAjmQ+6p07mpid7XZ6IiEjMUtCW2HbmGfj1Z6HtNCx4lbdmSoMAACAASURBVNO/XbDc66piUjBo2XG6lYd31/DcmTaSEuJ4+5oStlVXsbxYp06KiIjcKAVtiX2BETjwbXj272CoF9Y/CK/6HKTmeF1ZzDpzqYfte2r56SHn1MnbF+SwrbqKe5YX6tRJERGRKVLQltmj/7KzWfLgw5CcAXd/Fjb8EcTrdMSb1dnvnjq5p5bGrkHKc+bxoTsqefeGcjJ16qSIiMg1KWjL7NNywhkHeP73kLcUXv93sPger6uKaf5AkKdfvsT23TUcqO0gLSme+9aX86HNlVTp1EkREZFJKWjL7GQtnH4Kfv15uHwOFr/OCdx5i72uLOYdre9i++4afn6kEX/Q8qqlBWyrruTORXk6dVJERCSMgrbMbv5h2P+fzkjAkX7Y+GFnJOA8zYx+pVp6Bvnuvot87/kLtPUOs7ggnW3VVbxjbSnzknTqpIiIiIK2zA29rfD7v4FDj0FKFrz687DuAYhP8LqymDfkD/Dzw01s313D8Ubn1Mn7N1TwwTvmU5KlUydFRGTuUtCWuaX5qNO/XfscFNzitJMsfJXXVc0K1lr211xm++5ann65GWMM995axIN3VrKuIlttJSIiMucoaMvcYy2c/AU8/QXoqIWlb4TX/Q3kLvS6slmj7nI/39l3gR/sv0j3oJ9VZT62VVfyppUlOnVSRETmDAVtmbtGBuH5b8DOfwL/ENz+J7Dlf0GKz+vKZo2+IT8/fbGB7btrON/aR35GMh+4fT7v3VRBnk6dFBGRWU5BW6TnEvzuy/Di45CWB6/+Aqz9AMRpQ990CQYtO8+0sn13LTtOt5IUH8db15SwrbqSW0v0DxsREZmdFLRFRjW+6PRvX9wLRSvh3q9A5Z1eVzXrnG3p5ZE9NfzkhQYGRgJsrMrhweoqXnuLTp0UEZHZRUFbJJy1cPxJ+M1fQVcdLH8rvO6vIbvS68pmna7+EX548CKP7rlAQ+cAZdljp0765unUSRERiX0K2iKTGRmAPf8Gu74KwQDc8RG465PO0e4yrfyBIM+cuMTDu2rZX3uZ1KR4/uC2Mh7YXMmC/HSvyxMREblpCtoi19LdCM98CY78ANIL4TUPwer3QJwmZ0TCsYYutu+u5eeHGxkOBLl7aT7bqqvYslinToqISOxR0BaZivqD8NRnoP4AlKx1+rcrbve6qlmrtWeIx5+/wHf3XaStd4iF+Wlsq67inetKSU3SIUMiIhIbFLRFpioYhGNPwG8egp5GWPEuuOdLkFXudWWz1pA/wC+PNPHw7hqONXSTmZLAezZW8MHNlZTq1EkREYlyCtoiN2q4D3Z/zbkBbP4Y3PkJSErztq5ZzFrLwQsdbN9dw1PHmgG4d0UR26qrWD9fp06KiEh0UtAWuVmddfDMQ3DsJ5BRAvd8EVbep/7tCKvv6Oc7ey/wfffUyRWlmTxYXcWbVhWTnKDZ5yIiEj0UtEVeqYv74FefhqaXoHg1LH49lG+E0tsgNcfr6mat/mE/Pz3UwCN7ajnb0kteejLvv72C922aT36GTp0UERHvKWiLTIdg0JlMsu8bcOkY2KDzeO5iJ3SXbXC+5i/TiZPTzFrLc2faeHh3Dc+eck6dfPPqYh6srmJFqU6dFBER7yhoi0y3oV7nlMn6/VB3wPna3+48l5QBpevGwnfZBq16T6Nzrb08uqeWJ16op384wMbKHLZVV/LaWwpJiFdLj4iIzCwFbZFIsxY6asZCd91+uHQcbMB5PncRlG2EsvVOAC+4Raver1DXwAg/OlDHo3trqe8YoDRrHh/aPJ8/XF+BL1WnToqIyMxQ0BbxwnCfs+pdt9+ZzV23H/rbnOeS0p1V77INbgDfAGm53tYbowJBy29evsT23TU8X3OZeYnxvOu2Uh7YXMWiAp06KSIikaWgLRINrIWOWid0jwbv5qNjq945C5zQXe6G74JbIF4Ht9yI443OqZM/e8k5dXLLkny2VVeydXE+cXEaDygiItNPQVskWg33u73eYeG7r8V5LjFtbNV7tN87Lc/bemNEW+8Q33v+It/Zd4HWniEW5KexbXMl71xXRlqy/vEiIiLTR0FbJFZYC50XnOPg6/Y7/d7NRyHod57Prhq/ybJwhVa9r2HYH+SXRxvZvruWI/VdZKQkcP+Gcj54RyXlOalelyciIrOAgrZILBvuh6bDY5ss6w9A7yXnucRUKFnntpu4LSfp+d7WG4WstRy62MHDu2t56lgz1lped0sR26or2ViVo1MnRUTkpiloi8wm1kJX3Vjorj8ATUcgOOI8n105FrrLR1e9NYVjVGPnAI+5p052DYxwa0km26qreMtqnTopIiI3TkFbZLYbGXBWvcPDd0+T81zCPChZO7bJsnwjpBd4W28UGBgO8OSLDWzfXcOZll7y0pN476b5vP/2CgoyUrwuT0REYoSCtshcYy101TvtJqP93k2Hx1a9syrGQnfZeihaNWdXva217DrbxvbdtfzuZAuJ8YY3ryrhfZsqWFuRTbymlYiIyDUoaIsIjAxC85GxTZZ1B6Cn0XkuIcVZ9R7dZFm+ETKKvK3XAzVtfTy6p5YfH6yjbziAb14idy7OY+vifLYsyafIp5VuEREZL6qCtjGmHHgMKAKCwDettV8zxuQAPwQqgVrg3dbaDuPsUvoa8EagH3jAWnvoWq+hoC0yRV0N44+RbzoMgWHnOV/F+E2WRSshIcnbemdI9+AIz55qZefpVnacbqW1ZwiApYUZbFmSx9YlBayvzCYlUT3dIiJzXbQF7WKg2Fp7yBiTAbwAvB14ALhsrf2KMeYzQLa19tPGmDcCH8UJ2puAr1lrN13rNRS0RW6Sf8jZWBmacHIQuuud5xJSoHjN2DHyZRshs9jbemeAtZaTzT2h0H2wtoPhQJCUxDhuX5DL1iXOaveCvDRNLxERmYOiKmhf8aLG/Dfwb+7tbmttkxvGn7XWLjXG/Kf7/ffd60+NXne136mgLTKNuhvHb7JsfAkCzgovmWXjN1kWrYSEZG/rjbC+IT/7zrez83QrO8+0UdPWB0BZ9jy2LMlny+J8qhflkpEyN3veRUTmmqgN2saYSmAnsAK4aK3NCnuuw1qbbYz5BfAVa+0u9/HfAp+21h6c8Ls+DHwYoKKi4rYLFy7MzJsQmWv8Q84hOuHhu6vOeS4+GYpXjz9Ux1fqbb0RdrG9nx1nWtlxqpW959roGw6QEGdYV5HN1qVO8L61JFNHwIuIzFJRGbSNMenADuBvrbU/NcZ0XiVo/xL4+wlB+1PW2heu9ru1oi0yw7qb3AknB5x+78YXw1a9S8cfI1+8etaueg/7gxy62MGO005/9/HGbgBy05K4a3EeW5bkc9fifPIzZuf7FxGZi6IuaBtjEoFfAL+21n7VfSzUEqLWEZEY5x92Vr3rD4xttuy66DwXn+SE7fAJJ74yb+uNkNaeIZ4744Tu58600d7nbDS9tSSTLUvy2bokn3UV2SQlxHlcqYiI3KyoCtruFJFHcTY+fiLs8X8E2sM2Q+ZYaz9ljHkT8GeMbYb8urV247VeQ0FbJAr1NLsr3u7Kd+OL4B90nssoGb/Jsng1JM6uUXrBoOV4Yzc73TaTQxc78ActaUnxbF7krHZvXZxPRW6q16WKiMgNiLagfSfwHHAUZ7wfwOeA54EfARXAReA+a+1lN5j/G3Avzni/bRP7sydS0BaJAYGRsFVvN4B3unsr4hKheNXYMfJlG8BXDrNoqkfP4Ah7zrWH2kzqOwYAqMpLY4vbZnLHwlxSkxI8rlRERK4lqoL2TFDQFolRPZfGgnf9AWg4BH4ngJJeNDbhpGwDlKyBxHne1jtNrLWcb+tzJpmcbmXv+XYGR4IkxcexvjI7NEJwWVGGRgiKiEQZBW0RiU2BEbh0bOwY+fr90FHrPBeX6IwTDJ9wklUxK1a9B0cCHKztYMfpFnaebuPUpR4ACjKSnRGCS/K5a1Ee2Wlz4wAhEZFopqAtIrNHb4sTvEc3WTYegpF+57n0wvGbLEvWzopV76auAZ473caOM63sOtNG18AIxsCqsiy2Ls5j69J8VpdlkRCvTZUiIjNNQVtEZq+AH1qOj22yrNsPHTXOc3EJzqr36DHy5Rsga35Mr3oHgpbD9Z2hkyoP13UStJCZksCdi/PYsthZ8S7Jiv1/YIiIxAIFbRGZW/raxk84aTgEI84JjqQVuCvebvguWQtJsTvpo7N/mN1n20NtJs3dziSXxQXpoTaTTVU5pCTGe1ypiMjspKAtInNbwA8tL7uH6rj93pfPOc+ZeChaMbbJsnwDZFfF5Kq3tZbTl3rd4+Fbeb7mMsP+IMkJcWxakMvWJflsXZLHwvx0baoUEZkmCtoiIhP1tYdNONnvrHoP9zrPpeVD8RrIXQg5CyF3gfM1qwLiYmdleGA4wL6a9lCbyflWZ1W/xJcSOh5+86I8fPMSPa5URCR2KWiLiFxPMOCuervHyF86Cu3nx1pOwJl0kl0JuYvcEL5gLIxnlkJcdG9GrO/oZ+fpNnacbmHP2XZ6hvzExxnWlmeFTqpcWeojLk6r3SIiU6WgLSJyM6yF3kvQfs5pNQl9Pe98HT3ZEiAhxWk5mRjAcxdBRlHUtaKMBIK8eLEz1GZypL4LgOzURO5yN1RuWZxHQebsOqFTRGS6KWiLiEy3YBB6GieE8PPO144aCAyPXZuY5oZvtwUlFMIXOm0qURDC23uH2HW2jR2nWtl5po223iEAlhdnsmVJHlsX53NbZTbJCbHTOiMiMhMUtEVEZlIwAF31YwE8PIx3XoCgf+za5EzIqXJWvieG8NQcb8oPWk40d4eOh3/hQgcjAUtqUjx3LMgN9XdX5qV5Up+ISDRR0BYRiRYBvxO2R1e/w1tSOi+CDY5dm5I1PniHb8yclzVjJfcO+dl7bmxT5cXLzgFBFTmpoePh71iYS3pywozVJCISLRS0RURigX/YOWL+8rkrW1K66oGw/0an5l0ZvkfvJ6dHtMzatj52nmllx6lW9p5vp384QGK84bb52aFNlbcUZ2qEoIjMCQraIiKxbmTQ6f2+oif8LPQ0jb82vXAsgIe3pGRXTfvhPEP+AC/UdrDjTCs7T7dxoqkbgLz0ZKe3e0k+dy7KIzc9eVpfV0QkWihoi4jMZsN9E1pRzo+F8b6W8ddmlk6YiuJ+zamChFcehlu6B9l5po2dp1t57kwrHf0jGAMrS31sWZzP1qX5rCnPIjE+ukchiohMlYK2iMhcNdjthPDJNmYOXA670EBW+ZUbMnMWQvZ8iL/xQ20CQcuxhq5Qb/eLdZ0EgpaM5AQ2L8pl65ICtizJoyx7elfZRURmkoK2iIhcaaBj/Op3+NfBrrHrTLxzKuYVGzMXgq8c4qe2CbJrYIQ9Z9vY6baZNHQOALAgPy20qfL2qlzmJWmEoIjEDgVtERGZOmuhv32Sg3rcvvDRo+oh7LTMSTZmZpZd9bRMay3nWnvZcbqNHadbef58O0P+IEkJcWyqygm1mSwuSNemShGJagraIiIyPayF3pbJA3j7OfAPjF0bnxzWDz6hLzyjeNxBPYMjAfbXXA7N7j7T4oT5Yl8KW9yTKu9clIcv9cZbWEREIklBW0REIi8YdCagTHZc/eUaCAyNXZuY6oTviQE8dxGk5dPYNRg6Hv65M230DPqJM7CmPCs0QnBVWRbxcVrtFhFvKWiLiIi3ggHobhi/Cj76fUft+NMykzLGtaAEshZwJlDA71oz+fX5YY40dGEtZKUmUr3IGSG4dUk+hZkpnr09EZm7FLRFRCR6BfzQdXHyjZmdF8EGxq5N8eHPWkBzQinHh/LZddnH4f5cam0RxYVFoePh11dmk5KoTZUiEnkK2iIiEpv8w07Ybj97ZUtKVx3hp2V2x/k46y+gxhZRZ4pJLlhM6cIVrFy1jsqSQm2qFJGImGrQntp8JhERkZmSkAR5i5zbRCOD446sz7x8jtVtZ7ml5TQpA89BG87teWgjm560ChLzF5E//xaSCxc7rSm+UkjJGrcxU0QkEhS0RUQkdiSmQMEy5+aKd28M98Pl87ReeJm6c8fobzpFSnctFb2/Jbn2J+N+jY1LxKTlQ3o+pOVDWgGk5UF6gXvfvaUXQGruTR3eIyKioC0iIrNDUioUrSC/aAX5m94NwLA/yKGLHXzvRC3nTh0l2HaOInOZvLhuFgz1U0EfBX1NZARPkDjQhgmfkhJuXrYbxqcQzpPTZ/BNi0g0U4+2iIjMGW29Q7x0sZMj9Z0cru/iSH0nHf0jACTFG9YVJrCpMMDq7GGWZQxSFN9LXH8r9Lm33tHvW8afpBkuMdUJ4KPB/Gor5Wn5MC/nqgf8iEj00mZIERGR67DWUt8xwBE3dB+u7+RYQze9Q87owdSkeFaU+FhV5mNVeRarSn3Mz011Nln6h8cCeCiIt0y4H/Z9+CSVUSYOUkeDeN4kq+YTbokaZygSDRS0RUREbkIwaDnf1seR+k6O1HdxuL6Tlxu7GfIHAfDNS3SCd5mPVWVZrCrzUZSZcu0JJ8EgDHZeJYy3QF+bs0o+Gs5H+ib/PcmZYaviV2thce+n+LThUyRCFLRFRESmyUggyOlLPaGV7yP1XZxq7sEfdP4Ozc9IZrUbvFeW+VhdlkVOWtLNv+BwnxvE28KC+WggnxDO+y8TPvIwJD5prHXlev3lqXkQr21bIlOloC0iIhJBgyMBXm7q5khdJ0caujhS38W51l5G/1oty57Hajd4ryrzsbLUR0ZKBKaXBPzQ3z4+jF9r1TwwPPnvmZcTtip+nXCelDb970MkhmiOtoiISASlJMazriKbdRXZocd6Bkc41tDtrHo3OKvfvzzaBDhdHAvy0sLCdxa3lmS+8tMs4xMgo9C5XY+1MNQ9+Up5eDhvPuq0sAxda8Nn+MbOq23+LHAmtmjDp8xRWtEWERGJoMt9wxyp7+RofVdo0klLjzNGMCHOsKQwY1y/99KiDBLjoySY+ocmn7gyWQtLX9tVNnzGu0F84tSVq2z+TEie+fcpcoPUOiIiIhKlmrsGx222PFLfRdeAO2YwIY5bijNDPd+ry30syEsnLi7KNzYGgzDQERbGJwnn4avmI/2T/55kX9iq+NVaWNz7yZna8CmeUNAWERGJEdZaLl7uDxsz2MWxhi76h50V4rSkeFaU+lhd7qx6ry7Loix73rUnnUS70Q2f48L4hJGIo6vmA5cn/x3xyWE95RNWyn2l4CsHX5lzX+0rMo0UtEVERGJYIGg539obajc5XN/FicZuhgPOmMHs1ERWlmWFVr5XlfkozJylc7YDfuifrF1l4mQW9zZxw2dc4vjgHbqVu7dSbfCUG6KgLSIiMssM+50xg4frOzlS18WRhi5OX+oh4I4ZLMxMdtpNynysLHMO2Ml+JWMGY5G1zszy7kboqofOi87X8FtPI9jg+J+blxMWvieG8TJIL9SquIQoaIuIiMwBA8MBXm7q4nBdV2jayfnWsQNvKnJSQ+0mK8t8rCj1kZ48x4eOBfzQ0xQWvuvcm3u/sw6Ge8b/zFVXxcPCuFbF5wwFbRERkTmqe3CEY+6Uk6MNnRyu66KhcwBw9g4uyk8PtZusKvOxvHgaxgzONoNdE4J4/fggPumqePaElhStis9WCtoiIiIS0tY7xNH6rnEbLtt6x8YMLivOYGXpWM/3ksJ0EqJlzGA0mnRVvH78/aHu8T8TlwiZJVeuime5wTyzFJLTvXk/ckMUtEVEROSqrLU0hY0ZHA3g3YN+AFISnTGDoyMGV5VlUZWbFv1jBqPJtVbFu+qdPvKJs8fHrYpP1itepFXxKKCgLSIiIjfEWktte39Y+O7kWEM3AyNOGMxITmBFqY9V5W7Pd6kv9scMeingh95mpxXlamF84umcV1sVD7+vVfGIU9AWERGRV8wfCHKutc89WMcJ4CeauhkJOPkhNy0pdKT8KjeEF2TM0jGDXhjsgq4GN3hPMkFlslXxlCwneGdda4KKevJfCQVtERERiYghf4BTzT3OjO86J3yfaenBnTJIsS9l3LHyq0qz8KUmelv0bDW6Kj5Zi8roSvkVq+IJk6yKl2tV/AYoaIuIiMiM6R/2c7yxm8Nu8D7a0EVN29iYwcrc1LBJJ1msKM0kNWmOjxmcKeNWxSfZtHmtVfHJRhlmlc/5VXEFbREREfFUV/8IRxu6OFzf6U486aSxaxCAOAOLCzJYWeYLTTpZVpxBcsLcDW+eudaq+Oj9wamsik/sFc/w5v3MAAVtERERiTqtPUOh8YJH3Z7v9j7nyPTEeMPy4kxWljqbLVeV+1iUrzGDUWGw+zoTVBomWRX3ga/i6gf8ZBTF7Kq4graIiIhEPWstDZ0D40YMHq3vomfIGTM4LzGeW0vGjxmcn5OqMYPRJhiAnuawID7FVfGMkgnzxGNjVVxBW0RERGJSMGipae/jaH2XO+2ki+ONXQyOOCcxZqQkhHq9V5f5WFmWRYkvRWMGo91gt7PyHb4q3lk3hVXxq7WnlENGsSdzxRW0RUREZNbwB4KcaekNtZ0cqe/kZFMPfnfUSV56Umiz5eqyLJYXZ1KYmazwHUuuWBWfsCI+2ar4x16CnKoZL3WqQVvbfUVERCTqJcTHsbw4k+XFmfzhBuexwZEAJ5t7nPBd54Tv359qYXQNMSs1kaWFGSwvzmRpUQbLijJYUphBWrLiT1SKiwdfqXNj0+TXTFwVzyyd0RJvlFa0RUREZNboG3LGDJ5s7uZEUw+nmrs51dxD3/BYS8L83FSWFmawrDiTZW4An5+bRrz6vmWKtKItIiIic05acgIbq3LYWJUTeiwYtNR3DHCyuZuTzT2cau7hRHM3z5y4FDpkJyUxjiWFGVcE8Nz0ZI/eicwGWtEWERGROWlwJMCZS73jAvjJ5m7aeodD1+RnJIdC99IiJ4AvKkgnJTE2x9LJ9NCKtoiIiMg1pCTGs7LMx8oy37jHW3uGQqF7NIA/tvcCQ35n6kl8nKEqL42lRRksDwvgZdnztPlSxlHQFhEREQmTn5FMfkYydy7OCz0WCFpq2/s46fZ9n2ju4Wh9F7880hS6Jj05gaVFGeMC+NKiDHzzEr14GxIF1DoiIiIicpN6h/ycvtQzLoCfbOqme9AfuqbEl8KysMkny4oyWZCfRqJOvIxZah0RERERibD05ATWVWSzriI79Ji1lubuQU429XDSbUE51dzDztOtobnfifGGhfnp40YPLivS7O/ZRkFbREREZBoZYyj2zaPYN49XLSsIPT7sD3K+rXdcAN93vp0nX2wIXZOVmhgK3cvcNhTN/o5d+tREREREZkBSQpwboDPHPd7ZP+xuvhwL4D8+WBea/W0MVOSkhiafLHcDuGZ/Rz8FbREREREPZaUmsWlBLpsW5IYeu9rs79+8fOXs74kBXLO/o4c2Q4qIiIjEiNHZ3yfcvu+Tzd2cbOqhvU+zv2eSNkOKiIiIzDJTnf19srlbs7+jgIK2iIiISIybbPa3PxCktr1/XAA/Ut85bvZ3RnICS0JTTzJCYwgzUzT7ezqodURERERkDukd8nMq7Mj5k5PM/i7NmhcaO7i0KIPlxZlU5Wn29yi1joiIiIjIFdKTE7htfja3zb/27O+TTeNnfyfFx7GwID2s/9sJ4AUZmv19NQraIiIiInPctWZ/n2vtDU09OdXcw95z15/9vbQog9QkxUz9CYiIiIjIpJIS4lhenMny4kzeTmno8c7+4dDYwdH2kx8drKN/ktnfowF8WXEmFTmpc2r2t4K2iIiIiNyQrNQkbl+Qy+2TzP4eN3qwueeK2d9LCzPc/u+xAJ6TluTRO4ksbYYUERERkYgJn/19sqmHU5euPft7WZEz+SSaZ39rM6SIiIiIeO5as79PuqvfJ9wA/ujeCwxPmP09MYDH0uxvBW0RERERmXHO7O987lqcH3psdPZ3eAA/XN/JL64y+/vj9yymICPFi/KnREFbRERERKJCQnwciwrSWVSQzptXjT0+Ovt7NICfbOrh54cb+dTrl3lX7BQoaIuIiIhIVLva7O9obyHR8T4iIiIiEnOiPWSDgraIiIiISEQoaIuIiIiIRICCtoiIiIhIBChoi4iIiIhEgIK2iIiIiEgEzEjQNsY8bIxpMcYcC3vsi8aYBmPMS+7tjWHPfdYYc9YYc8oY8/qZqFFEREREZDrN1Ir2I8C9kzz+L9baNe7tfwCMMbcA9wO3uj/zH8aY6DzoXkRERETkKmYkaFtrdwKXp3j524AfWGuHrLU1wFlgY8SKExERERGJAK97tP/MGHPEbS0ZPeqnFKgLu6befewKxpgPG2MOGmMOtra2RrpWEREREZEp8zJofwNYCKwBmoB/dh+f7JgfO9kvsNZ+01q73lq7Pj8/PzJVioiIiIjcBM+CtrX2krU2YK0NAv/FWHtIPVAedmkZ0DjT9YmIiIiIvBKeBW1jTHHY3XcAoxNJfgbcb4xJNsZUAYuB/TNdn4iIiIjIK5EwEy9ijPk+cDeQZ4ypBx4C7jbGrMFpC6kF/hjAWnvcGPMj4GXAD3zEWhuYiTpFRERERKaLsXbS9ueYs379envw4EGvyxARERGRWc4Y84K1dv31rvN66oiIiIiIyKykoC0iIiIiEgEK2iIiIiIiEaCgLSIiIiISAQraIiIiIiIRoKAtIiIiIhIBCtoiIiIiIhGgoC0iIiIiEgEK2iIiIiIiEaCgLSIiIiISAQraIiIiIiIRoKAtIiIiIhIBCtoiIiIiIhFgrLVe1zAtjDGtwAWPXj4PaPPotWVm6DOeG/Q5zw36nOcGfc6zn5ef8Xxrbf71Lpo1QdtLxpiD1tr1XtchkaPPeG7Q5zw36HOeG/Q5z36x8BmrdUREREREJAIUtEVEREREIkBBe3p80+sCJOL0Gc8N+pznBn3Oc4M+59kv6j9j9WiLiIiIiESAVrRFRERERCJAQVtEREREJAIUtF8BY8zDxpgWY8wxr2uRyDDGlBtjfm+MTqPFXQAABmhJREFUOWGMOW6M+bjXNcn0M8akGGP2G2MOu5/zl7yuSSLDGBNvjHnRGPMLr2uRyDDG1BpjjhpjXjLGHPS6HokMY0yWMeYJY8xJ9+/oO7yuaTLq0X4FjDFbgF7gMWvtCq/rkelnjCkGiq21h4wxGcALwNuttS97XJpMI2OMAdKstb3GmERgF/Bxa+0+j0uTaWaM+SSwHsi01r7Z63pk+hljaoH11lodVjOLGWMeBZ6z1n7LGJMEpFprO72uayKtaL8C1tqdwGWv65DIsdY2WWsPud/3ACeAUm+rkulmHb3u3UT3plWIWcYYUwa8CfiW17WIyM0zxmQCW4BvA1hrh6MxZIOCtsiUGWMqgbXA895WIpHgthS8BLQAv7HW6nOeff4V+BQQ9LoQiSgLPG2MecEY82Gvi5GIWAC0AtvdVrBvGWPSvC5qMgraIlNgjEkHfgJ8wlrb7XU9Mv2stQFr7RqgDNhojFE72CxijHkz0GKtfcHrWiTiqq2164A3AB9x2zxldkkA1gHfsNauBfqAz3hb0uQUtEWuw+3Z/QnwuLX2p17XI5Hl/u/HZ4F7PS5Fplc18Fa3f/cHwKuNMd/1tiSJBGtto/u1BXgS2OhtRRIB9UB92P95fAIneEcdBW2Ra3A3yX0bOGGt/arX9UhkGGPyjTFZ7vfzgHuAk95WJdPJWvtZa22ZtbYSuB/4nbX2/R6XJdPMGJPmblzHbSV4HaDJYLOMtbYZqDPGLHUfeg0QlUMKErwuIJYZY74P3A3kGWPqgYestd/2tiqZZtXAB4Cjbv8uwOestf/jYU0y/YqBR40x8TgLED+y1mr8m0jsKQSedNZISAC+Z619ytuSJEI+CjzuThw5D2zzuJ5JabyfiIiIiEgEqHVERERERCQCFLRFRERERCJAQVtEREREJAIUtEVEREREIkBBW0REREQkAhS0RUQkIowxlcYYa4zRKFkRmZMUtEVEREREIkBBW0REREQkAhS0RURmiDGm1hjzF8aYI8aYLmPMD40xKcaYB4wxuyZca40xi9zvHzHG/Icx5lfGmF5jzG5jTJEx5l+NMR3GmJPGmLVTeP0SY8xPjDGtxpgaY8zHwp77ojHmCbemHmPMIWPM6rDnlxtjnjXGdBpjjhtj3hr23DxjzD8bYy6472uXe5T9qPcZYy4aY9qMMZ8P+7mNxpiDxphuY8wlY8xXb/KPVkQkKiloi4jMrHcD9wJVwCrggRv4uS8AecAQsBc45N5/ArhmSDXGxAE/Bw4DpcBrgE8YY14fdtnbgB8DOcD3gP9njEk0xiS6P/s0UMDY0cdL3Z/7J+A2YLP7s58CgmG/905gqfuaf2WMWe4+/jXga9baTGAh8KMp/lmIiMQEBW0RkZn1dWtto7X2Mk54XTPFn3vSWvuCtXYQeBIYtNY+Zq0NAD8ErreivQHIt9Z+2Vo7bK09D/wXcH/YNS9Ya5+w1o7gBPcU4Hb3lg58xf3Z3wG/AN7jBvgHgY9baxustQFr7R5r7VDY7/2StXbAWnsYJ+iPrpSPAIuMMXnW2l5r7b4p/lmIiMQEBW0RkZnVHPZ9P06AnYpLYd8PTHL/er9nPlDitn50GmM6gc8BhWHX1I1+Y60NAvVAiXurcx8bdQFnZTwPJ5Cfu8ZrX+09/xGwBDhpjDlgjHnzdd6DiEhM0cglERHv9QGpo3eMMUUReI06oMZau/ga15SH1RAHlAGNo88ZY+LCwnYFcBpoAwZxWj8O30hB1tozjK2KvxN4whiTa63tu5HfIyISrbSiLSLivcPArcaYNcaYFOCLEXiN/UC3MebT7ubFeGPMCmPMhrBrbjPGvNOde/0JnF7wfcDzOP8Y+JTbs3038BbgB27wfhj4qrvZMt4Yc4cxJvl6BRlj3m+MyXd/R6f7cGDa3rGIiMcUtEVEPGatPQ18GXgGOAPsuvZP3NRrBHDC8RqgBmcl+luAL+yy/wb+EOgAPgC801o7Yq0dBt4KvMH9uf8APmitPen+3F8AR4EDwGXgH5ja3y/3AseNMb04GyPvd3vQRURmBWOt9boGERHxmDHmi8Aia+37va5FRGS20Iq2iIiIiEgEaDOkiMgsYYypAF6+ytO3WGsvzmQ9IiJznVpHREREREQiQK0jIiIiIiIRoKAtIiIiIhIBCtoiIiIiIhGgoC0iIiIiEgEK2iIiIiIiEfD/AROW9F314k/jAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x864 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_graph(n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qn9tZexTtrhJ",
        "outputId": "a8567426-e7b5-4311-e95a-dbbe4bd1c05f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe8e25727f0>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import scikitplot as skplt\n",
        "y_true = [le.classes_[x] for x in test_y]\n",
        "y_pred = [le.classes_[x] for x in val_preds.argmax(axis=1)]\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    y_true, \n",
        "    y_pred,\n",
        "    figsize=(12,12),x_tick_rotation=90)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HevHVLdxtrhJ"
      },
      "source": [
        "## Pytorch Model - BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_J58dh-NuWx9"
      },
      "outputs": [],
      "source": [
        "class BiLSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self, max_features, embed_size, hidden_size, drp, n_layers, n_classes):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        # self.hidden_size = 64\n",
        "        # drp = 0.1\n",
        "        # n_classes = len(le.classes_)\n",
        "        self.embedding = nn.Embedding(max_features, embed_size)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, bidirectional=True, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size*4 , hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(drp)\n",
        "        self.out = nn.Linear(hidden_size, n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #rint(x.size())\n",
        "        h_embedding = self.embedding(x)\n",
        "        #_embedding = torch.squeeze(torch.unsqueeze(h_embedding, 0))\n",
        "        h_lstm, _ = self.lstm(h_embedding)\n",
        "        avg_pool = torch.mean(h_lstm, 1)\n",
        "        max_pool, _ = torch.max(h_lstm, 1)\n",
        "        conc = torch.cat(( avg_pool, max_pool), 1)\n",
        "        conc = self.relu(self.linear(conc))\n",
        "        conc = self.dropout(conc)\n",
        "        out = self.out(conc)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5CDm2dcl7ha"
      },
      "source": [
        "### Training and testing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4L8XnvoueZE"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Full Training\n",
        "# train_X = full_train_X\n",
        "# train_Y = full_train_Y\n",
        "\n",
        "# val_X = test_X\n",
        "# val_Y = test_Y\n",
        "\n",
        "def train_and_validate(params):\n",
        "  n_epochs = params['n_epochs']\n",
        "  hidden_size = params['hidden_size']\n",
        "  drop_rate = params['drop_rate']\n",
        "  n_layers = params['n_layers']\n",
        "  n_classes = len(le.classes_)\n",
        "  embed_size = 300 \n",
        "  max_features = 12000\n",
        "  learning_rate = params['learning_rate']\n",
        "\n",
        "  model = BiLSTM(max_features, embed_size, hidden_size, drop_rate, n_layers, n_classes)\n",
        "  loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
        "  model.cuda()\n",
        "  # optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
        "  optimizer = getattr(optim, params['optimizer'])(model.parameters(), lr= params['learning_rate'])\n",
        "\n",
        "\n",
        "  # Load train and test in CUDA Memory\n",
        "  x_train = torch.tensor(train_X, dtype=torch.long).cuda()\n",
        "  y_train = torch.tensor(train_Y, dtype=torch.long).cuda()\n",
        "  x_cv = torch.tensor(val_X, dtype=torch.long).cuda()\n",
        "  y_cv = torch.tensor(val_Y, dtype=torch.long).cuda()\n",
        "\n",
        "  # Create Torch datasets\n",
        "  train = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "  valid = torch.utils.data.TensorDataset(x_cv, y_cv)\n",
        "\n",
        "  # train = DatasetMaper(x_train, y_train)\n",
        "  # valid = DatasetMaper(x_cv, y_cv)\n",
        "\n",
        "  # Create Data Loaders\n",
        "  train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "  valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  train_loss = []\n",
        "  valid_loss = []\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      start_time = time.time()\n",
        "      # Set model to train configuration\n",
        "      model.train()\n",
        "      avg_loss = 0.  \n",
        "      for i, (x_batch, y_batch) in enumerate(train_loader):\n",
        "          # Predict/Forward Pass\n",
        "          y_pred = model(x_batch)\n",
        "          # Compute loss\n",
        "          loss = loss_fn(y_pred, y_batch)\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          avg_loss += loss.item() / len(train_loader)\n",
        "      \n",
        "      # Set model to validation configuration -Doesn't get trained here\n",
        "      model.eval()        \n",
        "      avg_val_loss = 0.\n",
        "      val_preds = np.zeros((len(x_cv),len(le.classes_)))\n",
        "      \n",
        "      for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "          y_pred = model(x_batch).detach()\n",
        "          avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
        "          # keep/store predictions\n",
        "          val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
        "      \n",
        "      # Check Accuracy\n",
        "      val_accuracy = sum(val_preds.argmax(axis=1)==val_Y)/len(val_Y)\n",
        "      train_loss.append(avg_loss)\n",
        "      valid_loss.append(avg_val_loss)\n",
        "      elapsed_time = time.time() - start_time \n",
        "      print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f}  \\t val_acc={:.4f}  \\t time={:.2f}s'.format(\n",
        "                  epoch + 1, n_epochs, avg_loss, avg_val_loss, val_accuracy, elapsed_time))\n",
        "  f_score = f1_score(val_Y, val_preds.argmax(axis=1), average='micro')\n",
        "  # print(evaluate(model))\n",
        "  return f_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wsweXrw6Gla"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate(model):\n",
        "  x_test = torch.tensor(test_X, dtype=torch.long).cuda()\n",
        "  y_test = torch.tensor(test_Y, dtype=torch.long).cuda()\n",
        "\n",
        "  test = torch.utils.data.TensorDataset(x_test, y_test)\n",
        "\n",
        "  test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  test_preds = np.zeros((len(x_test),len(le.classes_)))\n",
        "  avg_test_loss = 0\n",
        "  for i, (x_batch, y_batch) in enumerate(test_loader):\n",
        "      y_pred = model(x_batch).detach()\n",
        "      # avg_test_loss += loss_fn(y_pred, y_batch).item() / len(test_loader)\n",
        "      # keep/store predictions\n",
        "      test_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
        "  \n",
        "  # Check Accuracy\n",
        "  # print(len(test_Y))\n",
        "  # print(test_preds.argmax(axis=1))\n",
        "  test_accuracy = sum(test_preds.argmax(axis=1)==test_Y)/len(test_Y)\n",
        "  print(classification_report(test_Y, test_preds.argmax(axis=1), target_names=[label_indices[0],label_indices[1]]))\n",
        "  return test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(filename, epoch, model):\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'model': model,\n",
        "        #'optimizer': optimizer,\n",
        "        }\n",
        "    torch.save(state, filename)"
      ],
      "metadata": {
        "id": "uiJLhylgpOYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_on_full_data(params):\n",
        "  n_epochs = params['n_epochs']\n",
        "  hidden_size = params['hidden_size']\n",
        "  drop_rate = params['drop_rate']\n",
        "  n_layers = params['n_layers']\n",
        "  learning_rate = params['learning_rate']\n",
        "  n_classes = len(le.classes_)\n",
        "\n",
        "  model = BiLSTM(max_features, embed_size, hidden_size, drop_rate, n_layers, n_classes)\n",
        "  loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
        "  model.cuda()\n",
        "  # optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
        "  optimizer = getattr(optim, params['optimizer'])(model.parameters(), lr= params['learning_rate'])\n",
        "\n",
        "\n",
        "  x_train = torch.tensor(full_train_X, dtype=torch.long).cuda()\n",
        "  y_train = torch.tensor(full_train_Y, dtype=torch.long).cuda()\n",
        "  train = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "  train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  train_loss = []\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      start_time = time.time()\n",
        "      # Set model to train configuration\n",
        "      model.train()\n",
        "      avg_loss = 0.\n",
        "      \n",
        "      for i, (x_batch, y_batch) in enumerate(train_loader):\n",
        "          # Predict/Forward Pass\n",
        "          y_pred = model(x_batch)\n",
        "          # Compute loss\n",
        "          loss = loss_fn(y_pred, y_batch)\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          avg_loss += loss.item() / len(train_loader)\n",
        "\n",
        "      train_loss.append(avg_loss)\n",
        "      elapsed_time = time.time() - start_time \n",
        "      \n",
        "      print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
        "                  epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
        "  file_name = 'checkpoints/saved_weights.pt'\n",
        "  \n",
        "  save_checkpoint(file_name, epoch, model)\n",
        "  return evaluate(model)"
      ],
      "metadata": {
        "id": "3Klk0GeUpEdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyper Parameter Tuning using Bayesian Optimization"
      ],
      "metadata": {
        "id": "PmJDe7EzsEzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "\n",
        "    params = {\n",
        "              'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
        "              'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
        "              'n_layers': trial.suggest_int(\"n_layers\", 1, 4),\n",
        "              'drop_rate':trial.suggest_float(\"drop_rate\", 0.1, 0.5),\n",
        "              'hidden_size': trial.suggest_int(\"hidden_size\", 48, 128),\n",
        "              'n_epochs': trial.suggest_int(\"n_epochs\", 2, 8),\n",
        "              }\n",
        "    \n",
        "    \n",
        "    f_score = train_and_validate(params)\n",
        "\n",
        "    return f_score"
      ],
      "metadata": {
        "id": "npXrgpokNj75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
        "study.optimize(objective, n_trials=35)\n",
        "best_trial = study.best_trial\n",
        "\n",
        "for key, value in best_trial.params.items():\n",
        "    print(\"{}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaDEAUheUiyd",
        "outputId": "562c3912-dcd1-43e2-f780-27e7a128229b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:02,517]\u001b[0m A new study created in memory with name: no-name-66de36df-f4d6-47e9-ae7c-c10733540401\u001b[0m\n",
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 \t loss=10.8118 \t val_loss=9.5264  \t val_acc=0.9739  \t time=1.51s\n",
            "Epoch 2/7 \t loss=9.9812 \t val_loss=8.6377  \t val_acc=0.9826  \t time=0.31s\n",
            "Epoch 3/7 \t loss=8.3506 \t val_loss=6.8839  \t val_acc=0.9304  \t time=0.31s\n",
            "Epoch 4/7 \t loss=5.6575 \t val_loss=4.0639  \t val_acc=0.9391  \t time=0.32s\n",
            "Epoch 5/7 \t loss=2.9357 \t val_loss=1.8125  \t val_acc=1.0000  \t time=0.31s\n",
            "Epoch 6/7 \t loss=1.2853 \t val_loss=1.1316  \t val_acc=0.9565  \t time=0.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:15,693]\u001b[0m Trial 0 finished with value: 1.0 and parameters: {'learning_rate': 0.00013925406894987598, 'optimizer': 'RMSprop', 'n_layers': 1, 'drop_rate': 0.3133126915599974, 'hidden_size': 92, 'n_epochs': 7}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 \t loss=0.9673 \t val_loss=1.1432  \t val_acc=1.0000  \t time=0.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 \t loss=11.0060 \t val_loss=9.9293  \t val_acc=0.4957  \t time=0.23s\n",
            "Epoch 2/3 \t loss=10.8603 \t val_loss=9.8408  \t val_acc=0.4957  \t time=0.22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:16,411]\u001b[0m Trial 1 finished with value: 0.4956521739130435 and parameters: {'learning_rate': 0.00011409482781963235, 'optimizer': 'Adam', 'n_layers': 3, 'drop_rate': 0.4721962329345235, 'hidden_size': 58, 'n_epochs': 3}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 \t loss=10.7619 \t val_loss=9.7421  \t val_acc=0.4957  \t time=0.22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4 \t loss=11.0076 \t val_loss=9.9859  \t val_acc=0.2870  \t time=0.56s\n",
            "Epoch 2/4 \t loss=10.9831 \t val_loss=9.9828  \t val_acc=0.3217  \t time=0.56s\n",
            "Epoch 3/4 \t loss=10.9982 \t val_loss=9.9798  \t val_acc=0.3565  \t time=0.56s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:18,695]\u001b[0m Trial 2 finished with value: 0.4000000000000001 and parameters: {'learning_rate': 7.079764941264458e-05, 'optimizer': 'SGD', 'n_layers': 2, 'drop_rate': 0.3073744239023778, 'hidden_size': 118, 'n_epochs': 4}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/4 \t loss=10.9941 \t val_loss=9.9765  \t val_acc=0.4000  \t time=0.56s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2 \t loss=11.0402 \t val_loss=9.9940  \t val_acc=0.4696  \t time=0.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:19,261]\u001b[0m Trial 3 finished with value: 0.46956521739130436 and parameters: {'learning_rate': 0.00020478970582602516, 'optimizer': 'SGD', 'n_layers': 2, 'drop_rate': 0.18442590232411643, 'hidden_size': 65, 'n_epochs': 2}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/2 \t loss=11.0616 \t val_loss=9.9876  \t val_acc=0.4696  \t time=0.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 \t loss=10.9558 \t val_loss=9.9539  \t val_acc=0.4957  \t time=0.32s\n",
            "Epoch 2/3 \t loss=10.9557 \t val_loss=9.9431  \t val_acc=0.4957  \t time=0.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:20,245]\u001b[0m Trial 4 finished with value: 0.4956521739130435 and parameters: {'learning_rate': 0.0003083587021900847, 'optimizer': 'SGD', 'n_layers': 1, 'drop_rate': 0.3557918928990672, 'hidden_size': 89, 'n_epochs': 3}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 \t loss=10.9777 \t val_loss=9.9346  \t val_acc=0.4957  \t time=0.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4 \t loss=10.8727 \t val_loss=9.7458  \t val_acc=0.9652  \t time=0.56s\n",
            "Epoch 2/4 \t loss=10.5801 \t val_loss=9.5670  \t val_acc=0.7043  \t time=0.56s\n",
            "Epoch 3/4 \t loss=10.3221 \t val_loss=9.3142  \t val_acc=0.9739  \t time=0.56s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:22,519]\u001b[0m Trial 5 finished with value: 0.9826086956521739 and parameters: {'learning_rate': 5.9818031859053646e-05, 'optimizer': 'RMSprop', 'n_layers': 3, 'drop_rate': 0.4817907192661891, 'hidden_size': 120, 'n_epochs': 4}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/4 \t loss=9.9374 \t val_loss=8.9895  \t val_acc=0.9826  \t time=0.56s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 \t loss=10.9709 \t val_loss=9.8310  \t val_acc=0.6696  \t time=0.27s\n",
            "Epoch 2/7 \t loss=10.7492 \t val_loss=9.6645  \t val_acc=0.6348  \t time=0.28s\n",
            "Epoch 3/7 \t loss=10.4800 \t val_loss=9.3877  \t val_acc=0.8000  \t time=0.27s\n",
            "Epoch 4/7 \t loss=9.9434 \t val_loss=8.8227  \t val_acc=0.9652  \t time=0.28s\n",
            "Epoch 5/7 \t loss=9.0317 \t val_loss=7.7565  \t val_acc=0.9478  \t time=0.28s\n",
            "Epoch 6/7 \t loss=7.3091 \t val_loss=5.9253  \t val_acc=0.9652  \t time=0.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:24,474]\u001b[0m Trial 6 finished with value: 0.9652173913043478 and parameters: {'learning_rate': 0.00015807356702282545, 'optimizer': 'Adam', 'n_layers': 3, 'drop_rate': 0.1223695371880937, 'hidden_size': 70, 'n_epochs': 7}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 \t loss=4.7190 \t val_loss=3.2769  \t val_acc=0.9652  \t time=0.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8 \t loss=10.9339 \t val_loss=9.8896  \t val_acc=0.5130  \t time=0.29s\n",
            "Epoch 2/8 \t loss=10.8106 \t val_loss=9.8097  \t val_acc=0.7565  \t time=0.29s\n",
            "Epoch 3/8 \t loss=10.6977 \t val_loss=9.7287  \t val_acc=0.9391  \t time=0.29s\n",
            "Epoch 4/8 \t loss=10.5529 \t val_loss=9.6302  \t val_acc=0.8522  \t time=0.29s\n",
            "Epoch 5/8 \t loss=10.4099 \t val_loss=9.5079  \t val_acc=0.9478  \t time=0.29s\n",
            "Epoch 6/8 \t loss=10.2917 \t val_loss=9.3633  \t val_acc=0.9391  \t time=0.29s\n",
            "Epoch 7/8 \t loss=10.0211 \t val_loss=9.1799  \t val_acc=0.9565  \t time=0.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:26,838]\u001b[0m Trial 7 finished with value: 0.9391304347826087 and parameters: {'learning_rate': 5.994438668580415e-05, 'optimizer': 'Adam', 'n_layers': 4, 'drop_rate': 0.4737942159538837, 'hidden_size': 80, 'n_epochs': 8}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/8 \t loss=9.8324 \t val_loss=8.9473  \t val_acc=0.9391  \t time=0.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8 \t loss=10.9635 \t val_loss=9.9864  \t val_acc=0.4957  \t time=0.54s\n",
            "Epoch 2/8 \t loss=10.9957 \t val_loss=9.9857  \t val_acc=0.4957  \t time=0.54s\n",
            "Epoch 3/8 \t loss=10.9982 \t val_loss=9.9851  \t val_acc=0.4957  \t time=0.53s\n",
            "Epoch 4/8 \t loss=11.0016 \t val_loss=9.9843  \t val_acc=0.4957  \t time=0.54s\n",
            "Epoch 5/8 \t loss=10.9647 \t val_loss=9.9836  \t val_acc=0.4957  \t time=0.53s\n",
            "Epoch 6/8 \t loss=10.9795 \t val_loss=9.9829  \t val_acc=0.4957  \t time=0.53s\n",
            "Epoch 7/8 \t loss=10.9865 \t val_loss=9.9821  \t val_acc=0.4957  \t time=0.54s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:31,162]\u001b[0m Trial 8 finished with value: 0.4956521739130435 and parameters: {'learning_rate': 1.8593176107281284e-05, 'optimizer': 'SGD', 'n_layers': 3, 'drop_rate': 0.3840082098229196, 'hidden_size': 104, 'n_epochs': 8}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/8 \t loss=10.9634 \t val_loss=9.9815  \t val_acc=0.4957  \t time=0.54s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 \t loss=44.2553 \t val_loss=2.2956  \t val_acc=0.9652  \t time=0.29s\n",
            "Epoch 2/7 \t loss=2.0886 \t val_loss=0.8665  \t val_acc=0.9826  \t time=0.29s\n",
            "Epoch 3/7 \t loss=0.6869 \t val_loss=0.3812  \t val_acc=0.9913  \t time=0.30s\n",
            "Epoch 4/7 \t loss=0.2775 \t val_loss=0.3065  \t val_acc=0.9913  \t time=0.29s\n",
            "Epoch 5/7 \t loss=0.3341 \t val_loss=0.3861  \t val_acc=0.9913  \t time=0.29s\n",
            "Epoch 6/7 \t loss=0.2974 \t val_loss=0.2257  \t val_acc=0.9913  \t time=0.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:33,232]\u001b[0m Trial 9 finished with value: 0.991304347826087 and parameters: {'learning_rate': 0.008794874198297805, 'optimizer': 'RMSprop', 'n_layers': 4, 'drop_rate': 0.31939145195608676, 'hidden_size': 78, 'n_epochs': 7}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 \t loss=0.1067 \t val_loss=0.2148  \t val_acc=0.9913  \t time=0.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 \t loss=9.1330 \t val_loss=4.6912  \t val_acc=0.8609  \t time=0.20s\n",
            "Epoch 2/6 \t loss=1.6982 \t val_loss=0.4588  \t val_acc=0.9913  \t time=0.20s\n",
            "Epoch 3/6 \t loss=0.2797 \t val_loss=0.2076  \t val_acc=1.0000  \t time=0.20s\n",
            "Epoch 4/6 \t loss=0.0927 \t val_loss=0.0888  \t val_acc=1.0000  \t time=0.51s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:34,894]\u001b[0m Trial 10 finished with value: 1.0 and parameters: {'learning_rate': 0.0011372083309553107, 'optimizer': 'RMSprop', 'n_layers': 1, 'drop_rate': 0.23765828663537486, 'hidden_size': 48, 'n_epochs': 6}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/6 \t loss=0.0520 \t val_loss=0.0644  \t val_acc=1.0000  \t time=0.30s\n",
            "Epoch 6/6 \t loss=0.0302 \t val_loss=0.0460  \t val_acc=1.0000  \t time=0.19s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 \t loss=11.1523 \t val_loss=9.9925  \t val_acc=0.5043  \t time=0.21s\n",
            "Epoch 2/6 \t loss=10.9339 \t val_loss=9.7388  \t val_acc=0.5826  \t time=0.39s\n",
            "Epoch 3/6 \t loss=9.6170 \t val_loss=6.1069  \t val_acc=0.9565  \t time=0.35s\n",
            "Epoch 4/6 \t loss=3.5498 \t val_loss=1.4131  \t val_acc=0.9826  \t time=0.22s\n",
            "Epoch 5/6 \t loss=1.3506 \t val_loss=0.4097  \t val_acc=0.9913  \t time=0.22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:36,557]\u001b[0m Trial 11 finished with value: 1.0 and parameters: {'learning_rate': 0.0008647004188304768, 'optimizer': 'RMSprop', 'n_layers': 1, 'drop_rate': 0.23138853114420854, 'hidden_size': 51, 'n_epochs': 6}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/6 \t loss=0.6434 \t val_loss=0.2979  \t val_acc=1.0000  \t time=0.21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 \t loss=7.5776 \t val_loss=1.1623  \t val_acc=0.9826  \t time=0.56s\n",
            "Epoch 2/6 \t loss=0.4831 \t val_loss=0.2079  \t val_acc=1.0000  \t time=0.56s\n",
            "Epoch 3/6 \t loss=0.0870 \t val_loss=0.1163  \t val_acc=1.0000  \t time=0.56s\n",
            "Epoch 4/6 \t loss=0.0398 \t val_loss=0.0714  \t val_acc=1.0000  \t time=0.56s\n",
            "Epoch 5/6 \t loss=0.0255 \t val_loss=0.0349  \t val_acc=1.0000  \t time=0.56s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:39,957]\u001b[0m Trial 12 finished with value: 1.0 and parameters: {'learning_rate': 0.0011250172722568376, 'optimizer': 'RMSprop', 'n_layers': 1, 'drop_rate': 0.24829856688259672, 'hidden_size': 101, 'n_epochs': 6}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/6 \t loss=0.0194 \t val_loss=0.0300  \t val_acc=1.0000  \t time=0.56s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 \t loss=8.0704 \t val_loss=3.4997  \t val_acc=0.9391  \t time=0.33s\n",
            "Epoch 2/6 \t loss=1.5167 \t val_loss=0.4275  \t val_acc=1.0000  \t time=0.33s\n",
            "Epoch 3/6 \t loss=0.1957 \t val_loss=0.2570  \t val_acc=1.0000  \t time=0.33s\n",
            "Epoch 4/6 \t loss=0.0778 \t val_loss=0.0847  \t val_acc=1.0000  \t time=0.32s\n",
            "Epoch 5/6 \t loss=0.0350 \t val_loss=0.0837  \t val_acc=1.0000  \t time=0.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:42,007]\u001b[0m Trial 13 finished with value: 1.0 and parameters: {'learning_rate': 0.0009515442994677754, 'optimizer': 'RMSprop', 'n_layers': 2, 'drop_rate': 0.2493096361280928, 'hidden_size': 95, 'n_epochs': 6}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/6 \t loss=0.0152 \t val_loss=0.0845  \t val_acc=1.0000  \t time=0.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 \t loss=10.9230 \t val_loss=9.8694  \t val_acc=0.5043  \t time=0.59s\n",
            "Epoch 2/5 \t loss=10.8636 \t val_loss=9.8363  \t val_acc=0.5913  \t time=0.59s\n",
            "Epoch 3/5 \t loss=10.8124 \t val_loss=9.8105  \t val_acc=0.8609  \t time=0.59s\n",
            "Epoch 4/5 \t loss=10.7847 \t val_loss=9.7862  \t val_acc=0.9043  \t time=0.59s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:45,014]\u001b[0m Trial 14 finished with value: 0.9217391304347826 and parameters: {'learning_rate': 1.1832171240906281e-05, 'optimizer': 'RMSprop', 'n_layers': 1, 'drop_rate': 0.17227292544916992, 'hidden_size': 109, 'n_epochs': 5}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 \t loss=10.7339 \t val_loss=9.7630  \t val_acc=0.9217  \t time=0.59s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 \t loss=9.5925 \t val_loss=5.5241  \t val_acc=0.9913  \t time=0.20s\n",
            "Epoch 2/7 \t loss=3.2392 \t val_loss=1.5792  \t val_acc=0.9739  \t time=0.20s\n",
            "Epoch 3/7 \t loss=1.9332 \t val_loss=1.2066  \t val_acc=0.9652  \t time=0.20s\n",
            "Epoch 4/7 \t loss=0.5510 \t val_loss=0.6087  \t val_acc=0.9913  \t time=0.20s\n",
            "Epoch 5/7 \t loss=0.2733 \t val_loss=0.3189  \t val_acc=1.0000  \t time=0.21s\n",
            "Epoch 6/7 \t loss=0.1573 \t val_loss=0.1915  \t val_acc=1.0000  \t time=0.20s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:46,478]\u001b[0m Trial 15 finished with value: 1.0 and parameters: {'learning_rate': 0.0005267836458950588, 'optimizer': 'RMSprop', 'n_layers': 1, 'drop_rate': 0.2842725072254969, 'hidden_size': 48, 'n_epochs': 7}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 \t loss=0.0886 \t val_loss=0.1517  \t val_acc=1.0000  \t time=0.20s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 \t loss=12.6596 \t val_loss=4.3791  \t val_acc=0.8957  \t time=0.31s\n",
            "Epoch 2/5 \t loss=1.8020 \t val_loss=0.8076  \t val_acc=0.9826  \t time=0.31s\n",
            "Epoch 3/5 \t loss=0.3164 \t val_loss=0.3821  \t val_acc=0.9913  \t time=0.32s\n",
            "Epoch 4/5 \t loss=0.1779 \t val_loss=0.2155  \t val_acc=0.9913  \t time=0.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:48,100]\u001b[0m Trial 16 finished with value: 0.991304347826087 and parameters: {'learning_rate': 0.002463858683542979, 'optimizer': 'RMSprop', 'n_layers': 2, 'drop_rate': 0.40498909374577396, 'hidden_size': 82, 'n_epochs': 5}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 \t loss=0.1278 \t val_loss=0.2123  \t val_acc=0.9913  \t time=0.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 \t loss=10.1612 \t val_loss=7.4464  \t val_acc=0.9739  \t time=0.28s\n",
            "Epoch 2/7 \t loss=5.0872 \t val_loss=2.6099  \t val_acc=0.9478  \t time=0.27s\n",
            "Epoch 3/7 \t loss=1.2840 \t val_loss=1.1216  \t val_acc=0.9739  \t time=0.28s\n",
            "Epoch 4/7 \t loss=0.9198 \t val_loss=0.9720  \t val_acc=0.9739  \t time=0.28s\n",
            "Epoch 5/7 \t loss=0.5327 \t val_loss=0.4757  \t val_acc=0.9913  \t time=0.28s\n",
            "Epoch 6/7 \t loss=0.2097 \t val_loss=0.3302  \t val_acc=0.9913  \t time=0.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:50,097]\u001b[0m Trial 17 finished with value: 0.991304347826087 and parameters: {'learning_rate': 0.0003414400264167762, 'optimizer': 'RMSprop', 'n_layers': 1, 'drop_rate': 0.3417421534429189, 'hidden_size': 69, 'n_epochs': 7}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 \t loss=0.1260 \t val_loss=0.3269  \t val_acc=0.9913  \t time=0.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 \t loss=12.7175 \t val_loss=1.5071  \t val_acc=0.9739  \t time=0.60s\n",
            "Epoch 2/6 \t loss=0.4515 \t val_loss=0.4170  \t val_acc=0.9913  \t time=0.60s\n",
            "Epoch 3/6 \t loss=0.0688 \t val_loss=0.3085  \t val_acc=0.9913  \t time=0.59s\n",
            "Epoch 4/6 \t loss=0.0330 \t val_loss=0.2571  \t val_acc=0.9913  \t time=0.60s\n",
            "Epoch 5/6 \t loss=0.0189 \t val_loss=0.2898  \t val_acc=0.9913  \t time=0.61s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:53,746]\u001b[0m Trial 18 finished with value: 0.991304347826087 and parameters: {'learning_rate': 0.002201031391228526, 'optimizer': 'RMSprop', 'n_layers': 2, 'drop_rate': 0.2821921271348488, 'hidden_size': 127, 'n_epochs': 6}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/6 \t loss=0.0096 \t val_loss=0.2800  \t val_acc=0.9913  \t time=0.60s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8 \t loss=10.9097 \t val_loss=9.8798  \t val_acc=0.5043  \t time=0.33s\n",
            "Epoch 2/8 \t loss=10.8417 \t val_loss=9.8317  \t val_acc=0.5217  \t time=0.32s\n",
            "Epoch 3/8 \t loss=10.7498 \t val_loss=9.7879  \t val_acc=0.7217  \t time=0.33s\n",
            "Epoch 4/8 \t loss=10.6985 \t val_loss=9.7410  \t val_acc=0.6870  \t time=0.33s\n",
            "Epoch 5/8 \t loss=10.6571 \t val_loss=9.6923  \t val_acc=0.8000  \t time=0.33s\n",
            "Epoch 6/8 \t loss=10.5606 \t val_loss=9.6374  \t val_acc=0.7652  \t time=0.34s\n",
            "Epoch 7/8 \t loss=10.4919 \t val_loss=9.5757  \t val_acc=0.9043  \t time=0.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:56,443]\u001b[0m Trial 19 finished with value: 0.9217391304347826 and parameters: {'learning_rate': 2.7939757347178512e-05, 'optimizer': 'Adam', 'n_layers': 1, 'drop_rate': 0.20647869602475366, 'hidden_size': 89, 'n_epochs': 8}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/8 \t loss=10.4262 \t val_loss=9.5059  \t val_acc=0.9217  \t time=0.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 \t loss=10.5720 \t val_loss=8.5945  \t val_acc=0.9391  \t time=0.23s\n",
            "Epoch 2/5 \t loss=7.1210 \t val_loss=4.2585  \t val_acc=0.9130  \t time=0.22s\n",
            "Epoch 3/5 \t loss=2.6870 \t val_loss=2.0741  \t val_acc=1.0000  \t time=0.23s\n",
            "Epoch 4/5 \t loss=1.2888 \t val_loss=1.8057  \t val_acc=0.9478  \t time=0.23s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:57,639]\u001b[0m Trial 20 finished with value: 0.9826086956521739 and parameters: {'learning_rate': 0.00029946186189297875, 'optimizer': 'RMSprop', 'n_layers': 2, 'drop_rate': 0.27302588938159117, 'hidden_size': 61, 'n_epochs': 5}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 \t loss=0.7935 \t val_loss=0.8430  \t val_acc=0.9826  \t time=0.23s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 \t loss=8.9892 \t val_loss=4.2236  \t val_acc=0.9478  \t time=0.21s\n",
            "Epoch 2/6 \t loss=2.0356 \t val_loss=2.4030  \t val_acc=0.9391  \t time=0.22s\n",
            "Epoch 3/6 \t loss=0.4516 \t val_loss=0.4616  \t val_acc=0.9913  \t time=0.21s\n",
            "Epoch 4/6 \t loss=0.3268 \t val_loss=0.1894  \t val_acc=1.0000  \t time=0.21s\n",
            "Epoch 5/6 \t loss=0.1145 \t val_loss=0.0968  \t val_acc=1.0000  \t time=0.21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:38:58,977]\u001b[0m Trial 21 finished with value: 1.0 and parameters: {'learning_rate': 0.0006123392890400335, 'optimizer': 'RMSprop', 'n_layers': 1, 'drop_rate': 0.23131731563611146, 'hidden_size': 50, 'n_epochs': 6}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/6 \t loss=0.0534 \t val_loss=0.0683  \t val_acc=1.0000  \t time=0.21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 \t loss=6.4744 \t val_loss=1.0942  \t val_acc=0.9826  \t time=0.22s\n",
            "Epoch 2/6 \t loss=0.4748 \t val_loss=0.2266  \t val_acc=1.0000  \t time=0.22s\n",
            "Epoch 3/6 \t loss=0.0825 \t val_loss=0.1030  \t val_acc=1.0000  \t time=0.23s\n",
            "Epoch 4/6 \t loss=0.0384 \t val_loss=0.0412  \t val_acc=1.0000  \t time=0.21s\n",
            "Epoch 5/6 \t loss=0.0209 \t val_loss=0.0318  \t val_acc=1.0000  \t time=0.21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:39:00,346]\u001b[0m Trial 22 finished with value: 1.0 and parameters: {'learning_rate': 0.0016162572048122326, 'optimizer': 'RMSprop', 'n_layers': 1, 'drop_rate': 0.2248194049420122, 'hidden_size': 52, 'n_epochs': 6}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/6 \t loss=0.0128 \t val_loss=0.0272  \t val_acc=1.0000  \t time=0.22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 \t loss=10.2597 \t val_loss=6.6920  \t val_acc=0.9565  \t time=0.22s\n",
            "Epoch 2/7 \t loss=4.2583 \t val_loss=1.5302  \t val_acc=0.9913  \t time=0.23s\n",
            "Epoch 3/7 \t loss=1.1637 \t val_loss=0.7072  \t val_acc=1.0000  \t time=0.22s\n",
            "Epoch 4/7 \t loss=0.4606 \t val_loss=0.3787  \t val_acc=0.9826  \t time=0.23s\n",
            "Epoch 5/7 \t loss=0.1529 \t val_loss=0.3687  \t val_acc=0.9913  \t time=0.23s\n",
            "Epoch 6/7 \t loss=0.0769 \t val_loss=0.3604  \t val_acc=0.9913  \t time=0.23s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:39:01,985]\u001b[0m Trial 23 finished with value: 0.991304347826087 and parameters: {'learning_rate': 0.0005883064926942359, 'optimizer': 'RMSprop', 'n_layers': 1, 'drop_rate': 0.26491705749467437, 'hidden_size': 59, 'n_epochs': 7}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 \t loss=0.0544 \t val_loss=0.3648  \t val_acc=0.9913  \t time=0.22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 \t loss=12.9150 \t val_loss=1.3403  \t val_acc=0.9652  \t time=0.28s\n",
            "Epoch 2/6 \t loss=0.6432 \t val_loss=0.2462  \t val_acc=0.9913  \t time=0.29s\n",
            "Epoch 3/6 \t loss=0.2092 \t val_loss=0.1208  \t val_acc=1.0000  \t time=0.29s\n",
            "Epoch 4/6 \t loss=0.0721 \t val_loss=0.1034  \t val_acc=1.0000  \t time=0.29s\n",
            "Epoch 5/6 \t loss=0.0400 \t val_loss=0.0932  \t val_acc=1.0000  \t time=0.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:39:03,766]\u001b[0m Trial 24 finished with value: 1.0 and parameters: {'learning_rate': 0.0038104157961630246, 'optimizer': 'RMSprop', 'n_layers': 1, 'drop_rate': 0.30405519881330534, 'hidden_size': 74, 'n_epochs': 6}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/6 \t loss=0.0451 \t val_loss=0.0841  \t val_acc=1.0000  \t time=0.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4 \t loss=8.6958 \t val_loss=2.8755  \t val_acc=0.9739  \t time=0.22s\n",
            "Epoch 2/4 \t loss=1.1999 \t val_loss=1.5742  \t val_acc=0.9391  \t time=0.22s\n",
            "Epoch 3/4 \t loss=0.2642 \t val_loss=0.1065  \t val_acc=1.0000  \t time=0.22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:39:04,698]\u001b[0m Trial 25 finished with value: 1.0 and parameters: {'learning_rate': 0.0009639687528954852, 'optimizer': 'RMSprop', 'n_layers': 2, 'drop_rate': 0.20318557998039188, 'hidden_size': 55, 'n_epochs': 4}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/4 \t loss=0.0667 \t val_loss=0.0547  \t val_acc=1.0000  \t time=0.22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 \t loss=9.9166 \t val_loss=6.4392  \t val_acc=0.8870  \t time=0.22s\n",
            "Epoch 2/5 \t loss=3.9005 \t val_loss=1.4076  \t val_acc=0.9739  \t time=0.23s\n",
            "Epoch 3/5 \t loss=0.8836 \t val_loss=0.4387  \t val_acc=0.9913  \t time=0.23s\n",
            "Epoch 4/5 \t loss=0.9604 \t val_loss=0.6484  \t val_acc=0.9913  \t time=0.23s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:39:05,898]\u001b[0m Trial 26 finished with value: 1.0 and parameters: {'learning_rate': 0.0004546002638307066, 'optimizer': 'RMSprop', 'n_layers': 1, 'drop_rate': 0.16235729638688362, 'hidden_size': 64, 'n_epochs': 5}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 \t loss=0.2503 \t val_loss=0.1942  \t val_acc=1.0000  \t time=0.23s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 \t loss=10.6358 \t val_loss=8.8028  \t val_acc=0.8348  \t time=0.33s\n",
            "Epoch 2/7 \t loss=7.8822 \t val_loss=5.3370  \t val_acc=0.9478  \t time=0.33s\n",
            "Epoch 3/7 \t loss=3.5452 \t val_loss=2.2592  \t val_acc=0.9565  \t time=0.34s\n",
            "Epoch 4/7 \t loss=1.2997 \t val_loss=1.2980  \t val_acc=0.9652  \t time=0.33s\n",
            "Epoch 5/7 \t loss=0.6413 \t val_loss=0.5532  \t val_acc=1.0000  \t time=0.34s\n",
            "Epoch 6/7 \t loss=0.4753 \t val_loss=0.3407  \t val_acc=1.0000  \t time=0.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:39:08,323]\u001b[0m Trial 27 finished with value: 1.0 and parameters: {'learning_rate': 0.0001913492445908548, 'optimizer': 'RMSprop', 'n_layers': 2, 'drop_rate': 0.24638512059015633, 'hidden_size': 93, 'n_epochs': 7}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 \t loss=0.3024 \t val_loss=0.3413  \t val_acc=1.0000  \t time=0.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8 \t loss=10.5349 \t val_loss=8.7290  \t val_acc=0.7652  \t time=0.34s\n",
            "Epoch 2/8 \t loss=5.9664 \t val_loss=1.7973  \t val_acc=0.9652  \t time=0.33s\n",
            "Epoch 3/8 \t loss=1.3109 \t val_loss=1.5502  \t val_acc=0.9478  \t time=0.34s\n",
            "Epoch 4/8 \t loss=0.2507 \t val_loss=0.2846  \t val_acc=0.9913  \t time=0.33s\n",
            "Epoch 5/8 \t loss=0.0615 \t val_loss=0.1243  \t val_acc=1.0000  \t time=0.33s\n",
            "Epoch 6/8 \t loss=0.0256 \t val_loss=0.1325  \t val_acc=1.0000  \t time=0.33s\n",
            "Epoch 7/8 \t loss=0.0221 \t val_loss=0.1070  \t val_acc=1.0000  \t time=0.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:39:11,106]\u001b[0m Trial 28 finished with value: 0.991304347826087 and parameters: {'learning_rate': 0.0009105771632330032, 'optimizer': 'Adam', 'n_layers': 1, 'drop_rate': 0.21087714601060692, 'hidden_size': 84, 'n_epochs': 8}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/8 \t loss=0.0147 \t val_loss=0.1289  \t val_acc=0.9913  \t time=0.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 \t loss=10.9788 \t val_loss=9.9293  \t val_acc=0.5043  \t time=0.25s\n",
            "Epoch 2/6 \t loss=10.9650 \t val_loss=9.9230  \t val_acc=0.5043  \t time=0.23s\n",
            "Epoch 3/6 \t loss=10.9663 \t val_loss=9.9175  \t val_acc=0.5043  \t time=0.22s\n",
            "Epoch 4/6 \t loss=10.9467 \t val_loss=9.9128  \t val_acc=0.5043  \t time=0.22s\n",
            "Epoch 5/6 \t loss=10.9295 \t val_loss=9.9082  \t val_acc=0.5043  \t time=0.22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:39:12,575]\u001b[0m Trial 29 finished with value: 0.5043478260869565 and parameters: {'learning_rate': 0.0001465296237964403, 'optimizer': 'SGD', 'n_layers': 1, 'drop_rate': 0.14580669135036828, 'hidden_size': 55, 'n_epochs': 6}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/6 \t loss=10.9360 \t val_loss=9.9041  \t val_acc=0.5043  \t time=0.22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 \t loss=10.9895 \t val_loss=9.8710  \t val_acc=0.5565  \t time=0.30s\n",
            "Epoch 2/7 \t loss=10.8356 \t val_loss=9.7658  \t val_acc=0.6435  \t time=0.29s\n",
            "Epoch 3/7 \t loss=10.6508 \t val_loss=9.6220  \t val_acc=0.9217  \t time=0.29s\n",
            "Epoch 4/7 \t loss=10.4090 \t val_loss=9.4279  \t val_acc=0.9304  \t time=0.29s\n",
            "Epoch 5/7 \t loss=10.1295 \t val_loss=9.1270  \t val_acc=0.9565  \t time=0.29s\n",
            "Epoch 6/7 \t loss=9.6615 \t val_loss=8.7034  \t val_acc=0.9304  \t time=0.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:39:14,689]\u001b[0m Trial 30 finished with value: 0.9652173913043478 and parameters: {'learning_rate': 9.179848329339065e-05, 'optimizer': 'Adam', 'n_layers': 2, 'drop_rate': 0.11721872850219077, 'hidden_size': 73, 'n_epochs': 7}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/7 \t loss=9.0134 \t val_loss=8.1017  \t val_acc=0.9652  \t time=0.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 \t loss=7.0019 \t val_loss=1.2365  \t val_acc=0.9739  \t time=0.55s\n",
            "Epoch 2/6 \t loss=0.5633 \t val_loss=0.1132  \t val_acc=1.0000  \t time=0.56s\n",
            "Epoch 3/6 \t loss=0.0748 \t val_loss=0.0373  \t val_acc=1.0000  \t time=0.56s\n",
            "Epoch 4/6 \t loss=0.0280 \t val_loss=0.0165  \t val_acc=1.0000  \t time=0.55s\n",
            "Epoch 5/6 \t loss=0.0167 \t val_loss=0.0143  \t val_acc=1.0000  \t time=0.56s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:39:18,065]\u001b[0m Trial 31 finished with value: 1.0 and parameters: {'learning_rate': 0.0012456841397419237, 'optimizer': 'RMSprop', 'n_layers': 1, 'drop_rate': 0.24722984664441205, 'hidden_size': 104, 'n_epochs': 6}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/6 \t loss=0.0122 \t val_loss=0.0075  \t val_acc=1.0000  \t time=0.55s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 \t loss=8.1246 \t val_loss=2.7090  \t val_acc=0.9913  \t time=0.57s\n",
            "Epoch 2/5 \t loss=1.1607 \t val_loss=0.4821  \t val_acc=1.0000  \t time=0.58s\n",
            "Epoch 3/5 \t loss=0.1813 \t val_loss=0.2124  \t val_acc=1.0000  \t time=0.57s\n",
            "Epoch 4/5 \t loss=1.8677 \t val_loss=0.4635  \t val_acc=0.9913  \t time=0.58s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:39:20,996]\u001b[0m Trial 32 finished with value: 0.991304347826087 and parameters: {'learning_rate': 0.0006771183470107325, 'optimizer': 'RMSprop', 'n_layers': 1, 'drop_rate': 0.26005429187694745, 'hidden_size': 101, 'n_epochs': 5}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 \t loss=0.1575 \t val_loss=0.3043  \t val_acc=0.9913  \t time=0.58s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 \t loss=7.5124 \t val_loss=2.2274  \t val_acc=0.9391  \t time=0.57s\n",
            "Epoch 2/6 \t loss=0.5612 \t val_loss=0.1871  \t val_acc=1.0000  \t time=0.58s\n",
            "Epoch 3/6 \t loss=0.0719 \t val_loss=0.1147  \t val_acc=1.0000  \t time=0.57s\n",
            "Epoch 4/6 \t loss=0.0321 \t val_loss=0.0977  \t val_acc=1.0000  \t time=0.57s\n",
            "Epoch 5/6 \t loss=0.0200 \t val_loss=0.0829  \t val_acc=1.0000  \t time=0.57s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:39:24,504]\u001b[0m Trial 33 finished with value: 1.0 and parameters: {'learning_rate': 0.0015037491327109407, 'optimizer': 'RMSprop', 'n_layers': 1, 'drop_rate': 0.28764939914848126, 'hidden_size': 112, 'n_epochs': 6}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/6 \t loss=0.0417 \t val_loss=0.0704  \t val_acc=1.0000  \t time=0.58s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-05268f7b54a5>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-2),\n",
            "<ipython-input-28-14f87c8d90ff>:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2 \t loss=11.0626 \t val_loss=10.0396  \t val_acc=0.4957  \t time=0.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-01-27 18:39:25,204]\u001b[0m Trial 34 finished with value: 0.4956521739130435 and parameters: {'learning_rate': 0.00029054082351821325, 'optimizer': 'SGD', 'n_layers': 2, 'drop_rate': 0.19043059230381035, 'hidden_size': 96, 'n_epochs': 2}. Best is trial 0 with value: 1.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/2 \t loss=11.0258 \t val_loss=10.0195  \t val_acc=0.4957  \t time=0.32s\n",
            "learning_rate: 0.00013925406894987598\n",
            "optimizer: RMSprop\n",
            "n_layers: 1\n",
            "drop_rate: 0.3133126915599974\n",
            "hidden_size: 92\n",
            "n_epochs: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ySqZwhXKljL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declaring the best parameters"
      ],
      "metadata": {
        "id": "Qkc5oBj2Btgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = {\n",
        "    'learning_rate': 0.00013925406894987598,\n",
        " 'optimizer': 'RMSprop',\n",
        " 'n_layers': 1,\n",
        " 'drop_rate': 0.3133126915599974,\n",
        " 'hidden_size': 92,\n",
        " 'n_epochs': 7\n",
        "}\n",
        "\n",
        "# best_trial.params"
      ],
      "metadata": {
        "id": "M0eQ2wDwUq-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and testing the model with the best parameters got from hyper parameter tuning on the full training data"
      ],
      "metadata": {
        "id": "wPOzJRCwBvkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_train_X = full_train['Statement'] # Full train to be used only after hyper parameter tuning\n",
        "# full_train_Y = full_train['Measurement']\n",
        "# full_train_Y = full_train['Time Constraint']\n",
        "# full_train_Y = full_train['Data Definition']\n",
        "full_train_Y = full_train['Data Action']\n",
        "# full_train_Y = full_train['Convention']\n",
        "\n",
        "test_X = sep_test['Statement']\n",
        "# test_Y = sep_test['Measurement']\n",
        "# test_Y = sep_test['Data Definition']\n",
        "test_Y = sep_test['Data Action']\n",
        "# test_Y = sep_test['Convention']\n",
        "# test_Y = sep_test['Time Constraint']\n",
        "\n",
        "## Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(full_train_X))\n",
        "full_train_X = tokenizer.texts_to_sequences(full_train_X)\n",
        "test_X = tokenizer.texts_to_sequences(test_X)\n",
        "\n",
        "## Pad the sentences \n",
        "full_train_X = pad_sequences(full_train_X, maxlen=maxlen)\n",
        "test_X = pad_sequences(test_X, maxlen=maxlen)\n",
        "\n",
        "le = LabelEncoder()\n",
        "full_train_Y = le.fit_transform(full_train_Y.values)\n",
        "test_Y = le.transform(test_Y.values)## Tokenize the sentences\n",
        "\n",
        "if debug:\n",
        "    embedding_matrix = np.random.randn(12000,300)\n",
        "else:\n",
        "    embedding_matrix = load_glove(tokenizer.word_index)\n",
        "train_on_full_data(best_params)\n",
        "# train_and_validate(best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWLCaHIYai3u",
        "outputId": "5a2fc566-ecf0-488f-cea0-b90c95e99aa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7 \t loss=10.2822 \t time=1.81s\n",
            "Epoch 2/7 \t loss=6.2248 \t time=0.60s\n",
            "Epoch 3/7 \t loss=2.3177 \t time=0.60s\n",
            "Epoch 4/7 \t loss=1.6915 \t time=0.60s\n",
            "Epoch 5/7 \t loss=1.1279 \t time=0.60s\n",
            "Epoch 6/7 \t loss=0.7485 \t time=0.60s\n",
            "Epoch 7/7 \t loss=0.5712 \t time=0.61s\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "not_Data Action       1.00      0.97      0.98       115\n",
            "    Data Action       0.56      1.00      0.71         5\n",
            "\n",
            "       accuracy                           0.97       120\n",
            "      macro avg       0.78      0.98      0.85       120\n",
            "   weighted avg       0.98      0.97      0.97       120\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-0e9a28fb5bfd>:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  test_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KrJr0NNqPwZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCXj797lv25n",
        "outputId": "a2a447eb-af89-4566-f075-85a8b259995a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "      y_pred = model(x_batch).detach()\n",
        "      avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
        "      val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
        "val_accuracy = sum(val_preds.argmax(axis=1)==val_Y)/len(val_Y)\n",
        "print(val_accuracy)\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RphV-xjz6FS3"
      },
      "outputs": [],
      "source": [
        "def plot_graph(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Train/Validation Loss\")\n",
        "    plt.plot(list(np.arange(epochs) + 1) , train_loss, label='train')\n",
        "    plt.plot(list(np.arange(epochs) + 1), valid_loss, label='validation')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('loss', fontsize=12)\n",
        "    plt.legend(loc='best')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tk6ZTW2EtrhK"
      },
      "outputs": [],
      "source": [
        "plot_graph(n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNoYqVPBtrhK"
      },
      "outputs": [],
      "source": [
        "torch.save(model,'checkpoints/bilstm_Convention_RE')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXG9_-XotrhK"
      },
      "source": [
        "## Deploy : Predict A Single Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88-WPyMNvCjR"
      },
      "outputs": [],
      "source": [
        "def predict_single(x):    \n",
        "    # lower the text\n",
        "    # x = x.lower()\n",
        "    # Clean the text\n",
        "    # x =  clean_text(x)\n",
        "    # Clean numbers\n",
        "    # x =  clean_numbers(x)\n",
        "    # Clean Contractions\n",
        "    # x = replace_contractions(x)\n",
        "    # tokenize\n",
        "    x = tokenizer.texts_to_sequences([x])\n",
        "    # pad\n",
        "    x = pad_sequences(x, maxlen=maxlen)\n",
        "    # create dataset\n",
        "    x = torch.tensor(x, dtype=torch.long).cuda()\n",
        "\n",
        "    pred = model(x).detach()\n",
        "    pred = F.softmax(pred).cpu().numpy()\n",
        "\n",
        "    pred = pred.argmax(axis=1)\n",
        "\n",
        "    pred = le.classes_[pred]\n",
        "    return pred[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_CRoPZhEfui",
        "outputId": "a58e71ad-6b51-4c95-d6c3-4ff3cbce457d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "le.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vstQwIGrHUdE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMvaOjKtqv02"
      },
      "source": [
        "### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g70Kp3thvBW",
        "outputId": "e6ca4bf6-e9bd-4c5a-a7c2-6437931b1249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-c3ceede7e8d3>:77: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 \t loss=8.1638 \t val_loss=6.3264  \t val_acc=0.7843  \t time=0.35s\n",
            "Epoch 2/5 \t loss=7.2697 \t val_loss=4.9493  \t val_acc=0.7843  \t time=0.24s\n",
            "Epoch 3/5 \t loss=4.7948 \t val_loss=2.7889  \t val_acc=0.9216  \t time=0.23s\n",
            "Epoch 4/5 \t loss=3.3703 \t val_loss=2.3698  \t val_acc=0.9608  \t time=0.23s\n",
            "Epoch 5/5 \t loss=2.7503 \t val_loss=2.0195  \t val_acc=1.0000  \t time=0.23s\n",
            "Report for fold  1\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "not_Measurement       1.00      1.00      1.00        40\n",
            "    Measurement       1.00      1.00      1.00        11\n",
            "\n",
            "       accuracy                           1.00        51\n",
            "      macro avg       1.00      1.00      1.00        51\n",
            "   weighted avg       1.00      1.00      1.00        51\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-c3ceede7e8d3>:90: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "<ipython-input-81-c3ceede7e8d3>:77: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 \t loss=8.3457 \t val_loss=5.8447  \t val_acc=0.8235  \t time=0.33s\n",
            "Epoch 2/5 \t loss=7.3537 \t val_loss=4.2357  \t val_acc=0.8235  \t time=0.24s\n",
            "Epoch 3/5 \t loss=4.3791 \t val_loss=2.4990  \t val_acc=0.9412  \t time=0.23s\n",
            "Epoch 4/5 \t loss=2.7404 \t val_loss=2.8691  \t val_acc=0.9020  \t time=0.23s\n",
            "Epoch 5/5 \t loss=2.1162 \t val_loss=2.9645  \t val_acc=0.9216  \t time=0.23s\n",
            "Report for fold  2\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "not_Measurement       1.00      0.90      0.95        42\n",
            "    Measurement       0.69      1.00      0.82         9\n",
            "\n",
            "       accuracy                           0.92        51\n",
            "      macro avg       0.85      0.95      0.88        51\n",
            "   weighted avg       0.95      0.92      0.93        51\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-c3ceede7e8d3>:90: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "<ipython-input-81-c3ceede7e8d3>:77: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 \t loss=8.0738 \t val_loss=7.0667  \t val_acc=0.7255  \t time=0.34s\n",
            "Epoch 2/5 \t loss=7.0566 \t val_loss=5.5424  \t val_acc=0.7255  \t time=0.23s\n",
            "Epoch 3/5 \t loss=4.6583 \t val_loss=2.7092  \t val_acc=0.9608  \t time=0.23s\n",
            "Epoch 4/5 \t loss=2.9801 \t val_loss=2.0203  \t val_acc=0.9608  \t time=0.23s\n",
            "Epoch 5/5 \t loss=1.5769 \t val_loss=1.8812  \t val_acc=0.9412  \t time=0.23s\n",
            "Report for fold  3\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "not_Measurement       0.93      1.00      0.96        37\n",
            "    Measurement       1.00      0.79      0.88        14\n",
            "\n",
            "       accuracy                           0.94        51\n",
            "      macro avg       0.96      0.89      0.92        51\n",
            "   weighted avg       0.95      0.94      0.94        51\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-c3ceede7e8d3>:90: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "<ipython-input-81-c3ceede7e8d3>:77: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 \t loss=8.3816 \t val_loss=6.8190  \t val_acc=0.7600  \t time=0.36s\n",
            "Epoch 2/5 \t loss=7.5494 \t val_loss=5.7233  \t val_acc=0.7600  \t time=0.23s\n",
            "Epoch 3/5 \t loss=5.7001 \t val_loss=3.2028  \t val_acc=0.9200  \t time=0.23s\n",
            "Epoch 4/5 \t loss=3.3314 \t val_loss=2.1364  \t val_acc=0.9600  \t time=0.23s\n",
            "Epoch 5/5 \t loss=2.0373 \t val_loss=2.7032  \t val_acc=0.9400  \t time=0.23s\n",
            "Report for fold  4\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "not_Measurement       0.93      1.00      0.96        38\n",
            "    Measurement       1.00      0.75      0.86        12\n",
            "\n",
            "       accuracy                           0.94        50\n",
            "      macro avg       0.96      0.88      0.91        50\n",
            "   weighted avg       0.94      0.94      0.94        50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-c3ceede7e8d3>:90: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "<ipython-input-81-c3ceede7e8d3>:77: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 \t loss=8.4947 \t val_loss=5.8712  \t val_acc=0.8200  \t time=0.36s\n",
            "Epoch 2/5 \t loss=7.3656 \t val_loss=4.9614  \t val_acc=0.8200  \t time=0.23s\n",
            "Epoch 3/5 \t loss=4.9970 \t val_loss=3.0200  \t val_acc=0.9200  \t time=0.24s\n",
            "Epoch 4/5 \t loss=3.3636 \t val_loss=2.0022  \t val_acc=0.9400  \t time=0.23s\n",
            "Epoch 5/5 \t loss=2.0139 \t val_loss=1.3779  \t val_acc=0.9600  \t time=0.23s\n",
            "Report for fold  5\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "not_Measurement       0.98      0.98      0.98        41\n",
            "    Measurement       0.89      0.89      0.89         9\n",
            "\n",
            "       accuracy                           0.96        50\n",
            "      macro avg       0.93      0.93      0.93        50\n",
            "   weighted avg       0.96      0.96      0.96        50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-c3ceede7e8d3>:90: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "<ipython-input-81-c3ceede7e8d3>:77: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 \t loss=8.2074 \t val_loss=7.1011  \t val_acc=0.7400  \t time=0.36s\n",
            "Epoch 2/5 \t loss=7.3820 \t val_loss=6.2498  \t val_acc=0.7400  \t time=0.23s\n",
            "Epoch 3/5 \t loss=5.2373 \t val_loss=4.2713  \t val_acc=0.8400  \t time=0.24s\n",
            "Epoch 4/5 \t loss=3.4121 \t val_loss=3.1072  \t val_acc=0.8800  \t time=0.23s\n",
            "Epoch 5/5 \t loss=2.2592 \t val_loss=2.5426  \t val_acc=0.9600  \t time=0.24s\n",
            "Report for fold  6\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "not_Measurement       0.97      0.97      0.97        37\n",
            "    Measurement       0.92      0.92      0.92        13\n",
            "\n",
            "       accuracy                           0.96        50\n",
            "      macro avg       0.95      0.95      0.95        50\n",
            "   weighted avg       0.96      0.96      0.96        50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-c3ceede7e8d3>:90: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "<ipython-input-81-c3ceede7e8d3>:77: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 \t loss=8.5474 \t val_loss=6.5195  \t val_acc=0.7800  \t time=0.35s\n",
            "Epoch 2/5 \t loss=7.8741 \t val_loss=6.1371  \t val_acc=0.7800  \t time=0.24s\n",
            "Epoch 3/5 \t loss=5.6253 \t val_loss=5.7415  \t val_acc=0.8400  \t time=0.23s\n",
            "Epoch 4/5 \t loss=3.4667 \t val_loss=5.8010  \t val_acc=0.8400  \t time=0.23s\n",
            "Epoch 5/5 \t loss=2.9163 \t val_loss=4.3239  \t val_acc=0.8200  \t time=0.24s\n",
            "Report for fold  7\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "not_Measurement       0.94      0.82      0.88        39\n",
            "    Measurement       0.56      0.82      0.67        11\n",
            "\n",
            "       accuracy                           0.82        50\n",
            "      macro avg       0.75      0.82      0.77        50\n",
            "   weighted avg       0.86      0.82      0.83        50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-c3ceede7e8d3>:90: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "<ipython-input-81-c3ceede7e8d3>:77: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 \t loss=8.7049 \t val_loss=6.0340  \t val_acc=0.8200  \t time=0.35s\n",
            "Epoch 2/5 \t loss=7.8398 \t val_loss=5.2830  \t val_acc=0.8200  \t time=0.24s\n",
            "Epoch 3/5 \t loss=6.1478 \t val_loss=3.5225  \t val_acc=0.8200  \t time=0.23s\n",
            "Epoch 4/5 \t loss=4.2104 \t val_loss=3.4438  \t val_acc=0.9400  \t time=0.24s\n",
            "Epoch 5/5 \t loss=2.7975 \t val_loss=2.9831  \t val_acc=0.9400  \t time=0.24s\n",
            "Report for fold  8\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "not_Measurement       0.93      1.00      0.96        41\n",
            "    Measurement       1.00      0.67      0.80         9\n",
            "\n",
            "       accuracy                           0.94        50\n",
            "      macro avg       0.97      0.83      0.88        50\n",
            "   weighted avg       0.94      0.94      0.94        50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-c3ceede7e8d3>:90: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "<ipython-input-81-c3ceede7e8d3>:77: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 \t loss=8.7489 \t val_loss=5.8599  \t val_acc=0.8200  \t time=0.36s\n",
            "Epoch 2/5 \t loss=7.7609 \t val_loss=5.3737  \t val_acc=0.8200  \t time=0.24s\n",
            "Epoch 3/5 \t loss=5.9633 \t val_loss=3.3297  \t val_acc=0.9200  \t time=0.23s\n",
            "Epoch 4/5 \t loss=4.3127 \t val_loss=2.8522  \t val_acc=0.9000  \t time=0.23s\n",
            "Epoch 5/5 \t loss=2.8677 \t val_loss=2.0089  \t val_acc=0.9400  \t time=0.24s\n",
            "Report for fold  9\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "not_Measurement       0.97      0.95      0.96        41\n",
            "    Measurement       0.80      0.89      0.84         9\n",
            "\n",
            "       accuracy                           0.94        50\n",
            "      macro avg       0.89      0.92      0.90        50\n",
            "   weighted avg       0.94      0.94      0.94        50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-c3ceede7e8d3>:90: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "<ipython-input-81-c3ceede7e8d3>:77: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 \t loss=8.4672 \t val_loss=6.7574  \t val_acc=0.7600  \t time=0.36s\n",
            "Epoch 2/5 \t loss=7.7096 \t val_loss=6.0051  \t val_acc=0.7600  \t time=0.24s\n",
            "Epoch 3/5 \t loss=5.8864 \t val_loss=3.7866  \t val_acc=0.8600  \t time=0.22s\n",
            "Epoch 4/5 \t loss=3.7631 \t val_loss=2.4538  \t val_acc=0.9400  \t time=0.24s\n",
            "Epoch 5/5 \t loss=2.3121 \t val_loss=1.7204  \t val_acc=0.9400  \t time=0.24s\n",
            "Report for fold  10\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "not_Measurement       0.93      1.00      0.96        38\n",
            "    Measurement       1.00      0.75      0.86        12\n",
            "\n",
            "       accuracy                           0.94        50\n",
            "      macro avg       0.96      0.88      0.91        50\n",
            "   weighted avg       0.94      0.94      0.94        50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-c3ceede7e8d3>:90: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n"
          ]
        }
      ],
      "source": [
        "kf = KFold(n_splits=10, shuffle=True, random_state=42069)\n",
        "fold = 1\n",
        "\n",
        "for train_idx, val_idx in kf.split(data):\n",
        "  train_X = x_data[train_idx]\n",
        "  train_Y = y_data[train_idx]\n",
        "  val_X = x_data[val_idx]\n",
        "  val_Y = y_data[val_idx]\n",
        "\n",
        "  tokenizer = Tokenizer(num_words=max_features)\n",
        "  tokenizer.fit_on_texts(list(train_X))\n",
        "  train_X = tokenizer.texts_to_sequences(train_X)\n",
        "  val_X = tokenizer.texts_to_sequences(val_X)\n",
        "  \n",
        "  train_X = pad_sequences(train_X, maxlen=maxlen)\n",
        "  val_X = pad_sequences(val_X, maxlen=maxlen)\n",
        "\n",
        "  le = LabelEncoder()\n",
        "  train_Y = le.fit_transform(train_Y.values)\n",
        "  val_Y = le.transform(val_Y.values)\n",
        "\n",
        "  if debug:\n",
        "    embedding_matrix = np.random.randn(12000,300)\n",
        "  else:\n",
        "      embedding_matrix = load_glove(tokenizer.word_index)\n",
        "\n",
        "  n_epochs = 5\n",
        "  model = BiLSTM()\n",
        "  loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
        "  model.cuda()\n",
        "  optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
        "\n",
        "  # Load train and test in CUDA Memory\n",
        "  x_train = torch.tensor(train_X, dtype=torch.long).cuda()\n",
        "  y_train = torch.tensor(train_Y, dtype=torch.long).cuda()\n",
        "  x_cv = torch.tensor(val_X, dtype=torch.long).cuda()\n",
        "  y_cv = torch.tensor(val_Y, dtype=torch.long).cuda()\n",
        "\n",
        "  # Create Torch datasets\n",
        "  train = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "  valid = torch.utils.data.TensorDataset(x_cv, y_cv)\n",
        "\n",
        "  # train = DatasetMaper(x_train, y_train)\n",
        "  # valid = DatasetMaper(x_cv, y_cv)\n",
        "\n",
        "  # Create Data Loaders\n",
        "  train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "  valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  train_loss = []\n",
        "  valid_loss = []\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      start_time = time.time()\n",
        "      # Set model to train configuration\n",
        "      model.train()\n",
        "      avg_loss = 0.  \n",
        "      for i, (x_batch, y_batch) in enumerate(train_loader):\n",
        "          # Predict/Forward Pass\n",
        "          y_pred = model(x_batch)\n",
        "          # Compute loss\n",
        "          loss = loss_fn(y_pred, y_batch)\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          avg_loss += loss.item() / len(train_loader)\n",
        "      \n",
        "      # Set model to validation configuration -Doesn't get trained here\n",
        "      model.eval()        \n",
        "      avg_val_loss = 0.\n",
        "      val_preds = np.zeros((len(x_cv),len(le.classes_)))\n",
        "      \n",
        "      for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "          y_pred = model(x_batch).detach()\n",
        "          avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
        "          # keep/store predictions\n",
        "          val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
        "      \n",
        "      # Check Accuracy\n",
        "      val_accuracy = sum(val_preds.argmax(axis=1)==val_Y)/len(val_Y)\n",
        "      train_loss.append(avg_loss)\n",
        "      valid_loss.append(avg_val_loss)\n",
        "      elapsed_time = time.time() - start_time \n",
        "      print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f}  \\t val_acc={:.4f}  \\t time={:.2f}s'.format(\n",
        "                  epoch + 1, n_epochs, avg_loss, avg_val_loss, val_accuracy, elapsed_time))\n",
        "  \n",
        "  for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "      y_pred = model(x_batch).detach()\n",
        "      avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
        "      val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
        "  val_accuracy = sum(val_preds.argmax(axis=1)==val_Y)/len(val_Y)\n",
        "  print(\"Report for fold \",fold)\n",
        "  fold = fold + 1\n",
        "  print(classification_report(val_Y, val_preds.argmax(axis=1), target_names=['not_Measurement', 'Measurement']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7DT4tJaCQ_R"
      },
      "outputs": [],
      "source": [
        "test_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wShuewmA7tJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9YhPw5wtrhL",
        "outputId": "9dba896b-cc67-42bb-fa59-26c59feaf816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "and\n",
            "\n",
            "(b) a consumer prepackaged cheese that is packaged in Canada from imported bulk cheese for which a standard is set out in Volume 1 of the Standards of Identity Document.\n"
          ]
        }
      ],
      "source": [
        "x = sep_test['Statement'].values[1]\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp8AUWj5trhL",
        "outputId": "ca54b7ef-23e1-4875-c866-36ac480d825b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "not_Measurement\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ],
      "source": [
        "print(label_indices[predict_single(x)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd2vcKPXtrhL",
        "outputId": "535874ab-cfb3-42d3-bb87-ffb49d1bfbc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " sep_test['Measurement'].values[18]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_biganetrhL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo4jRViitrhM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvJXDrKgtrhM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOQD88a3trhM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "XhfIhhgftrhH",
        "mpngGWcitrhI"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python [conda env:pyt]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}